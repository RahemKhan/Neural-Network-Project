{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6ee776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb150b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(\"C:/Users/rahem/OneDrive/Desktop/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d72a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57fe335e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3423cc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 799.92x792 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identifying outliers\n",
    "\n",
    "non_categorical = ['Pregnancies','Glucose','BloodPressure','SkinThickness', 'Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "plt.figure(figsize=(11.11,11))\n",
    "sns.boxplot(data=diabetes[non_categorical],  palette=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50629356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking if there is any correlation between the varaibles\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(diabetes.corr(),annot=True,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faac144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming X and Y variables\n",
    "\n",
    "x = diabetes.drop(columns = ['Outcome'])\n",
    "y = diabetes['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d998cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising input varaibles\n",
    "X = (x - np.min(x)) / (np.max(x) - np.min(x)).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "134818c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset in training and test sets \n",
    "\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db59aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets as csv files\n",
    "x_train.to_csv('x_train.csv',index=False)\n",
    "y_train.to_csv('y_train.csv',index=False)\n",
    "x_test.to_csv('x_test.csv',index=False)\n",
    "y_test.to_csv('y_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36ddd2",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2ebc2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7db9ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skorch\n",
      "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\rahem\\anaconda3\\lib\\site-packages (from skorch) (1.0.2)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\rahem\\anaconda3\\lib\\site-packages (from skorch) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\rahem\\anaconda3\\lib\\site-packages (from skorch) (1.6.2)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in c:\\users\\rahem\\anaconda3\\lib\\site-packages (from skorch) (4.59.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rahem\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->skorch) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rahem\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n",
      "Installing collected packages: tabulate, skorch\n",
      "Successfully installed skorch-0.11.0 tabulate-0.8.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6929b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the dataset\n",
    "\n",
    "x_train = pd.read_csv('x_train.csv')\n",
    "x_test = pd.read_csv('x_test.csv')\n",
    "\n",
    "# Convert dataframes to series\n",
    "y_train = y_train.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f4b642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets into tensor\n",
    "x_trainTensor = torch.tensor(x_train.to_numpy()).float()\n",
    "y_trainTensor = torch.tensor(y_train.to_numpy()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6caeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "input_size = len(x_train.columns)\n",
    "hidden_size = 200\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4d4592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulid a MLP model\n",
    "class Net(nn.Module):\n",
    "     def __init__(self, hidden_size=200, nonlin=F.relu):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.nonlin = nonlin\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    " \n",
    "     def forward(self, x, **kwargs):\n",
    "        hidden = self.nonlin(self.fc1(x))\n",
    "        hidden = F.relu(self.fc2(hidden))\n",
    "        out = F.softmax(self.fc3(hidden), dim=1)\n",
    "        return out\n",
    "\n",
    "net = NeuralNetClassifier(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c77e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6873\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6671\u001b[0m  0.0570\n",
      "      2        \u001b[36m0.6559\u001b[0m       0.6392        \u001b[35m0.6635\u001b[0m  0.0223\n",
      "      3        0.6633       0.6392        0.6929  0.0180\n",
      "      4        0.6925       0.6392        0.7047  0.0160\n",
      "      5        0.6990       0.6392        0.6921  0.0150\n",
      "      6        0.6854       0.6392        0.6767  0.0190\n",
      "      7        0.6715       0.6392        0.6681  0.0160\n",
      "      8        0.6641       0.6392        0.6653  0.0180\n",
      "      9        0.6617       0.6392        0.6657  0.0190\n",
      "     10        0.6623       0.6392        0.6673  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7297\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6816\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6631\u001b[0m       0.6392        \u001b[35m0.6643\u001b[0m  0.0190\n",
      "      3        0.6667       0.6392        0.7027  0.0150\n",
      "      4        0.7038       0.6392        0.7139  0.0140\n",
      "      5        0.7077       0.6392        0.6946  0.0180\n",
      "      6        0.6878       0.6392        0.6754  0.0150\n",
      "      7        0.6708       0.6392        0.6656  0.0160\n",
      "      8        \u001b[36m0.6624\u001b[0m       0.6392        \u001b[35m0.6625\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6600\u001b[0m       0.6392        0.6630  0.0180\n",
      "     10        0.6605       0.6392        0.6644  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6972\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6632\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6527\u001b[0m       0.6392        0.6673  0.0330\n",
      "      3        0.6785       0.6392        0.7081  0.0160\n",
      "      4        0.7130       0.6392        0.6904  0.0180\n",
      "      5        0.6889       0.6392        \u001b[35m0.6601\u001b[0m  0.0190\n",
      "      6        0.6615       0.6392        \u001b[35m0.6476\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6508\u001b[0m       0.6392        \u001b[35m0.6449\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6497\u001b[0m       0.6392        0.6465  0.0160\n",
      "      9        0.6524       0.6392        0.6461  0.0160\n",
      "     10        0.6520       0.6392        \u001b[35m0.6394\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6973\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6709\u001b[0m  0.0167\n",
      "      2        \u001b[36m0.6592\u001b[0m       0.6392        \u001b[35m0.6584\u001b[0m  0.0140\n",
      "      3        0.6593       0.6392        0.6839  0.0160\n",
      "      4        0.6872       0.6392        0.6994  0.0160\n",
      "      5        0.6983       0.6392        0.6909  0.0170\n",
      "      6        0.6876       0.6392        0.6745  0.0210\n",
      "      7        0.6722       0.6392        0.6626  0.0160\n",
      "      8        0.6619       0.6392        \u001b[35m0.6568\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6570\u001b[0m       0.6392        \u001b[35m0.6549\u001b[0m  0.0130\n",
      "     10        \u001b[36m0.6556\u001b[0m       0.6392        \u001b[35m0.6547\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6847\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6622\u001b[0m  0.0143\n",
      "      2        \u001b[36m0.6534\u001b[0m       0.6392        0.6645  0.0160\n",
      "      3        0.6715       0.6392        0.6996  0.0150\n",
      "      4        0.7047       0.6392        0.6999  0.0160\n",
      "      5        0.6990       0.6392        0.6774  0.0170\n",
      "      6        0.6771       0.6392        \u001b[35m0.6617\u001b[0m  0.0170\n",
      "      7        0.6635       0.6392        \u001b[35m0.6562\u001b[0m  0.0150\n",
      "      8        0.6589       0.6392        \u001b[35m0.6560\u001b[0m  0.0190\n",
      "      9        0.6595       0.6392        0.6578  0.0170\n",
      "     10        0.6615       0.6392        0.6577  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7023\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6703\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6609\u001b[0m       0.6392        \u001b[35m0.6643\u001b[0m  0.0140\n",
      "      3        0.6722       0.6392        0.6975  0.0190\n",
      "      4        0.7044       0.6392        0.7020  0.0150\n",
      "      5        0.7017       0.6392        0.6820  0.0180\n",
      "      6        0.6807       0.6392        0.6649  0.0200\n",
      "      7        0.6654       0.6392        \u001b[35m0.6565\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6584\u001b[0m       0.6392        \u001b[35m0.6537\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.6565\u001b[0m       0.6392        \u001b[35m0.6535\u001b[0m  0.0170\n",
      "     10        0.6568       0.6392        \u001b[35m0.6530\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7054\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6732\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6605\u001b[0m       0.6392        \u001b[35m0.6622\u001b[0m  0.0180\n",
      "      3        0.6708       0.6392        0.6983  0.0150\n",
      "      4        0.7074       0.6392        0.7035  0.0160\n",
      "      5        0.7042       0.6392        0.6814  0.0150\n",
      "      6        0.6808       0.6392        0.6644  0.0150\n",
      "      7        0.6654       0.6392        \u001b[35m0.6575\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6595\u001b[0m       0.6392        \u001b[35m0.6564\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.6589\u001b[0m       0.6392        0.6577  0.0160\n",
      "     10        0.6604       0.6392        0.6585  0.0149\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6762\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6602\u001b[0m  0.0203\n",
      "      2        \u001b[36m0.6573\u001b[0m       0.6392        0.6657  0.0230\n",
      "      3        0.6746       0.6392        0.6952  0.0180\n",
      "      4        0.7010       0.6392        0.6965  0.0190\n",
      "      5        0.6959       0.6392        0.6785  0.0180\n",
      "      6        0.6773       0.6392        0.6648  0.0110\n",
      "      7        0.6651       0.6392        \u001b[35m0.6593\u001b[0m  0.0180\n",
      "      8        0.6604       0.6392        \u001b[35m0.6585\u001b[0m  0.0180\n",
      "      9        0.6600       0.6392        0.6595  0.0180\n",
      "     10        0.6608       0.6392        0.6595  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6856\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6617\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6558\u001b[0m       0.6392        \u001b[35m0.6594\u001b[0m  0.0167\n",
      "      3        0.6697       0.6392        0.6922  0.0170\n",
      "      4        0.7008       0.6392        0.6948  0.0150\n",
      "      5        0.6961       0.6392        0.6732  0.0170\n",
      "      6        0.6742       0.6392        \u001b[35m0.6564\u001b[0m  0.0150\n",
      "      7        0.6598       0.6392        \u001b[35m0.6491\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6541\u001b[0m       0.6392        \u001b[35m0.6468\u001b[0m  0.0138\n",
      "      9        \u001b[36m0.6531\u001b[0m       0.6392        \u001b[35m0.6463\u001b[0m  0.0180\n",
      "     10        0.6536       0.6392        \u001b[35m0.6446\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6661\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6554\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6513\u001b[0m       0.6392        0.6609  0.0130\n",
      "      3        0.6642       0.6392        0.6853  0.0110\n",
      "      4        0.6854       0.6392        0.6882  0.0150\n",
      "      5        0.6821       0.6392        0.6713  0.0151\n",
      "      6        0.6637       0.6392        \u001b[35m0.6545\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6479\u001b[0m       0.6392        \u001b[35m0.6447\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6385\u001b[0m       0.6392        \u001b[35m0.6401\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.6332\u001b[0m       0.6392        \u001b[35m0.6375\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6288\u001b[0m       0.6392        \u001b[35m0.6323\u001b[0m  0.0230\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6884\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6658\u001b[0m  0.0161\n",
      "      2        \u001b[36m0.6545\u001b[0m       0.6392        \u001b[35m0.6641\u001b[0m  0.0150\n",
      "      3        0.6697       0.6392        0.7105  0.0170\n",
      "      4        0.7165       0.6392        0.7260  0.0160\n",
      "      5        0.7222       0.6392        0.6995  0.0170\n",
      "      6        0.6940       0.6392        0.6719  0.0120\n",
      "      7        0.6694       0.6392        \u001b[35m0.6584\u001b[0m  0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        0.6579       0.6392        \u001b[35m0.6543\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6545\u001b[0m       0.6392        0.6550  0.0140\n",
      "     10        0.6557       0.6392        0.6588  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7068\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6758\u001b[0m  0.0090\n",
      "      2        \u001b[36m0.6599\u001b[0m       0.6392        \u001b[35m0.6640\u001b[0m  0.0120\n",
      "      3        0.6695       0.6392        0.7237  0.0130\n",
      "      4        0.7288       0.6392        0.7381  0.0140\n",
      "      5        0.7283       0.6392        0.6960  0.0170\n",
      "      6        0.6866       0.6392        \u001b[35m0.6637\u001b[0m  0.0170\n",
      "      7        0.6599       0.6392        \u001b[35m0.6525\u001b[0m  0.0110\n",
      "      8        \u001b[36m0.6506\u001b[0m       0.6392        \u001b[35m0.6514\u001b[0m  0.0120\n",
      "      9        \u001b[36m0.6494\u001b[0m       0.6392        0.6565  0.0110\n",
      "     10        0.6540       0.6392        0.6636  0.0137\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6836\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6655\u001b[0m  0.0100\n",
      "      2        \u001b[36m0.6564\u001b[0m       0.6392        \u001b[35m0.6569\u001b[0m  0.0140\n",
      "      3        0.6605       0.6392        0.6908  0.0130\n",
      "      4        0.6986       0.6392        0.7143  0.0150\n",
      "      5        0.7150       0.6392        0.7004  0.0140\n",
      "      6        0.6967       0.6392        0.6746  0.0160\n",
      "      7        0.6720       0.6392        0.6576  0.0130\n",
      "      8        0.6569       0.6392        \u001b[35m0.6503\u001b[0m  0.0140\n",
      "      9        \u001b[36m0.6504\u001b[0m       0.6392        \u001b[35m0.6488\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6495\u001b[0m       0.6392        0.6508  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6685\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6592\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6546\u001b[0m       0.6392        0.6691  0.0140\n",
      "      3        0.6745       0.6392        0.7062  0.0150\n",
      "      4        0.7093       0.6392        0.7089  0.0140\n",
      "      5        0.7043       0.6392        0.6807  0.0160\n",
      "      6        0.6764       0.6392        \u001b[35m0.6579\u001b[0m  0.0150\n",
      "      7        0.6566       0.6392        \u001b[35m0.6477\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6479\u001b[0m       0.6392        \u001b[35m0.6450\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6460\u001b[0m       0.6392        0.6462  0.0140\n",
      "     10        0.6475       0.6392        0.6458  0.0120\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7112\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6717\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6607\u001b[0m       0.6392        0.6918  0.0187\n",
      "      3        0.7118       0.6392        0.7550  0.0225\n",
      "      4        0.7600       0.6392        0.7207  0.0200\n",
      "      5        0.7162       0.6392        0.6722  0.0160\n",
      "      6        0.6738       0.6392        \u001b[35m0.6553\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.6592\u001b[0m       0.6392        \u001b[35m0.6520\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.6565\u001b[0m       0.6392        0.6547  0.0170\n",
      "      9        0.6609       0.6392        0.6615  0.0180\n",
      "     10        0.6690       0.6392        0.6644  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6772\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6621\u001b[0m  0.0260\n",
      "      2        \u001b[36m0.6574\u001b[0m       0.6392        0.6749  0.0149\n",
      "      3        0.6855       0.6392        0.7168  0.0170\n",
      "      4        0.7211       0.6392        0.7063  0.0200\n",
      "      5        0.7011       0.6392        0.6690  0.0170\n",
      "      6        0.6664       0.6392        \u001b[35m0.6485\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6495\u001b[0m       0.6392        \u001b[35m0.6422\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6447\u001b[0m       0.6392        0.6440  0.0160\n",
      "      9        0.6481       0.6392        0.6497  0.0160\n",
      "     10        0.6528       0.6392        0.6435  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6831\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6684\u001b[0m  0.0148\n",
      "      2        \u001b[36m0.6625\u001b[0m       0.6392        0.6695  0.0170\n",
      "      3        0.6791       0.6392        0.7090  0.0160\n",
      "      4        0.7173       0.6392        0.7105  0.0140\n",
      "      5        0.7079       0.6392        0.6764  0.0140\n",
      "      6        0.6733       0.6392        \u001b[35m0.6523\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6520\u001b[0m       0.6392        \u001b[35m0.6433\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6440\u001b[0m       0.6392        \u001b[35m0.6428\u001b[0m  0.0150\n",
      "      9        0.6443       0.6392        0.6472  0.0160\n",
      "     10        0.6482       0.6392        0.6446  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7204\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6777\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6664\u001b[0m       0.6392        \u001b[35m0.6758\u001b[0m  0.0160\n",
      "      3        0.6905       0.6392        0.7334  0.0100\n",
      "      4        0.7397       0.6392        0.7243  0.0140\n",
      "      5        0.7150       0.6392        0.6795  0.0120\n",
      "      6        0.6719       0.6392        \u001b[35m0.6558\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6523\u001b[0m       0.6392        \u001b[35m0.6490\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6461\u001b[0m       0.6392        \u001b[35m0.6487\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6460\u001b[0m       0.6392        0.6526  0.0120\n",
      "     10        0.6495       0.6392        0.6546  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7164\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6782\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6665\u001b[0m       0.6392        \u001b[35m0.6737\u001b[0m  0.0130\n",
      "      3        0.6906       0.6392        0.7346  0.0100\n",
      "      4        0.7437       0.6392        0.7240  0.0140\n",
      "      5        0.7169       0.6392        0.6759  0.0140\n",
      "      6        0.6710       0.6392        \u001b[35m0.6515\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6506\u001b[0m       0.6392        \u001b[35m0.6448\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6450\u001b[0m       0.6392        \u001b[35m0.6446\u001b[0m  0.0120\n",
      "      9        0.6461       0.6392        0.6489  0.0238\n",
      "     10        0.6512       0.6392        0.6518  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7208\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6792\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6655\u001b[0m       0.6392        \u001b[35m0.6626\u001b[0m  0.0100\n",
      "      3        0.6713       0.6392        0.7128  0.0150\n",
      "      4        0.7221       0.6392        0.7339  0.0150\n",
      "      5        0.7303       0.6392        0.7065  0.0130\n",
      "      6        0.6994       0.6392        0.6755  0.0130\n",
      "      7        0.6718       0.6392        \u001b[35m0.6596\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.6586\u001b[0m       0.6392        \u001b[35m0.6545\u001b[0m  0.0141\n",
      "      9        \u001b[36m0.6547\u001b[0m       0.6392        0.6551  0.0130\n",
      "     10        0.6560       0.6392        0.6589  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6872\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6622\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6515\u001b[0m       0.6392        0.6942  0.0160\n",
      "      3        0.7119       0.6392        0.7797  0.0170\n",
      "      4        0.7764       0.6392        0.7341  0.0150\n",
      "      5        0.7179       0.6392        0.6675  0.0160\n",
      "      6        0.6641       0.6392        \u001b[35m0.6512\u001b[0m  0.0120\n",
      "      7        \u001b[36m0.6508\u001b[0m       0.6392        \u001b[35m0.6489\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6477\u001b[0m       0.6392        0.6528  0.0160\n",
      "      9        0.6541       0.6392        0.6694  0.0160\n",
      "     10        0.6723       0.6392        0.6847  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6883\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6641\u001b[0m  0.0210\n",
      "      2        \u001b[36m0.6551\u001b[0m       0.6392        0.6914  0.0130\n",
      "      3        0.7078       0.6392        0.7772  0.0140\n",
      "      4        0.7734       0.6392        0.7383  0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        0.7194       0.6392        0.6697  0.0160\n",
      "      6        0.6635       0.6392        \u001b[35m0.6496\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6477\u001b[0m       0.6392        \u001b[35m0.6471\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6445\u001b[0m       0.6392        0.6543  0.0150\n",
      "      9        0.6535       0.6392        0.6730  0.0150\n",
      "     10        0.6720       0.6392        0.6864  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6988\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6687\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6570\u001b[0m       0.6392        0.6839  0.0160\n",
      "      3        0.6997       0.6392        0.7724  0.0150\n",
      "      4        0.7753       0.6392        0.7533  0.0150\n",
      "      5        0.7359       0.6392        0.6778  0.0170\n",
      "      6        0.6706       0.6392        \u001b[35m0.6484\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6491\u001b[0m       0.6392        \u001b[35m0.6457\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6458\u001b[0m       0.6392        0.6475  0.0160\n",
      "      9        0.6486       0.6392        0.6604  0.0150\n",
      "     10        0.6635       0.6392        0.6772  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7011\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6672\u001b[0m  0.0110\n",
      "      2        \u001b[36m0.6568\u001b[0m       0.6392        0.6935  0.0140\n",
      "      3        0.7140       0.6392        0.7748  0.0140\n",
      "      4        0.7780       0.6392        0.7372  0.0130\n",
      "      5        0.7245       0.6392        0.6708  0.0150\n",
      "      6        0.6680       0.6392        \u001b[35m0.6529\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6529\u001b[0m       0.6392        \u001b[35m0.6507\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6507\u001b[0m       0.6392        0.6545  0.0150\n",
      "      9        0.6557       0.6392        0.6650  0.0160\n",
      "     10        0.6673       0.6392        0.6758  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6801\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6600\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6528\u001b[0m       0.6392        0.6865  0.0150\n",
      "      3        0.7070       0.6392        0.7603  0.0150\n",
      "      4        0.7689       0.6392        0.7334  0.0150\n",
      "      5        0.7266       0.6392        0.6744  0.0160\n",
      "      6        0.6731       0.6392        \u001b[35m0.6524\u001b[0m  0.0170\n",
      "      7        0.6545       0.6392        \u001b[35m0.6489\u001b[0m  0.0130\n",
      "      8        \u001b[36m0.6503\u001b[0m       0.6392        0.6502  0.0150\n",
      "      9        0.6522       0.6392        0.6589  0.0150\n",
      "     10        0.6628       0.6392        0.6727  0.0208\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6825\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6613\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6575\u001b[0m       0.6392        0.6918  0.0140\n",
      "      3        0.7145       0.6392        0.7583  0.0150\n",
      "      4        0.7647       0.6392        0.7233  0.0130\n",
      "      5        0.7144       0.6392        0.6658  0.0140\n",
      "      6        0.6639       0.6392        \u001b[35m0.6458\u001b[0m  0.0120\n",
      "      7        \u001b[36m0.6477\u001b[0m       0.6392        \u001b[35m0.6421\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6447\u001b[0m       0.6392        0.6462  0.0170\n",
      "      9        0.6510       0.6392        0.6550  0.0120\n",
      "     10        0.6597       0.6392        0.6496  0.0120\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7277\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6742\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6609\u001b[0m       0.6392        0.7023  0.0140\n",
      "      3        0.7343       0.6392        0.8064  0.0167\n",
      "      4        0.8114       0.6392        0.7538  0.0120\n",
      "      5        0.7382       0.6392        \u001b[35m0.6734\u001b[0m  0.0140\n",
      "      6        0.6705       0.6392        \u001b[35m0.6530\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6540\u001b[0m       0.6392        \u001b[35m0.6513\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6524\u001b[0m       0.6392        0.6544  0.0260\n",
      "      9        0.6568       0.6392        0.6647  0.0160\n",
      "     10        0.6692       0.6392        0.6787  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6784\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6611\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6572\u001b[0m       0.6392        0.6775  0.0150\n",
      "      3        0.6952       0.6392        0.7383  0.0140\n",
      "      4        0.7481       0.6392        0.7332  0.0140\n",
      "      5        0.7262       0.6392        0.6834  0.0150\n",
      "      6        0.6774       0.6392        \u001b[35m0.6534\u001b[0m  0.0130\n",
      "      7        \u001b[36m0.6532\u001b[0m       0.6392        \u001b[35m0.6478\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6484\u001b[0m       0.6392        \u001b[35m0.6473\u001b[0m  0.0140\n",
      "      9        \u001b[36m0.6482\u001b[0m       0.6392        0.6504  0.0129\n",
      "     10        0.6525       0.6392        0.6562  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6768\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6565\u001b[0m  0.0110\n",
      "      2        \u001b[36m0.6498\u001b[0m       0.6392        0.6808  0.0149\n",
      "      3        0.6956       0.6392        0.7462  0.0120\n",
      "      4        0.7475       0.6392        0.7276  0.0150\n",
      "      5        0.7119       0.6392        0.6669  0.0150\n",
      "      6        0.6575       0.6392        \u001b[35m0.6386\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6365\u001b[0m       0.6392        \u001b[35m0.6318\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6303\u001b[0m       0.6392        \u001b[35m0.6310\u001b[0m  0.0140\n",
      "      9        0.6320       0.6392        0.6439  0.0180\n",
      "     10        0.6465       0.6392        0.6503  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6769\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6615\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6576\u001b[0m       0.6392        0.6803  0.0150\n",
      "      3        0.6977       0.6392        0.7434  0.0140\n",
      "      4        0.7491       0.6392        0.7235  0.0150\n",
      "      5        0.7103       0.6392        0.6647  0.0140\n",
      "      6        \u001b[36m0.6568\u001b[0m       0.6392        \u001b[35m0.6429\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.6390\u001b[0m       0.6392        \u001b[35m0.6384\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6339\u001b[0m       0.6392        0.6428  0.0150\n",
      "      9        0.6415       0.6392        0.6617  0.0120\n",
      "     10        0.6578       0.6392        0.6593  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6902\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6675\u001b[0m  0.0200\n",
      "      2        \u001b[36m0.6580\u001b[0m       0.6392        \u001b[35m0.6673\u001b[0m  0.0220\n",
      "      3        0.6708       0.6392        0.7012  0.0150\n",
      "      4        0.7030       0.6392        0.7063  0.0154\n",
      "      5        0.7017       0.6392        0.6862  0.0170\n",
      "      6        0.6815       0.6392        0.6693  0.0140\n",
      "      7        0.6664       0.6392        \u001b[35m0.6611\u001b[0m  0.0170\n",
      "      8        0.6592       0.6392        \u001b[35m0.6586\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6571\u001b[0m       0.6392        \u001b[35m0.6586\u001b[0m  0.0110\n",
      "     10        \u001b[36m0.6571\u001b[0m       0.6392        \u001b[35m0.6582\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7130\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6699\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6582\u001b[0m       0.6392        0.6832  0.0147\n",
      "      3        0.6902       0.6392        0.7255  0.0160\n",
      "      4        0.7212       0.6392        0.7049  0.0170\n",
      "      5        0.6955       0.6392        0.6742  0.0160\n",
      "      6        0.6688       0.6392        \u001b[35m0.6609\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.6575\u001b[0m       0.6392        \u001b[35m0.6579\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.6548\u001b[0m       0.6392        0.6598  0.0253\n",
      "      9        0.6564       0.6392        0.6620  0.0170\n",
      "     10        0.6570       0.6392        0.6589  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7101\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6692\u001b[0m  0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6565\u001b[0m       0.6392        0.6699  0.0180\n",
      "      3        0.6775       0.6392        0.7072  0.0190\n",
      "      4        0.7107       0.6392        0.7020  0.0200\n",
      "      5        0.6992       0.6392        0.6785  0.0180\n",
      "      6        0.6768       0.6392        \u001b[35m0.6647\u001b[0m  0.0160\n",
      "      7        0.6649       0.6392        \u001b[35m0.6601\u001b[0m  0.0160\n",
      "      8        0.6611       0.6392        0.6602  0.0150\n",
      "      9        0.6616       0.6392        0.6618  0.0170\n",
      "     10        0.6634       0.6392        0.6626  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6783\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6631\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6552\u001b[0m       0.6392        0.6767  0.0180\n",
      "      3        0.6817       0.6392        0.7094  0.0160\n",
      "      4        0.7083       0.6392        0.6968  0.0170\n",
      "      5        0.6913       0.6392        0.6703  0.0167\n",
      "      6        0.6675       0.6392        \u001b[35m0.6560\u001b[0m  0.0160\n",
      "      7        0.6556       0.6392        \u001b[35m0.6512\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6521\u001b[0m       0.6392        \u001b[35m0.6508\u001b[0m  0.0160\n",
      "      9        0.6524       0.6392        \u001b[35m0.6495\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6512\u001b[0m       0.6392        \u001b[35m0.6433\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6753\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6565\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6530\u001b[0m       0.6392        0.6733  0.0160\n",
      "      3        0.6822       0.6392        0.6987  0.0160\n",
      "      4        0.7019       0.6392        0.6831  0.0150\n",
      "      5        0.6828       0.6392        0.6573  0.0170\n",
      "      6        0.6595       0.6392        \u001b[35m0.6433\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6477\u001b[0m       0.6392        \u001b[35m0.6380\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6440\u001b[0m       0.6392        \u001b[35m0.6367\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6440\u001b[0m       0.6392        \u001b[35m0.6325\u001b[0m  0.0290\n",
      "     10        \u001b[36m0.6405\u001b[0m       0.6392        \u001b[35m0.6217\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7103\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6705\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6610\u001b[0m       0.6392        0.6765  0.0140\n",
      "      3        0.6920       0.6392        0.7134  0.0140\n",
      "      4        0.7199       0.6392        0.6901  0.0140\n",
      "      5        0.6907       0.6392        \u001b[35m0.6601\u001b[0m  0.0150\n",
      "      6        0.6639       0.6392        \u001b[35m0.6481\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6541\u001b[0m       0.6392        \u001b[35m0.6451\u001b[0m  0.0166\n",
      "      8        \u001b[36m0.6529\u001b[0m       0.6392        0.6455  0.0150\n",
      "      9        0.6544       0.6392        \u001b[35m0.6422\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.6511\u001b[0m       0.6392        \u001b[35m0.6325\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6962\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6659\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6593\u001b[0m       0.6392        0.6744  0.0173\n",
      "      3        0.6850       0.6392        0.7104  0.0160\n",
      "      4        0.7133       0.6392        0.6999  0.0160\n",
      "      5        0.6964       0.6392        0.6733  0.0150\n",
      "      6        0.6719       0.6392        \u001b[35m0.6585\u001b[0m  0.0150\n",
      "      7        0.6593       0.6392        \u001b[35m0.6535\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.6554\u001b[0m       0.6392        \u001b[35m0.6533\u001b[0m  0.0190\n",
      "      9        0.6557       0.6392        0.6538  0.0140\n",
      "     10        0.6557       0.6392        \u001b[35m0.6505\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7273\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6671\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6673\u001b[0m       0.6392        0.7156  0.0160\n",
      "      3        0.7350       0.6392        0.7282  0.0110\n",
      "      4        0.7236       0.6392        0.6796  0.0150\n",
      "      5        0.6776       0.6392        \u001b[35m0.6604\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6616\u001b[0m       0.6392        \u001b[35m0.6576\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6602\u001b[0m       0.6392        0.6615  0.0140\n",
      "      8        0.6651       0.6392        0.6661  0.0140\n",
      "      9        0.6687       0.6392        0.6644  0.0150\n",
      "     10        0.6654       0.6392        0.6577  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6905\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6576\u001b[0m       0.6392        0.6762  0.0140\n",
      "      3        0.6867       0.6392        0.7127  0.0160\n",
      "      4        0.7142       0.6392        0.7004  0.0201\n",
      "      5        0.6956       0.6392        0.6743  0.0170\n",
      "      6        0.6723       0.6392        \u001b[35m0.6612\u001b[0m  0.0140\n",
      "      7        0.6617       0.6392        \u001b[35m0.6577\u001b[0m  0.0150\n",
      "      8        0.6595       0.6392        0.6588  0.0160\n",
      "      9        0.6612       0.6392        0.6606  0.0140\n",
      "     10        0.6630       0.6392        0.6598  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7003\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6637\u001b[0m  0.0230\n",
      "      2        \u001b[36m0.6599\u001b[0m       0.6392        0.6834  0.0120\n",
      "      3        0.6984       0.6392        0.7150  0.0145\n",
      "      4        0.7156       0.6392        0.6864  0.0170\n",
      "      5        0.6820       0.6392        \u001b[35m0.6592\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6572\u001b[0m       0.6392        \u001b[35m0.6487\u001b[0m  0.0148\n",
      "      7        \u001b[36m0.6476\u001b[0m       0.6392        \u001b[35m0.6457\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6451\u001b[0m       0.6392        \u001b[35m0.6451\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.6438\u001b[0m       0.6392        \u001b[35m0.6406\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.6368\u001b[0m       0.6392        \u001b[35m0.6300\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6864\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6603\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6535\u001b[0m       0.6392        0.6839  0.0170\n",
      "      3        0.6956       0.6392        0.7357  0.0150\n",
      "      4        0.7330       0.6392        0.7031  0.0140\n",
      "      5        0.6945       0.6392        0.6628  0.0150\n",
      "      6        0.6609       0.6392        \u001b[35m0.6497\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6500\u001b[0m       0.6392        \u001b[35m0.6478\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.6492\u001b[0m       0.6392        0.6531  0.0150\n",
      "      9        0.6563       0.6392        0.6577  0.0170\n",
      "     10        0.6603       0.6392        0.6489  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6630\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6583\u001b[0m  0.0141\n",
      "      2        \u001b[36m0.6568\u001b[0m       0.6392        0.6845  0.0170\n",
      "      3        0.6921       0.6392        0.7145  0.0130\n",
      "      4        0.7112       0.6392        0.6889  0.0170\n",
      "      5        0.6815       0.6392        0.6609  0.0160\n",
      "      6        \u001b[36m0.6564\u001b[0m       0.6392        \u001b[35m0.6522\u001b[0m  0.0130\n",
      "      7        \u001b[36m0.6477\u001b[0m       0.6392        0.6539  0.0180\n",
      "      8        0.6490       0.6392        0.6606  0.0180\n",
      "      9        0.6535       0.6392        0.6575  0.0140\n",
      "     10        \u001b[36m0.6468\u001b[0m       0.6392        \u001b[35m0.6434\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6824\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6620\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6543\u001b[0m       0.6392        0.6699  0.0170\n",
      "      3        0.6785       0.6392        0.7181  0.0180\n",
      "      4        0.7224       0.6392        0.7172  0.0140\n",
      "      5        0.7111       0.6392        0.6808  0.0170\n",
      "      6        0.6762       0.6392        \u001b[35m0.6566\u001b[0m  0.0160\n",
      "      7        0.6558       0.6392        \u001b[35m0.6476\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6482\u001b[0m       0.6392        \u001b[35m0.6458\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.6476\u001b[0m       0.6392        0.6489  0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        0.6514       0.6392        0.6499  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6820\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6634\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6567\u001b[0m       0.6392        0.6909  0.0190\n",
      "      3        0.7013       0.6392        0.7332  0.0160\n",
      "      4        0.7312       0.6392        0.7034  0.0160\n",
      "      5        0.6965       0.6392        0.6673  0.0170\n",
      "      6        0.6655       0.6392        \u001b[35m0.6541\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6544\u001b[0m       0.6392        \u001b[35m0.6517\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6529\u001b[0m       0.6392        0.6546  0.0150\n",
      "      9        0.6574       0.6392        0.6596  0.0140\n",
      "     10        0.6625       0.6392        0.6576  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6768\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6586\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6531\u001b[0m       0.6392        0.6818  0.0160\n",
      "      3        0.6954       0.6392        0.7259  0.0150\n",
      "      4        0.7283       0.6392        0.6974  0.0200\n",
      "      5        0.6941       0.6392        0.6609  0.0140\n",
      "      6        0.6626       0.6392        \u001b[35m0.6477\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6511\u001b[0m       0.6392        \u001b[35m0.6446\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6493\u001b[0m       0.6392        0.6475  0.0150\n",
      "      9        0.6544       0.6392        0.6510  0.0170\n",
      "     10        0.6580       0.6392        \u001b[35m0.6433\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7045\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6692\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6628\u001b[0m       0.6392        0.7040  0.0160\n",
      "      3        0.7259       0.6392        0.7506  0.0150\n",
      "      4        0.7480       0.6392        0.6956  0.0207\n",
      "      5        0.6886       0.6392        \u001b[35m0.6585\u001b[0m  0.0120\n",
      "      6        \u001b[36m0.6583\u001b[0m       0.6392        \u001b[35m0.6505\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6517\u001b[0m       0.6392        0.6518  0.0150\n",
      "      8        0.6548       0.6392        0.6610  0.0160\n",
      "      9        0.6648       0.6392        0.6659  0.0130\n",
      "     10        0.6668       0.6392        0.6547  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7005\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6678\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6563\u001b[0m       0.6392        0.6680  0.0160\n",
      "      3        0.6830       0.6392        0.7270  0.0160\n",
      "      4        0.7368       0.6392        0.7205  0.0160\n",
      "      5        0.7158       0.6392        0.6763  0.0180\n",
      "      6        0.6738       0.6392        \u001b[35m0.6534\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6542\u001b[0m       0.6392        \u001b[35m0.6464\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6481\u001b[0m       0.6392        \u001b[35m0.6453\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6479\u001b[0m       0.6392        0.6486  0.0290\n",
      "     10        0.6521       0.6392        0.6481  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6898\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6634\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6639\u001b[0m       0.6392        0.7020  0.0160\n",
      "      3        0.7201       0.6392        0.7374  0.0150\n",
      "      4        0.7345       0.6392        0.6942  0.0150\n",
      "      5        0.6875       0.6392        \u001b[35m0.6613\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6597\u001b[0m       0.6392        \u001b[35m0.6519\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6518\u001b[0m       0.6392        \u001b[35m0.6517\u001b[0m  0.0160\n",
      "      8        0.6525       0.6392        0.6574  0.0170\n",
      "      9        0.6588       0.6392        0.6631  0.0150\n",
      "     10        0.6624       0.6392        0.6593  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6637\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6536\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6565\u001b[0m       0.6392        0.6887  0.0130\n",
      "      3        0.7007       0.6392        0.7081  0.0217\n",
      "      4        0.7025       0.6392        0.6656  0.0170\n",
      "      5        0.6601       0.6392        \u001b[35m0.6400\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6398\u001b[0m       0.6392        \u001b[35m0.6344\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6365\u001b[0m       0.6392        0.6405  0.0140\n",
      "      8        0.6439       0.6392        0.6400  0.0160\n",
      "      9        0.6385       0.6392        \u001b[35m0.6165\u001b[0m  0.0120\n",
      "     10        \u001b[36m0.6157\u001b[0m       0.6392        \u001b[35m0.5960\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6964\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6600\u001b[0m       0.6392        0.6820  0.0180\n",
      "      3        0.6973       0.6392        0.7296  0.0170\n",
      "      4        0.7301       0.6392        0.7002  0.0160\n",
      "      5        0.6896       0.6392        \u001b[35m0.6561\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6500\u001b[0m       0.6392        \u001b[35m0.6390\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6349\u001b[0m       0.6392        \u001b[35m0.6343\u001b[0m  0.0110\n",
      "      8        \u001b[36m0.6304\u001b[0m       0.6392        0.6373  0.0180\n",
      "      9        0.6325       0.6392        0.6350  0.0150\n",
      "     10        \u001b[36m0.6240\u001b[0m       0.6392        \u001b[35m0.6140\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6635\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6607\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6601\u001b[0m       0.6392        0.7187  0.0150\n",
      "      3        0.7266       0.6392        0.7338  0.0130\n",
      "      4        0.7200       0.6392        0.6674  0.0140\n",
      "      5        0.6631       0.6392        \u001b[35m0.6434\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6443\u001b[0m       0.6392        \u001b[35m0.6379\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6408\u001b[0m       0.6392        0.6475  0.0160\n",
      "      8        0.6567       0.6392        0.6597  0.0250\n",
      "      9        0.6655       0.6392        \u001b[35m0.6315\u001b[0m  0.0110\n",
      "     10        \u001b[36m0.6363\u001b[0m       0.6392        \u001b[35m0.6043\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6897\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6586\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6539\u001b[0m       0.6392        0.7046  0.0160\n",
      "      3        0.7217       0.6392        0.7613  0.0140\n",
      "      4        0.7549       0.6392        0.7076  0.0190\n",
      "      5        0.6962       0.6392        0.6620  0.0170\n",
      "      6        0.6597       0.6392        \u001b[35m0.6527\u001b[0m  0.0120\n",
      "      7        \u001b[36m0.6526\u001b[0m       0.6392        0.6539  0.0170\n",
      "      8        0.6540       0.6392        0.6612  0.0190\n",
      "      9        0.6618       0.6392        0.6728  0.0110\n",
      "     10        0.6709       0.6392        0.6743  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6938\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6642\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6553\u001b[0m       0.6392        0.6964  0.0170\n",
      "      3        0.7186       0.6392        0.7733  0.0170\n",
      "      4        0.7752       0.6392        0.7240  0.0160\n",
      "      5        0.7129       0.6392        \u001b[35m0.6609\u001b[0m  0.0150\n",
      "      6        0.6596       0.6392        \u001b[35m0.6469\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6474\u001b[0m       0.6392        \u001b[35m0.6455\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.6453\u001b[0m       0.6392        0.6487  0.0250\n",
      "      9        0.6506       0.6392        0.6582  0.0240\n",
      "     10        0.6614       0.6392        0.6604  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6950\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6610\u001b[0m  0.0290\n",
      "      2        \u001b[36m0.6605\u001b[0m       0.6392        0.7458  0.0180\n",
      "      3        0.7684       0.6392        0.7701  0.0240\n",
      "      4        0.7525       0.6392        0.6712  0.0170\n",
      "      5        0.6674       0.6392        \u001b[35m0.6472\u001b[0m  0.0240\n",
      "      6        \u001b[36m0.6492\u001b[0m       0.6392        \u001b[35m0.6454\u001b[0m  0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m0.6456\u001b[0m       0.6392        0.6503  0.0187\n",
      "      8        0.6555       0.6392        0.6759  0.0210\n",
      "      9        0.6832       0.6392        0.6831  0.0226\n",
      "     10        0.6824       0.6392        0.6489  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7050\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6610\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6598\u001b[0m       0.6392        0.7417  0.0180\n",
      "      3        0.7705       0.6392        0.7729  0.0170\n",
      "      4        0.7596       0.6392        0.6723  0.0180\n",
      "      5        0.6701       0.6392        \u001b[35m0.6467\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6498\u001b[0m       0.6392        0.6470  0.0170\n",
      "      7        \u001b[36m0.6482\u001b[0m       0.6392        0.6524  0.0180\n",
      "      8        0.6570       0.6392        0.6749  0.0160\n",
      "      9        0.6817       0.6392        0.6888  0.0170\n",
      "     10        0.6897       0.6392        0.6659  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6974\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6639\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6580\u001b[0m       0.6392        0.6930  0.0150\n",
      "      3        0.7203       0.6392        0.7680  0.0160\n",
      "      4        0.7740       0.6392        0.7210  0.0190\n",
      "      5        0.7109       0.6392        \u001b[35m0.6586\u001b[0m  0.0167\n",
      "      6        \u001b[36m0.6573\u001b[0m       0.6392        \u001b[35m0.6426\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6444\u001b[0m       0.6392        \u001b[35m0.6396\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6412\u001b[0m       0.6392        0.6419  0.0160\n",
      "      9        0.6461       0.6392        0.6532  0.0200\n",
      "     10        0.6566       0.6392        0.6478  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6894\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6582\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6579\u001b[0m       0.6392        0.7084  0.0170\n",
      "      3        0.7371       0.6392        0.7579  0.0170\n",
      "      4        0.7533       0.6392        0.6791  0.0170\n",
      "      5        0.6719       0.6392        \u001b[35m0.6401\u001b[0m  0.0190\n",
      "      6        \u001b[36m0.6429\u001b[0m       0.6392        \u001b[35m0.6347\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.6361\u001b[0m       0.6392        0.6370  0.0140\n",
      "      8        0.6448       0.6392        0.6646  0.0160\n",
      "      9        0.6698       0.6392        0.6490  0.0180\n",
      "     10        0.6421       0.6392        \u001b[35m0.5913\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7104\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6634\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6621\u001b[0m       0.6392        0.7268  0.0160\n",
      "      3        0.7599       0.6392        0.7856  0.0130\n",
      "      4        0.7732       0.6392        0.6917  0.0170\n",
      "      5        0.6791       0.6392        \u001b[35m0.6497\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6487\u001b[0m       0.6392        \u001b[35m0.6471\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6467\u001b[0m       0.6392        0.6504  0.0170\n",
      "      8        0.6520       0.6392        0.6643  0.0170\n",
      "      9        0.6677       0.6392        0.6810  0.0160\n",
      "     10        0.6819       0.6392        0.6815  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6841\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6614\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6648\u001b[0m       0.6392        0.7258  0.0200\n",
      "      3        0.7460       0.6392        0.7597  0.0210\n",
      "      4        0.7460       0.6392        0.6815  0.0130\n",
      "      5        0.6708       0.6392        \u001b[35m0.6417\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6415\u001b[0m       0.6392        \u001b[35m0.6337\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6348\u001b[0m       0.6392        0.6338  0.0190\n",
      "      8        0.6396       0.6392        0.6502  0.0190\n",
      "      9        0.6566       0.6392        0.6454  0.0190\n",
      "     10        0.6414       0.6392        \u001b[35m0.5964\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6985\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0250\n",
      "      2        \u001b[36m0.6572\u001b[0m       0.6392        0.7042  0.0130\n",
      "      3        0.7286       0.6392        0.7620  0.0167\n",
      "      4        0.7530       0.6392        0.6839  0.0160\n",
      "      5        0.6677       0.6392        \u001b[35m0.6299\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6264\u001b[0m       0.6392        \u001b[35m0.6200\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6147\u001b[0m       0.6392        \u001b[35m0.6169\u001b[0m  0.0170\n",
      "      8        0.6177       0.6392        0.6343  0.0170\n",
      "      9        0.6272       0.6392        \u001b[35m0.5942\u001b[0m  0.0130\n",
      "     10        \u001b[36m0.5733\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5631\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6732\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6617\u001b[0m  0.0219\n",
      "      2        \u001b[36m0.6627\u001b[0m       0.6392        0.7194  0.0190\n",
      "      3        0.7186       0.6392        0.7062  0.0210\n",
      "      4        0.6930       0.6392        0.6624  0.0180\n",
      "      5        \u001b[36m0.6575\u001b[0m       0.6392        \u001b[35m0.6516\u001b[0m  0.0200\n",
      "      6        \u001b[36m0.6486\u001b[0m       0.6392        0.6552  0.0200\n",
      "      7        0.6530       0.6392        0.6567  0.0180\n",
      "      8        0.6525       0.6392        \u001b[35m0.6426\u001b[0m  0.0220\n",
      "      9        \u001b[36m0.6384\u001b[0m       0.6392        \u001b[35m0.6278\u001b[0m  0.0205\n",
      "     10        \u001b[36m0.6253\u001b[0m       0.6392        \u001b[35m0.6187\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6727\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6590\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6627\u001b[0m       0.6392        0.7209  0.0170\n",
      "      3        0.7219       0.6392        0.7094  0.0180\n",
      "      4        0.6963       0.6392        0.6693  0.0220\n",
      "      5        \u001b[36m0.6623\u001b[0m       0.6392        0.6602  0.0230\n",
      "      6        \u001b[36m0.6540\u001b[0m       0.6392        0.6656  0.0170\n",
      "      7        0.6582       0.6392        0.6731  0.0206\n",
      "      8        0.6617       0.6392        0.6677  0.0197\n",
      "      9        \u001b[36m0.6532\u001b[0m       0.6392        \u001b[35m0.6570\u001b[0m  0.0220\n",
      "     10        \u001b[36m0.6421\u001b[0m       0.6392        \u001b[35m0.6517\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6949\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6583\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6633\u001b[0m       0.6392        0.7372  0.0190\n",
      "      3        0.7419       0.6392        0.7128  0.0310\n",
      "      4        0.7023       0.6392        0.6619  0.0210\n",
      "      5        \u001b[36m0.6611\u001b[0m       0.6392        \u001b[35m0.6502\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6517\u001b[0m       0.6392        0.6517  0.0180\n",
      "      7        0.6551       0.6392        0.6569  0.0180\n",
      "      8        0.6601       0.6392        \u001b[35m0.6501\u001b[0m  0.0210\n",
      "      9        0.6524       0.6392        \u001b[35m0.6344\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6387\u001b[0m       0.6392        \u001b[35m0.6221\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6877\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6587\u001b[0m  0.0190\n",
      "      2        \u001b[36m0.6560\u001b[0m       0.6392        0.7071  0.0150\n",
      "      3        0.7160       0.6392        0.7114  0.0210\n",
      "      4        0.7034       0.6392        0.6637  0.0190\n",
      "      5        0.6616       0.6392        \u001b[35m0.6464\u001b[0m  0.0190\n",
      "      6        \u001b[36m0.6476\u001b[0m       0.6392        \u001b[35m0.6449\u001b[0m  0.0140\n",
      "      7        0.6479       0.6392        0.6482  0.0190\n",
      "      8        0.6510       0.6392        \u001b[35m0.6394\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.6416\u001b[0m       0.6392        \u001b[35m0.6215\u001b[0m  0.0232\n",
      "     10        \u001b[36m0.6264\u001b[0m       0.6392        \u001b[35m0.6078\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6872\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6581\u001b[0m  0.0180\n",
      "      2        \u001b[36m0.6683\u001b[0m       0.6392        0.7316  0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        0.7408       0.6392        0.6934  0.0210\n",
      "      4        0.6914       0.6392        \u001b[35m0.6529\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6580\u001b[0m       0.6392        \u001b[35m0.6472\u001b[0m  0.0200\n",
      "      6        \u001b[36m0.6543\u001b[0m       0.6392        0.6541  0.0200\n",
      "      7        0.6644       0.6392        0.6559  0.0210\n",
      "      8        0.6649       0.6392        \u001b[35m0.6409\u001b[0m  0.0207\n",
      "      9        \u001b[36m0.6506\u001b[0m       0.6392        \u001b[35m0.6280\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.6404\u001b[0m       0.6392        \u001b[35m0.6221\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7099\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6622\u001b[0m  0.0180\n",
      "      2        \u001b[36m0.6719\u001b[0m       0.6392        0.7374  0.0300\n",
      "      3        0.7476       0.6392        0.7036  0.0170\n",
      "      4        0.6970       0.6392        \u001b[35m0.6537\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6570\u001b[0m       0.6392        \u001b[35m0.6423\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6488\u001b[0m       0.6392        0.6430  0.0200\n",
      "      7        0.6528       0.6392        0.6424  0.0210\n",
      "      8        0.6517       0.6392        \u001b[35m0.6248\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.6361\u001b[0m       0.6392        \u001b[35m0.6075\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.6231\u001b[0m       0.6392        \u001b[35m0.5959\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6866\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6612\u001b[0m  0.0190\n",
      "      2        \u001b[36m0.6660\u001b[0m       0.6392        0.7112  0.0200\n",
      "      3        0.7261       0.6392        0.7067  0.0190\n",
      "      4        0.7034       0.6392        0.6613  0.0150\n",
      "      5        \u001b[36m0.6628\u001b[0m       0.6392        \u001b[35m0.6464\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6504\u001b[0m       0.6392        \u001b[35m0.6443\u001b[0m  0.0190\n",
      "      7        0.6504       0.6392        \u001b[35m0.6437\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.6494\u001b[0m       0.6392        \u001b[35m0.6305\u001b[0m  0.0210\n",
      "      9        \u001b[36m0.6351\u001b[0m       0.6392        \u001b[35m0.6121\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6185\u001b[0m       0.6392        \u001b[35m0.5982\u001b[0m  0.0230\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6867\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6585\u001b[0m  0.0171\n",
      "      2        \u001b[36m0.6676\u001b[0m       0.6392        0.7215  0.0170\n",
      "      3        0.7273       0.6392        0.6893  0.0180\n",
      "      4        0.6784       0.6392        \u001b[35m0.6421\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6393\u001b[0m       0.6392        \u001b[35m0.6300\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6298\u001b[0m       0.6392        0.6313  0.0170\n",
      "      7        0.6323       0.6392        \u001b[35m0.6235\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.6194\u001b[0m       0.6392        \u001b[35m0.5982\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.5941\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5806\u001b[0m  0.0204\n",
      "     10        \u001b[36m0.5785\u001b[0m       0.6701        \u001b[35m0.5689\u001b[0m  0.0147\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6883\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6571\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6655\u001b[0m       0.6392        0.7187  0.0200\n",
      "      3        0.7305       0.6392        0.7003  0.0210\n",
      "      4        0.6932       0.6392        \u001b[35m0.6545\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6554\u001b[0m       0.6392        \u001b[35m0.6443\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6484\u001b[0m       0.6392        0.6475  0.0160\n",
      "      7        0.6545       0.6392        0.6505  0.0180\n",
      "      8        0.6555       0.6392        \u001b[35m0.6364\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6399\u001b[0m       0.6392        \u001b[35m0.6195\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.6250\u001b[0m       0.6392        \u001b[35m0.6095\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6818\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6572\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6595\u001b[0m       0.6392        0.6997  0.0180\n",
      "      3        0.7105       0.6392        0.6966  0.0167\n",
      "      4        0.6873       0.6392        \u001b[35m0.6487\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6439\u001b[0m       0.6392        \u001b[35m0.6324\u001b[0m  0.0200\n",
      "      6        \u001b[36m0.6291\u001b[0m       0.6392        \u001b[35m0.6298\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.6274\u001b[0m       0.6392        \u001b[35m0.6261\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6187\u001b[0m       0.6392        \u001b[35m0.6059\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.5951\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5894\u001b[0m  0.0330\n",
      "     10        \u001b[36m0.5776\u001b[0m       0.6495        \u001b[35m0.5798\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6767\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6649\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6653\u001b[0m       0.6392        0.7343  0.0230\n",
      "      3        0.7346       0.6392        0.7207  0.0190\n",
      "      4        0.7034       0.6392        \u001b[35m0.6604\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6561\u001b[0m       0.6392        \u001b[35m0.6452\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6434\u001b[0m       0.6392        0.6462  0.0260\n",
      "      7        0.6472       0.6392        0.6561  0.0190\n",
      "      8        0.6555       0.6392        \u001b[35m0.6380\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6364\u001b[0m       0.6392        \u001b[35m0.6134\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.6163\u001b[0m       0.6392        \u001b[35m0.6027\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6754\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6555\u001b[0m  0.0210\n",
      "      2        \u001b[36m0.6555\u001b[0m       0.6392        0.7208  0.0210\n",
      "      3        0.7285       0.6392        0.7295  0.0250\n",
      "      4        0.7125       0.6392        0.6653  0.0220\n",
      "      5        0.6572       0.6392        \u001b[35m0.6441\u001b[0m  0.0227\n",
      "      6        \u001b[36m0.6394\u001b[0m       0.6392        \u001b[35m0.6418\u001b[0m  0.0240\n",
      "      7        \u001b[36m0.6370\u001b[0m       0.6392        0.6525  0.0150\n",
      "      8        0.6456       0.6392        0.6486  0.0180\n",
      "      9        \u001b[36m0.6352\u001b[0m       0.6392        \u001b[35m0.6216\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.6099\u001b[0m       0.6392        \u001b[35m0.6054\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6707\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6625\u001b[0m  0.0180\n",
      "      2        \u001b[36m0.6689\u001b[0m       0.6392        0.7270  0.0260\n",
      "      3        0.7336       0.6392        0.6957  0.0190\n",
      "      4        0.6884       0.6392        \u001b[35m0.6470\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6489\u001b[0m       0.6392        \u001b[35m0.6378\u001b[0m  0.0200\n",
      "      6        \u001b[36m0.6418\u001b[0m       0.6392        0.6473  0.0180\n",
      "      7        0.6549       0.6392        0.6432  0.0201\n",
      "      8        0.6460       0.6392        \u001b[35m0.6104\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.6183\u001b[0m       0.6392        \u001b[35m0.5941\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.6071\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5855\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6807\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6555\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6581\u001b[0m       0.6392        0.7277  0.0241\n",
      "      3        0.7383       0.6392        0.7196  0.0210\n",
      "      4        0.7074       0.6392        \u001b[35m0.6536\u001b[0m  0.0179\n",
      "      5        \u001b[36m0.6519\u001b[0m       0.6392        \u001b[35m0.6342\u001b[0m  0.0220\n",
      "      6        \u001b[36m0.6353\u001b[0m       0.6392        \u001b[35m0.6304\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6336\u001b[0m       0.6392        0.6423  0.0180\n",
      "      8        0.6449       0.6392        \u001b[35m0.6295\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.6273\u001b[0m       0.6392        \u001b[35m0.5927\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.5983\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5746\u001b[0m  0.0300\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6763\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6568\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6602\u001b[0m       0.6392        0.7141  0.0187\n",
      "      3        0.7276       0.6392        0.7150  0.0210\n",
      "      4        0.7093       0.6392        \u001b[35m0.6563\u001b[0m  0.0210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        \u001b[36m0.6591\u001b[0m       0.6392        \u001b[35m0.6365\u001b[0m  0.0244\n",
      "      6        \u001b[36m0.6423\u001b[0m       0.6392        \u001b[35m0.6312\u001b[0m  0.0350\n",
      "      7        \u001b[36m0.6412\u001b[0m       0.6392        0.6370  0.0190\n",
      "      8        0.6494       0.6392        \u001b[35m0.6201\u001b[0m  0.0340\n",
      "      9        \u001b[36m0.6323\u001b[0m       0.6392        \u001b[35m0.5895\u001b[0m  0.0219\n",
      "     10        \u001b[36m0.6082\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5721\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6818\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6611\u001b[0m  0.0200\n",
      "      2        \u001b[36m0.6658\u001b[0m       0.6392        0.7198  0.0220\n",
      "      3        0.7378       0.6392        0.7183  0.0207\n",
      "      4        0.7120       0.6392        0.6633  0.0337\n",
      "      5        \u001b[36m0.6623\u001b[0m       0.6392        \u001b[35m0.6466\u001b[0m  0.0200\n",
      "      6        \u001b[36m0.6481\u001b[0m       0.6392        \u001b[35m0.6443\u001b[0m  0.0272\n",
      "      7        \u001b[36m0.6477\u001b[0m       0.6392        0.6515  0.0290\n",
      "      8        0.6559       0.6392        0.6499  0.0260\n",
      "      9        0.6499       0.6392        \u001b[35m0.6274\u001b[0m  0.0280\n",
      "     10        \u001b[36m0.6285\u001b[0m       0.6392        \u001b[35m0.6093\u001b[0m  0.0250\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6788\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6589\u001b[0m  0.0290\n",
      "      2        \u001b[36m0.6625\u001b[0m       0.6392        0.7085  0.0200\n",
      "      3        0.7263       0.6392        0.7162  0.0200\n",
      "      4        0.7100       0.6392        \u001b[35m0.6567\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6546\u001b[0m       0.6392        \u001b[35m0.6342\u001b[0m  0.0200\n",
      "      6        \u001b[36m0.6355\u001b[0m       0.6392        \u001b[35m0.6289\u001b[0m  0.0258\n",
      "      7        \u001b[36m0.6335\u001b[0m       0.6392        0.6356  0.0230\n",
      "      8        0.6402       0.6392        \u001b[35m0.6189\u001b[0m  0.0220\n",
      "      9        \u001b[36m0.6189\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5863\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.5908\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5686\u001b[0m  0.0230\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6957\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6733\u001b[0m       0.6392        0.7453  0.0210\n",
      "      3        0.7555       0.6392        0.7100  0.0220\n",
      "      4        0.6955       0.6392        \u001b[35m0.6480\u001b[0m  0.0290\n",
      "      5        \u001b[36m0.6457\u001b[0m       0.6392        \u001b[35m0.6354\u001b[0m  0.0230\n",
      "      6        \u001b[36m0.6349\u001b[0m       0.6392        \u001b[35m0.6346\u001b[0m  0.0230\n",
      "      7        0.6387       0.6392        0.6461  0.0280\n",
      "      8        0.6486       0.6392        \u001b[35m0.6308\u001b[0m  0.0230\n",
      "      9        \u001b[36m0.6265\u001b[0m       0.6392        \u001b[35m0.5974\u001b[0m  0.0211\n",
      "     10        \u001b[36m0.5969\u001b[0m       0.6392        \u001b[35m0.5796\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6828\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6582\u001b[0m  0.0220\n",
      "      2        \u001b[36m0.6663\u001b[0m       0.6392        0.7311  0.0280\n",
      "      3        0.7412       0.6392        0.7072  0.0330\n",
      "      4        0.6948       0.6392        \u001b[35m0.6492\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.6487\u001b[0m       0.6392        \u001b[35m0.6357\u001b[0m  0.0370\n",
      "      6        \u001b[36m0.6384\u001b[0m       0.6392        \u001b[35m0.6356\u001b[0m  0.0240\n",
      "      7        0.6434       0.6392        0.6443  0.0170\n",
      "      8        0.6501       0.6392        \u001b[35m0.6231\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.6256\u001b[0m       0.6392        \u001b[35m0.5913\u001b[0m  0.0231\n",
      "     10        \u001b[36m0.6002\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5769\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6838\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6575\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6606\u001b[0m       0.6392        0.7050  0.0190\n",
      "      3        0.7217       0.6392        0.7160  0.0200\n",
      "      4        0.7058       0.6392        \u001b[35m0.6554\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6477\u001b[0m       0.6392        \u001b[35m0.6319\u001b[0m  0.0190\n",
      "      6        \u001b[36m0.6264\u001b[0m       0.6392        \u001b[35m0.6251\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.6204\u001b[0m       0.6392        0.6301  0.0160\n",
      "      8        0.6229       0.6392        \u001b[35m0.6145\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5959\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5842\u001b[0m  0.0177\n",
      "     10        \u001b[36m0.5639\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5727\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6811\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6584\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6645\u001b[0m       0.6392        0.7571  0.0170\n",
      "      3        0.7658       0.6392        0.7249  0.0190\n",
      "      4        0.7052       0.6392        \u001b[35m0.6477\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6483\u001b[0m       0.6392        \u001b[35m0.6392\u001b[0m  0.0220\n",
      "      6        \u001b[36m0.6371\u001b[0m       0.6392        0.6429  0.0190\n",
      "      7        0.6504       0.6392        0.6661  0.0190\n",
      "      8        0.6689       0.6392        \u001b[35m0.6193\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6247\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5947\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.6008\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5739\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6928\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6621\u001b[0m  0.0200\n",
      "      2        \u001b[36m0.6589\u001b[0m       0.6392        0.7403  0.0180\n",
      "      3        0.7536       0.6392        0.7770  0.0180\n",
      "      4        0.7501       0.6392        0.6821  0.0200\n",
      "      5        0.6682       0.6392        \u001b[35m0.6499\u001b[0m  0.0190\n",
      "      6        \u001b[36m0.6462\u001b[0m       0.6392        \u001b[35m0.6466\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.6419\u001b[0m       0.6392        0.6564  0.0180\n",
      "      8        0.6535       0.6392        0.6832  0.0190\n",
      "      9        0.6715       0.6392        0.6647  0.0170\n",
      "     10        0.6434       0.6392        \u001b[35m0.6173\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6842\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6575\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6676\u001b[0m       0.6392        0.7703  0.0210\n",
      "      3        0.7774       0.6392        0.7263  0.0170\n",
      "      4        0.7067       0.6392        \u001b[35m0.6452\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6473\u001b[0m       0.6392        \u001b[35m0.6344\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6357\u001b[0m       0.6392        \u001b[35m0.6320\u001b[0m  0.0170\n",
      "      7        0.6389       0.6392        0.6552  0.0170\n",
      "      8        0.6629       0.6392        \u001b[35m0.6313\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6321\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5746\u001b[0m  0.0230\n",
      "     10        \u001b[36m0.5929\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5455\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6838\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6624\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6667\u001b[0m       0.6392        0.7471  0.0300\n",
      "      3        0.7630       0.6392        0.7336  0.0190\n",
      "      4        0.7191       0.6392        \u001b[35m0.6540\u001b[0m  0.0207\n",
      "      5        \u001b[36m0.6535\u001b[0m       0.6392        \u001b[35m0.6404\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6409\u001b[0m       0.6392        0.6406  0.0170\n",
      "      7        0.6445       0.6392        0.6622  0.0190\n",
      "      8        0.6681       0.6392        0.6608  0.0200\n",
      "      9        0.6557       0.6392        \u001b[35m0.6080\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6098\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5757\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7006\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6609\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6637\u001b[0m       0.6392        0.7551  0.0210\n",
      "      3        0.7765       0.6392        0.7500  0.0180\n",
      "      4        0.7330       0.6392        \u001b[35m0.6528\u001b[0m  0.0210\n",
      "      5        \u001b[36m0.6539\u001b[0m       0.6392        \u001b[35m0.6384\u001b[0m  0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m0.6397\u001b[0m       0.6392        \u001b[35m0.6344\u001b[0m  0.0219\n",
      "      7        \u001b[36m0.6383\u001b[0m       0.6392        0.6532  0.0190\n",
      "      8        0.6621       0.6392        0.6555  0.0190\n",
      "      9        0.6530       0.6392        \u001b[35m0.5954\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.6009\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5606\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6839\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6641\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6687\u001b[0m       0.6392        0.7321  0.0160\n",
      "      3        0.7533       0.6392        0.7388  0.0190\n",
      "      4        0.7252       0.6392        \u001b[35m0.6576\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6568\u001b[0m       0.6392        \u001b[35m0.6398\u001b[0m  0.0190\n",
      "      6        \u001b[36m0.6431\u001b[0m       0.6392        \u001b[35m0.6350\u001b[0m  0.0177\n",
      "      7        \u001b[36m0.6419\u001b[0m       0.6392        0.6532  0.0220\n",
      "      8        0.6653       0.6392        0.6534  0.0180\n",
      "      9        0.6535       0.6392        \u001b[35m0.5988\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6109\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5721\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6723\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6575\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6673\u001b[0m       0.6392        0.7400  0.0159\n",
      "      3        0.7546       0.6392        0.7078  0.0180\n",
      "      4        0.6907       0.6392        \u001b[35m0.6307\u001b[0m  0.0310\n",
      "      5        \u001b[36m0.6314\u001b[0m       0.6392        \u001b[35m0.6154\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6139\u001b[0m       0.6392        0.6227  0.0178\n",
      "      7        0.6321       0.6392        0.6271  0.0180\n",
      "      8        0.6144       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5516\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.5581\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5189\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.5379\u001b[0m       0.7320        \u001b[35m0.5129\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7029\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6623\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6649\u001b[0m       0.6392        0.7364  0.0190\n",
      "      3        0.7631       0.6392        0.7579  0.0170\n",
      "      4        0.7394       0.6392        \u001b[35m0.6621\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6547\u001b[0m       0.6392        \u001b[35m0.6398\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6391\u001b[0m       0.6392        \u001b[35m0.6372\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.6369\u001b[0m       0.6392        0.6450  0.0160\n",
      "      8        0.6485       0.6392        0.6577  0.0170\n",
      "      9        0.6541       0.6392        \u001b[35m0.6250\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.6111\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5731\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6914\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6603\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6766\u001b[0m       0.6392        0.7754  0.0171\n",
      "      3        0.7894       0.6392        0.7250  0.0180\n",
      "      4        0.7031       0.6392        \u001b[35m0.6441\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6451\u001b[0m       0.6392        \u001b[35m0.6383\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6378\u001b[0m       0.6392        \u001b[35m0.6363\u001b[0m  0.0180\n",
      "      7        0.6422       0.6392        0.6620  0.0190\n",
      "      8        0.6708       0.6392        0.6584  0.0180\n",
      "      9        0.6498       0.6392        \u001b[35m0.5956\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5929\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5592\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6910\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6628\u001b[0m  0.0200\n",
      "      2        \u001b[36m0.6819\u001b[0m       0.6392        0.7694  0.0150\n",
      "      3        0.7774       0.6392        0.7033  0.0200\n",
      "      4        \u001b[36m0.6802\u001b[0m       0.6392        \u001b[35m0.6344\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6284\u001b[0m       0.6392        \u001b[35m0.6218\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.6129\u001b[0m       0.6392        0.6364  0.0190\n",
      "      7        0.6368       0.6392        0.6397  0.0210\n",
      "      8        \u001b[36m0.6079\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5715\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.5494\u001b[0m       0.6804        \u001b[35m0.5572\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.5352\u001b[0m       0.6804        0.5807  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6985\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6586\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6553\u001b[0m       0.6392        0.7160  0.0110\n",
      "      3        0.7243       0.6392        0.7233  0.0160\n",
      "      4        0.7126       0.6392        0.6717  0.0259\n",
      "      5        0.6685       0.6392        \u001b[35m0.6535\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6542\u001b[0m       0.6392        \u001b[35m0.6530\u001b[0m  0.0170\n",
      "      7        0.6553       0.6392        0.6597  0.0140\n",
      "      8        0.6625       0.6392        0.6579  0.0150\n",
      "      9        0.6601       0.6392        \u001b[35m0.6450\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.6493\u001b[0m       0.6392        \u001b[35m0.6340\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6766\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6575\u001b[0m  0.0183\n",
      "      2        \u001b[36m0.6518\u001b[0m       0.6392        0.6899  0.0150\n",
      "      3        0.6963       0.6392        0.7143  0.0170\n",
      "      4        0.7075       0.6392        0.6823  0.0140\n",
      "      5        0.6757       0.6392        0.6596  0.0150\n",
      "      6        0.6567       0.6392        \u001b[35m0.6533\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6512\u001b[0m       0.6392        0.6548  0.0170\n",
      "      8        0.6523       0.6392        0.6545  0.0140\n",
      "      9        \u001b[36m0.6500\u001b[0m       0.6392        \u001b[35m0.6456\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6401\u001b[0m       0.6392        \u001b[35m0.6349\u001b[0m  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7028\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6596\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6496\u001b[0m       0.6392        0.6864  0.0130\n",
      "      3        0.6972       0.6392        0.7260  0.0160\n",
      "      4        0.7215       0.6392        0.6923  0.0167\n",
      "      5        0.6864       0.6392        0.6639  0.0160\n",
      "      6        0.6630       0.6392        \u001b[35m0.6562\u001b[0m  0.0180\n",
      "      7        0.6571       0.6392        0.6581  0.0130\n",
      "      8        0.6600       0.6392        0.6619  0.0160\n",
      "      9        0.6635       0.6392        \u001b[35m0.6556\u001b[0m  0.0250\n",
      "     10        0.6568       0.6392        \u001b[35m0.6414\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6783\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6591\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6615\u001b[0m       0.6392        0.7155  0.0176\n",
      "      3        0.7249       0.6392        0.7132  0.0170\n",
      "      4        0.7080       0.6392        0.6725  0.0120\n",
      "      5        0.6723       0.6392        0.6605  0.0150\n",
      "      6        0.6625       0.6392        0.6623  0.0150\n",
      "      7        0.6654       0.6392        0.6688  0.0170\n",
      "      8        0.6720       0.6392        0.6701  0.0140\n",
      "      9        0.6723       0.6392        0.6638  0.0120\n",
      "     10        0.6658       0.6392        \u001b[35m0.6557\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6666\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6592\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6652\u001b[0m       0.6392        0.7171  0.0150\n",
      "      3        0.7195       0.6392        0.6904  0.0160\n",
      "      4        0.6853       0.6392        \u001b[35m0.6583\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.6590\u001b[0m       0.6392        \u001b[35m0.6543\u001b[0m  0.0155\n",
      "      6        \u001b[36m0.6567\u001b[0m       0.6392        0.6620  0.0130\n",
      "      7        0.6648       0.6392        0.6636  0.0150\n",
      "      8        0.6643       0.6392        \u001b[35m0.6520\u001b[0m  0.0250\n",
      "      9        \u001b[36m0.6530\u001b[0m       0.6392        \u001b[35m0.6419\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6449\u001b[0m       0.6392        \u001b[35m0.6387\u001b[0m  0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6651\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6525\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6639\u001b[0m       0.6392        0.7119  0.0180\n",
      "      3        0.7218       0.6392        0.6901  0.0130\n",
      "      4        0.6858       0.6392        \u001b[35m0.6514\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6525\u001b[0m       0.6392        \u001b[35m0.6435\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6470\u001b[0m       0.6392        0.6493  0.0149\n",
      "      7        0.6538       0.6392        0.6487  0.0140\n",
      "      8        0.6493       0.6392        \u001b[35m0.6296\u001b[0m  0.0149\n",
      "      9        \u001b[36m0.6303\u001b[0m       0.6392        \u001b[35m0.6130\u001b[0m  0.0140\n",
      "     10        \u001b[36m0.6170\u001b[0m       0.6392        \u001b[35m0.6042\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6911\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6598\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6635\u001b[0m       0.6392        0.7148  0.0150\n",
      "      3        0.7289       0.6392        0.7122  0.0170\n",
      "      4        0.7064       0.6392        0.6668  0.0150\n",
      "      5        0.6664       0.6392        \u001b[35m0.6532\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6553\u001b[0m       0.6392        \u001b[35m0.6531\u001b[0m  0.0140\n",
      "      7        0.6567       0.6392        0.6576  0.0150\n",
      "      8        0.6602       0.6392        \u001b[35m0.6510\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6512\u001b[0m       0.6392        \u001b[35m0.6350\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6375\u001b[0m       0.6392        \u001b[35m0.6259\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6870\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6552\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6553\u001b[0m       0.6392        0.6904  0.0140\n",
      "      3        0.7038       0.6392        0.7143  0.0130\n",
      "      4        0.7098       0.6392        0.6786  0.0160\n",
      "      5        0.6738       0.6392        0.6560  0.0150\n",
      "      6        0.6554       0.6392        \u001b[35m0.6507\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6516\u001b[0m       0.6392        0.6525  0.0170\n",
      "      8        0.6542       0.6392        0.6543  0.0170\n",
      "      9        0.6546       0.6392        \u001b[35m0.6474\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.6460\u001b[0m       0.6392        \u001b[35m0.6356\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6745\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6558\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6571\u001b[0m       0.6392        0.6879  0.0170\n",
      "      3        0.6987       0.6392        0.7086  0.0180\n",
      "      4        0.7059       0.6392        0.6810  0.0130\n",
      "      5        0.6770       0.6392        0.6600  0.0150\n",
      "      6        0.6594       0.6392        \u001b[35m0.6539\u001b[0m  0.0210\n",
      "      7        \u001b[36m0.6552\u001b[0m       0.6392        0.6553  0.0100\n",
      "      8        0.6573       0.6392        0.6571  0.0170\n",
      "      9        0.6583       0.6392        \u001b[35m0.6530\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6533\u001b[0m       0.6392        \u001b[35m0.6449\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6803\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6506\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6575\u001b[0m       0.6392        0.7101  0.0140\n",
      "      3        0.7155       0.6392        0.6922  0.0160\n",
      "      4        0.6789       0.6392        \u001b[35m0.6443\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6385\u001b[0m       0.6392        \u001b[35m0.6314\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6272\u001b[0m       0.6392        0.6337  0.0176\n",
      "      7        0.6282       0.6392        \u001b[35m0.6222\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6078\u001b[0m       0.6392        \u001b[35m0.5925\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.5775\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5789\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5594\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5571\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6999\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6589\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6726\u001b[0m       0.6392        0.7802  0.0260\n",
      "      3        0.7749       0.6392        0.7040  0.0140\n",
      "      4        0.6895       0.6392        \u001b[35m0.6518\u001b[0m  0.0140\n",
      "      5        \u001b[36m0.6512\u001b[0m       0.6392        \u001b[35m0.6495\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6492\u001b[0m       0.6392        0.6636  0.0160\n",
      "      7        0.6659       0.6392        0.6811  0.0150\n",
      "      8        0.6798       0.6392        0.6735  0.0160\n",
      "      9        0.6690       0.6392        0.6542  0.0150\n",
      "     10        0.6510       0.6392        \u001b[35m0.6437\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6780\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6550\u001b[0m  0.0149\n",
      "      2        \u001b[36m0.6567\u001b[0m       0.6392        0.7301  0.0130\n",
      "      3        0.7374       0.6392        0.7267  0.0140\n",
      "      4        0.7105       0.6392        0.6640  0.0150\n",
      "      5        0.6587       0.6392        \u001b[35m0.6484\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6457\u001b[0m       0.6392        0.6509  0.0130\n",
      "      7        0.6485       0.6392        0.6642  0.0140\n",
      "      8        0.6595       0.6392        0.6608  0.0170\n",
      "      9        0.6495       0.6392        \u001b[35m0.6330\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6232\u001b[0m       0.6392        \u001b[35m0.6173\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6788\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6530\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6555\u001b[0m       0.6392        0.7365  0.0180\n",
      "      3        0.7451       0.6392        0.7287  0.0120\n",
      "      4        0.7111       0.6392        0.6577  0.0140\n",
      "      5        \u001b[36m0.6552\u001b[0m       0.6392        \u001b[35m0.6419\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6421\u001b[0m       0.6392        0.6431  0.0150\n",
      "      7        0.6458       0.6392        0.6583  0.0140\n",
      "      8        0.6588       0.6392        0.6428  0.0220\n",
      "      9        \u001b[36m0.6404\u001b[0m       0.6392        \u001b[35m0.6120\u001b[0m  0.0231\n",
      "     10        \u001b[36m0.6160\u001b[0m       0.6392        \u001b[35m0.5976\u001b[0m  0.0250\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6699\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6555\u001b[0m  0.0310\n",
      "      2        \u001b[36m0.6571\u001b[0m       0.6392        0.7162  0.0181\n",
      "      3        0.7254       0.6392        0.7214  0.0200\n",
      "      4        0.7097       0.6392        0.6660  0.0150\n",
      "      5        0.6617       0.6392        \u001b[35m0.6489\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6483\u001b[0m       0.6392        0.6520  0.0162\n",
      "      7        0.6539       0.6392        0.6662  0.0150\n",
      "      8        0.6667       0.6392        0.6566  0.0160\n",
      "      9        0.6527       0.6392        \u001b[35m0.6281\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6281\u001b[0m       0.6392        \u001b[35m0.6147\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6720\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6557\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6545\u001b[0m       0.6392        0.7106  0.0130\n",
      "      3        0.7201       0.6392        0.7274  0.0140\n",
      "      4        0.7171       0.6392        0.6743  0.0157\n",
      "      5        0.6693       0.6392        \u001b[35m0.6521\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6513\u001b[0m       0.6392        \u001b[35m0.6518\u001b[0m  0.0120\n",
      "      7        0.6524       0.6392        0.6623  0.0140\n",
      "      8        0.6639       0.6392        0.6683  0.0120\n",
      "      9        0.6674       0.6392        0.6571  0.0190\n",
      "     10        0.6548       0.6392        \u001b[35m0.6398\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6655\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6531\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6619\u001b[0m       0.6392        0.7086  0.0140\n",
      "      3        0.7233       0.6392        0.7108  0.0150\n",
      "      4        0.7066       0.6392        0.6658  0.0160\n",
      "      5        0.6658       0.6392        \u001b[35m0.6505\u001b[0m  0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m0.6534\u001b[0m       0.6392        0.6508  0.0140\n",
      "      7        0.6556       0.6392        0.6599  0.0150\n",
      "      8        0.6658       0.6392        0.6629  0.0210\n",
      "      9        0.6660       0.6392        \u001b[35m0.6474\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6506\u001b[0m       0.6392        \u001b[35m0.6311\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6895\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6508\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6555\u001b[0m       0.6392        0.7211  0.0180\n",
      "      3        0.7416       0.6392        0.7178  0.0160\n",
      "      4        0.7064       0.6392        0.6520  0.0160\n",
      "      5        \u001b[36m0.6520\u001b[0m       0.6392        \u001b[35m0.6388\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6408\u001b[0m       0.6392        \u001b[35m0.6366\u001b[0m  0.0170\n",
      "      7        0.6443       0.6392        0.6416  0.0160\n",
      "      8        0.6436       0.6392        \u001b[35m0.5927\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.5993\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5596\u001b[0m  0.0167\n",
      "     10        \u001b[36m0.5785\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5402\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6675\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6540\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6552\u001b[0m       0.6392        0.6869  0.0150\n",
      "      3        0.7004       0.6392        0.7151  0.0180\n",
      "      4        0.7100       0.6392        0.6761  0.0170\n",
      "      5        0.6676       0.6392        \u001b[35m0.6471\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6437\u001b[0m       0.6392        \u001b[35m0.6401\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6376\u001b[0m       0.6392        0.6452  0.0170\n",
      "      8        0.6433       0.6392        0.6403  0.0160\n",
      "      9        \u001b[36m0.6296\u001b[0m       0.6392        \u001b[35m0.6052\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5965\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5874\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6911\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6626\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6740\u001b[0m       0.6392        0.7561  0.0144\n",
      "      3        0.7591       0.6392        0.7157  0.0190\n",
      "      4        0.6990       0.6392        \u001b[35m0.6579\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6557\u001b[0m       0.6392        \u001b[35m0.6486\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6494\u001b[0m       0.6392        0.6528  0.0130\n",
      "      7        0.6562       0.6392        0.6646  0.0170\n",
      "      8        0.6666       0.6392        0.6618  0.0140\n",
      "      9        0.6588       0.6392        \u001b[35m0.6407\u001b[0m  0.0140\n",
      "     10        \u001b[36m0.6391\u001b[0m       0.6392        \u001b[35m0.6252\u001b[0m  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6869\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6594\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6609\u001b[0m       0.6392        0.7153  0.0130\n",
      "      3        0.7313       0.6392        0.7275  0.0140\n",
      "      4        0.7143       0.6392        0.6643  0.0140\n",
      "      5        \u001b[36m0.6568\u001b[0m       0.6392        \u001b[35m0.6428\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6397\u001b[0m       0.6392        \u001b[35m0.6384\u001b[0m  0.0130\n",
      "      7        \u001b[36m0.6370\u001b[0m       0.6392        0.6459  0.0150\n",
      "      8        0.6413       0.6392        \u001b[35m0.6255\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6117\u001b[0m       0.6392        \u001b[35m0.5920\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5781\u001b[0m       0.6392        \u001b[35m0.5748\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6861\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6576\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6605\u001b[0m       0.6392        0.7645  0.0150\n",
      "      3        0.7757       0.6392        0.7557  0.0130\n",
      "      4        0.7329       0.6392        0.6659  0.0160\n",
      "      5        0.6625       0.6392        \u001b[35m0.6513\u001b[0m  0.0152\n",
      "      6        \u001b[36m0.6521\u001b[0m       0.6392        0.6540  0.0170\n",
      "      7        0.6552       0.6392        0.6636  0.0160\n",
      "      8        0.6668       0.6392        0.6694  0.0270\n",
      "      9        0.6703       0.6392        \u001b[35m0.6474\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.6461\u001b[0m       0.6392        \u001b[35m0.6110\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6736\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6589\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6654\u001b[0m       0.6392        0.7492  0.0160\n",
      "      3        0.7535       0.6392        0.7244  0.0160\n",
      "      4        0.7030       0.6392        \u001b[35m0.6535\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.6474\u001b[0m       0.6392        \u001b[35m0.6425\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6350\u001b[0m       0.6392        0.6593  0.0160\n",
      "      7        0.6562       0.6392        0.6872  0.0160\n",
      "      8        0.6674       0.6392        \u001b[35m0.6379\u001b[0m  0.0120\n",
      "      9        \u001b[36m0.6193\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.6182\u001b[0m  0.0197\n",
      "     10        \u001b[36m0.5971\u001b[0m       0.6289        0.6613  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7014\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6574\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6640\u001b[0m       0.6392        0.7881  0.0150\n",
      "      3        0.8035       0.6392        0.7563  0.0180\n",
      "      4        0.7319       0.6392        0.6576  0.0150\n",
      "      5        \u001b[36m0.6575\u001b[0m       0.6392        \u001b[35m0.6506\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6506\u001b[0m       0.6392        0.6526  0.0170\n",
      "      7        0.6558       0.6392        0.6719  0.0160\n",
      "      8        0.6788       0.6392        0.6810  0.0170\n",
      "      9        0.6822       0.6392        \u001b[35m0.6427\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.6442\u001b[0m       0.6392        \u001b[35m0.6049\u001b[0m  0.0147\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7102\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6555\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6523\u001b[0m       0.6392        0.7438  0.0180\n",
      "      3        0.7725       0.6392        0.7952  0.0140\n",
      "      4        0.7787       0.6392        0.6974  0.0240\n",
      "      5        0.6881       0.6392        0.6620  0.0170\n",
      "      6        0.6606       0.6392        \u001b[35m0.6552\u001b[0m  0.0170\n",
      "      7        0.6547       0.6392        0.6566  0.0160\n",
      "      8        0.6576       0.6392        0.6687  0.0141\n",
      "      9        0.6717       0.6392        0.6781  0.0160\n",
      "     10        0.6771       0.6392        \u001b[35m0.6528\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6996\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6563\u001b[0m  0.0137\n",
      "      2        \u001b[36m0.6594\u001b[0m       0.6392        0.7626  0.0150\n",
      "      3        0.7843       0.6392        0.7464  0.0150\n",
      "      4        0.7291       0.6392        0.6600  0.0160\n",
      "      5        \u001b[36m0.6594\u001b[0m       0.6392        \u001b[35m0.6477\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6479\u001b[0m       0.6392        0.6517  0.0130\n",
      "      7        0.6542       0.6392        0.6633  0.0150\n",
      "      8        0.6653       0.6392        0.6488  0.0140\n",
      "      9        \u001b[36m0.6466\u001b[0m       0.6392        \u001b[35m0.6085\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.6109\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5799\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6794\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6588\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6733\u001b[0m       0.6392        0.7594  0.0130\n",
      "      3        0.7748       0.6392        0.7072  0.0140\n",
      "      4        0.6945       0.6392        \u001b[35m0.6455\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6485\u001b[0m       0.6392        \u001b[35m0.6420\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6456\u001b[0m       0.6392        0.6583  0.0180\n",
      "      7        0.6695       0.6392        0.6841  0.0320\n",
      "      8        0.6840       0.6392        \u001b[35m0.6360\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.6325\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5886\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5984\u001b[0m       0.6495        0.5933  0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6928\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6546\u001b[0m  0.0180\n",
      "      2        \u001b[36m0.6595\u001b[0m       0.6392        0.7391  0.0160\n",
      "      3        0.7702       0.6392        0.7751  0.0150\n",
      "      4        0.7645       0.6392        0.6911  0.0170\n",
      "      5        0.6850       0.6392        0.6589  0.0180\n",
      "      6        0.6605       0.6392        0.6561  0.0150\n",
      "      7        \u001b[36m0.6579\u001b[0m       0.6392        0.6602  0.0170\n",
      "      8        0.6642       0.6392        0.6740  0.0150\n",
      "      9        0.6800       0.6392        0.6880  0.0200\n",
      "     10        0.6921       0.6392        0.6861  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6969\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6595\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6647\u001b[0m       0.6392        0.7492  0.0110\n",
      "      3        0.7707       0.6392        0.7626  0.0150\n",
      "      4        0.7423       0.6392        0.6794  0.0150\n",
      "      5        0.6733       0.6392        \u001b[35m0.6557\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6560\u001b[0m       0.6392        \u001b[35m0.6547\u001b[0m  0.0170\n",
      "      7        0.6570       0.6392        0.6626  0.0180\n",
      "      8        0.6651       0.6392        0.6704  0.0170\n",
      "      9        0.6706       0.6392        0.6649  0.0160\n",
      "     10        0.6616       0.6392        \u001b[35m0.6465\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6631\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6588\u001b[0m  0.0090\n",
      "      2        0.6660       0.6392        0.7210  0.0140\n",
      "      3        0.7350       0.6392        0.7248  0.0150\n",
      "      4        0.7117       0.6392        0.6633  0.0160\n",
      "      5        \u001b[36m0.6593\u001b[0m       0.6392        \u001b[35m0.6467\u001b[0m  0.0130\n",
      "      6        \u001b[36m0.6472\u001b[0m       0.6392        0.6480  0.0137\n",
      "      7        0.6511       0.6392        0.6667  0.0150\n",
      "      8        0.6713       0.6392        0.6759  0.0150\n",
      "      9        0.6708       0.6392        \u001b[35m0.6446\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6387\u001b[0m       0.6392        \u001b[35m0.6122\u001b[0m  0.0120\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6828\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6587\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6698\u001b[0m       0.6392        0.7563  0.0120\n",
      "      3        0.7570       0.6392        0.6916  0.0149\n",
      "      4        \u001b[36m0.6644\u001b[0m       0.6392        \u001b[35m0.6288\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6236\u001b[0m       0.6392        \u001b[35m0.6177\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6168\u001b[0m       0.6392        0.6658  0.0120\n",
      "      7        0.6441       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5721\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.5486\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5549\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.5454\u001b[0m       0.7113        0.5645  0.0160\n",
      "     10        \u001b[36m0.5230\u001b[0m       0.7216        0.5600  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6739\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6563\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6687\u001b[0m       0.6392        0.7327  0.0160\n",
      "      3        0.7297       0.6392        0.6814  0.0190\n",
      "      4        0.6761       0.6392        \u001b[35m0.6482\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6500\u001b[0m       0.6392        \u001b[35m0.6448\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6488\u001b[0m       0.6392        0.6505  0.0170\n",
      "      7        0.6556       0.6392        \u001b[35m0.6399\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6443\u001b[0m       0.6392        \u001b[35m0.6177\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6259\u001b[0m       0.6392        \u001b[35m0.6037\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6168\u001b[0m       0.6289        \u001b[35m0.5839\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6793\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6580\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6620\u001b[0m       0.6392        0.7259  0.0150\n",
      "      3        0.7254       0.6392        0.7009  0.0160\n",
      "      4        0.6898       0.6392        0.6629  0.0170\n",
      "      5        \u001b[36m0.6588\u001b[0m       0.6392        \u001b[35m0.6551\u001b[0m  0.0167\n",
      "      6        \u001b[36m0.6521\u001b[0m       0.6392        0.6588  0.0200\n",
      "      7        0.6554       0.6392        0.6616  0.0260\n",
      "      8        0.6555       0.6392        \u001b[35m0.6526\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6446\u001b[0m       0.6392        \u001b[35m0.6400\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6317\u001b[0m       0.6392        \u001b[35m0.6287\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6923\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6588\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6613\u001b[0m       0.6392        0.7297  0.0180\n",
      "      3        0.7309       0.6392        0.7048  0.0180\n",
      "      4        0.6930       0.6392        0.6592  0.0150\n",
      "      5        \u001b[36m0.6567\u001b[0m       0.6392        \u001b[35m0.6487\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6484\u001b[0m       0.6392        0.6508  0.0180\n",
      "      7        0.6513       0.6392        0.6533  0.0170\n",
      "      8        0.6518       0.6392        \u001b[35m0.6411\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.6394\u001b[0m       0.6392        \u001b[35m0.6236\u001b[0m  0.0181\n",
      "     10        \u001b[36m0.6248\u001b[0m       0.6392        \u001b[35m0.6118\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7035\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6541\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6607\u001b[0m       0.6392        0.7439  0.0160\n",
      "      3        0.7427       0.6392        0.6887  0.0170\n",
      "      4        0.6800       0.6392        \u001b[35m0.6490\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6496\u001b[0m       0.6392        \u001b[35m0.6473\u001b[0m  0.0160\n",
      "      6        0.6505       0.6392        0.6576  0.0170\n",
      "      7        0.6593       0.6392        \u001b[35m0.6461\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6459\u001b[0m       0.6392        \u001b[35m0.6236\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6279\u001b[0m       0.6392        \u001b[35m0.6124\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.6192\u001b[0m       0.6392        \u001b[35m0.5897\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6911\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6569\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6637\u001b[0m       0.6392        0.7342  0.0180\n",
      "      3        0.7398       0.6392        0.7035  0.0310\n",
      "      4        0.6967       0.6392        0.6597  0.0180\n",
      "      5        \u001b[36m0.6611\u001b[0m       0.6392        \u001b[35m0.6518\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6546\u001b[0m       0.6392        0.6561  0.0150\n",
      "      7        0.6604       0.6392        0.6591  0.0160\n",
      "      8        0.6620       0.6392        \u001b[35m0.6463\u001b[0m  0.0290\n",
      "      9        \u001b[36m0.6488\u001b[0m       0.6392        \u001b[35m0.6292\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.6340\u001b[0m       0.6392        \u001b[35m0.6191\u001b[0m  0.0149\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6856\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6588\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6714\u001b[0m       0.6392        0.7334  0.0160\n",
      "      3        0.7385       0.6392        0.6975  0.0180\n",
      "      4        0.6910       0.6392        \u001b[35m0.6581\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6604\u001b[0m       0.6392        \u001b[35m0.6523\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6572\u001b[0m       0.6392        0.6594  0.0160\n",
      "      7        0.6658       0.6392        0.6628  0.0180\n",
      "      8        0.6666       0.6392        \u001b[35m0.6493\u001b[0m  0.0167\n",
      "      9        \u001b[36m0.6533\u001b[0m       0.6392        \u001b[35m0.6360\u001b[0m  0.0240\n",
      "     10        \u001b[36m0.6426\u001b[0m       0.6392        \u001b[35m0.6290\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6929\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6574\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6691\u001b[0m       0.6392        0.7324  0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        0.7343       0.6392        0.6791  0.0200\n",
      "      4        0.6734       0.6392        \u001b[35m0.6432\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6465\u001b[0m       0.6392        \u001b[35m0.6413\u001b[0m  0.0170\n",
      "      6        0.6483       0.6392        0.6498  0.0190\n",
      "      7        0.6550       0.6392        \u001b[35m0.6316\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.6356\u001b[0m       0.6392        \u001b[35m0.6105\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.6190\u001b[0m       0.6392        \u001b[35m0.6009\u001b[0m  0.0177\n",
      "     10        \u001b[36m0.6103\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5720\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6886\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6621\u001b[0m  0.0200\n",
      "      2        \u001b[36m0.6783\u001b[0m       0.6392        0.7381  0.0170\n",
      "      3        0.7353       0.6392        0.6753  0.0180\n",
      "      4        \u001b[36m0.6673\u001b[0m       0.6392        \u001b[35m0.6414\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.6411\u001b[0m       0.6392        \u001b[35m0.6381\u001b[0m  0.0170\n",
      "      6        0.6420       0.6392        0.6435  0.0180\n",
      "      7        0.6454       0.6392        \u001b[35m0.6237\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6208\u001b[0m       0.6392        \u001b[35m0.5976\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.5975\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5834\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5850\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5559\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6902\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6588\u001b[0m  0.0167\n",
      "      2        \u001b[36m0.6710\u001b[0m       0.6392        0.7299  0.0190\n",
      "      3        0.7341       0.6392        0.7005  0.0150\n",
      "      4        0.6913       0.6392        0.6592  0.0160\n",
      "      5        \u001b[36m0.6590\u001b[0m       0.6392        \u001b[35m0.6502\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6529\u001b[0m       0.6392        0.6528  0.0170\n",
      "      7        0.6571       0.6392        0.6552  0.0180\n",
      "      8        0.6573       0.6392        \u001b[35m0.6410\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6424\u001b[0m       0.6392        \u001b[35m0.6213\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.6261\u001b[0m       0.6392        \u001b[35m0.6071\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6913\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6590\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6843\u001b[0m       0.6392        0.7370  0.0160\n",
      "      3        0.7260       0.6392        \u001b[35m0.6544\u001b[0m  0.0180\n",
      "      4        \u001b[36m0.6463\u001b[0m       0.6392        \u001b[35m0.6287\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6240\u001b[0m       0.6392        \u001b[35m0.6282\u001b[0m  0.0170\n",
      "      6        0.6265       0.6392        \u001b[35m0.6176\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.6042\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5823\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.5681\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5683\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.5511\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5457\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.5240\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5368\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6736\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6498\u001b[0m  0.0154\n",
      "      2        \u001b[36m0.6598\u001b[0m       0.6392        0.7331  0.0220\n",
      "      3        0.7393       0.6392        0.6951  0.0130\n",
      "      4        0.6852       0.6392        \u001b[35m0.6454\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.6461\u001b[0m       0.6392        \u001b[35m0.6392\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6405\u001b[0m       0.6392        0.6514  0.0170\n",
      "      7        0.6566       0.6392        0.6414  0.0310\n",
      "      8        \u001b[36m0.6398\u001b[0m       0.6392        \u001b[35m0.5999\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6049\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5773\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5937\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5387\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6903\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6577\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6665\u001b[0m       0.6392        0.7599  0.0190\n",
      "      3        0.7568       0.6392        0.7021  0.0180\n",
      "      4        0.6856       0.6392        \u001b[35m0.6513\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6482\u001b[0m       0.6392        \u001b[35m0.6463\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6438\u001b[0m       0.6392        0.6585  0.0160\n",
      "      7        0.6562       0.6392        0.6643  0.0160\n",
      "      8        0.6519       0.6392        \u001b[35m0.6284\u001b[0m  0.0154\n",
      "      9        \u001b[36m0.6156\u001b[0m       0.6392        \u001b[35m0.6038\u001b[0m  0.0140\n",
      "     10        \u001b[36m0.5902\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5895\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6708\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6627\u001b[0m  0.0130\n",
      "      2        0.6774       0.6392        0.7550  0.0150\n",
      "      3        0.7478       0.6392        0.6779  0.0140\n",
      "      4        0.6715       0.6392        \u001b[35m0.6477\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6473\u001b[0m       0.6392        0.6493  0.0150\n",
      "      6        0.6514       0.6392        0.6666  0.0140\n",
      "      7        0.6676       0.6392        0.6578  0.0160\n",
      "      8        0.6542       0.6392        \u001b[35m0.6308\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6298\u001b[0m       0.6392        \u001b[35m0.6167\u001b[0m  0.0140\n",
      "     10        \u001b[36m0.6193\u001b[0m       0.6392        \u001b[35m0.5882\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6855\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6557\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.6552\u001b[0m       0.6392        0.7285  0.0190\n",
      "      3        0.7361       0.6392        0.7174  0.0203\n",
      "      4        0.7006       0.6392        \u001b[35m0.6497\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6465\u001b[0m       0.6392        \u001b[35m0.6337\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6327\u001b[0m       0.6392        0.6365  0.0170\n",
      "      7        0.6386       0.6392        0.6405  0.0150\n",
      "      8        0.6342       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5913\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5932\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5621\u001b[0m  0.0140\n",
      "     10        \u001b[36m0.5734\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5438\u001b[0m  0.0139\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6807\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6574\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.6647\u001b[0m       0.6392        0.7384  0.0170\n",
      "      3        0.7437       0.6392        0.7045  0.0170\n",
      "      4        0.6952       0.6392        \u001b[35m0.6552\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6576\u001b[0m       0.6392        \u001b[35m0.6484\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6517\u001b[0m       0.6392        0.6574  0.0150\n",
      "      7        0.6635       0.6392        0.6646  0.0150\n",
      "      8        0.6660       0.6392        \u001b[35m0.6331\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.6378\u001b[0m       0.6392        \u001b[35m0.6059\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6176\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5966\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6711\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6654\u001b[0m  0.0127\n",
      "      2        0.6868       0.6392        0.7474  0.0160\n",
      "      3        0.7386       0.6392        \u001b[35m0.6583\u001b[0m  0.0170\n",
      "      4        \u001b[36m0.6538\u001b[0m       0.6392        \u001b[35m0.6274\u001b[0m  0.0179\n",
      "      5        \u001b[36m0.6309\u001b[0m       0.6392        \u001b[35m0.6273\u001b[0m  0.0160\n",
      "      6        0.6403       0.6392        0.6300  0.0157\n",
      "      7        0.6337       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5765\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.5919\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5543\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.5832\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5172\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.5566\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4973\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6841\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0110\n",
      "      2        0.6861       0.6392        0.7620  0.0135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        0.7627       0.6392        0.6840  0.0139\n",
      "      4        \u001b[36m0.6772\u001b[0m       0.6392        \u001b[35m0.6460\u001b[0m  0.0293\n",
      "      5        \u001b[36m0.6483\u001b[0m       0.6392        \u001b[35m0.6435\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6480\u001b[0m       0.6392        0.6553  0.0150\n",
      "      7        0.6627       0.6392        0.6541  0.0150\n",
      "      8        0.6540       0.6392        \u001b[35m0.6159\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.6182\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5887\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5971\u001b[0m       0.6495        \u001b[35m0.5711\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6877\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6554\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6691\u001b[0m       0.6392        0.7444  0.0130\n",
      "      3        0.7477       0.6392        0.6835  0.0140\n",
      "      4        0.6693       0.6392        \u001b[35m0.6360\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6325\u001b[0m       0.6392        \u001b[35m0.6298\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6296\u001b[0m       0.6392        0.6423  0.0150\n",
      "      7        0.6402       0.6392        \u001b[35m0.6147\u001b[0m  0.0211\n",
      "      8        \u001b[36m0.5993\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5657\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.5580\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5518\u001b[0m  0.0140\n",
      "     10        \u001b[36m0.5425\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5005\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6844\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6638\u001b[0m  0.0130\n",
      "      2        0.6906       0.6392        0.7590  0.0160\n",
      "      3        0.7486       0.6392        0.6684  0.0120\n",
      "      4        \u001b[36m0.6614\u001b[0m       0.6392        \u001b[35m0.6430\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.6444\u001b[0m       0.6392        0.6441  0.0160\n",
      "      6        0.6503       0.6392        0.6643  0.0130\n",
      "      7        0.6665       0.6392        \u001b[35m0.6387\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6335\u001b[0m       0.6392        \u001b[35m0.6019\u001b[0m  0.0157\n",
      "      9        \u001b[36m0.6040\u001b[0m       0.6392        \u001b[35m0.5925\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5970\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5440\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6763\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6586\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6690\u001b[0m       0.6392        0.7260  0.0150\n",
      "      3        0.7320       0.6392        0.6966  0.0133\n",
      "      4        0.6830       0.6392        \u001b[35m0.6505\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.6452\u001b[0m       0.6392        \u001b[35m0.6392\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6342\u001b[0m       0.6392        0.6436  0.0150\n",
      "      7        0.6366       0.6392        \u001b[35m0.6364\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6146\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5992\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.5727\u001b[0m       0.6598        \u001b[35m0.5942\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5597\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5815\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6783\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6568\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6664\u001b[0m       0.6392        0.7762  0.0140\n",
      "      3        0.7772       0.6392        0.7058  0.0140\n",
      "      4        0.6893       0.6392        \u001b[35m0.6448\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6467\u001b[0m       0.6392        \u001b[35m0.6436\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6442\u001b[0m       0.6392        0.6510  0.0140\n",
      "      7        0.6552       0.6392        0.6574  0.0140\n",
      "      8        0.6577       0.6392        \u001b[35m0.6126\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.6137\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5665\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5767\u001b[0m       0.7010        \u001b[35m0.5513\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6814\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6623\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.6784\u001b[0m       0.6392        0.7868  0.0170\n",
      "      3        0.7776       0.6392        0.6903  0.0320\n",
      "      4        \u001b[36m0.6754\u001b[0m       0.6392        \u001b[35m0.6433\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6419\u001b[0m       0.6392        0.6440  0.0150\n",
      "      6        0.6435       0.6392        0.6670  0.0160\n",
      "      7        0.6680       0.6392        0.6733  0.0150\n",
      "      8        0.6596       0.6392        \u001b[35m0.6165\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6074\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5915\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5849\u001b[0m       0.6598        0.6098  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6827\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6549\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6718\u001b[0m       0.6392        0.7835  0.0130\n",
      "      3        0.7849       0.6392        0.7032  0.0150\n",
      "      4        0.6888       0.6392        \u001b[35m0.6494\u001b[0m  0.0140\n",
      "      5        \u001b[36m0.6501\u001b[0m       0.6392        0.6500  0.0157\n",
      "      6        0.6502       0.6392        0.6627  0.0160\n",
      "      7        0.6655       0.6392        0.6769  0.0170\n",
      "      8        0.6744       0.6392        0.6507  0.0140\n",
      "      9        \u001b[36m0.6440\u001b[0m       0.6392        \u001b[35m0.6051\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6070\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5850\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6658\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6645\u001b[0m  0.0140\n",
      "      2        0.6763       0.6392        0.7497  0.0180\n",
      "      3        0.7440       0.6392        0.6773  0.0170\n",
      "      4        0.6696       0.6392        \u001b[35m0.6421\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.6428\u001b[0m       0.6392        0.6434  0.0170\n",
      "      6        0.6508       0.6392        0.6779  0.0170\n",
      "      7        0.6818       0.6392        \u001b[35m0.6420\u001b[0m  0.0218\n",
      "      8        \u001b[36m0.6422\u001b[0m       0.6392        \u001b[35m0.5995\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6065\u001b[0m       0.6392        \u001b[35m0.5901\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.6036\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.5107\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6964\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0160\n",
      "      2        0.7096       0.6392        0.8097  0.0130\n",
      "      3        0.7900       0.6392        \u001b[35m0.6639\u001b[0m  0.0130\n",
      "      4        \u001b[36m0.6632\u001b[0m       0.6392        \u001b[35m0.6464\u001b[0m  0.0130\n",
      "      5        \u001b[36m0.6478\u001b[0m       0.6392        0.6565  0.0140\n",
      "      6        0.6636       0.6392        0.6842  0.0150\n",
      "      7        0.6908       0.6392        0.6757  0.0150\n",
      "      8        0.6729       0.6392        \u001b[35m0.6213\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6252\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5874\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5987\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5868\u001b[0m  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6817\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6606\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6801\u001b[0m       0.6392        0.7744  0.0160\n",
      "      3        0.7772       0.6392        0.6998  0.0150\n",
      "      4        0.6863       0.6392        \u001b[35m0.6487\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6502\u001b[0m       0.6392        \u001b[35m0.6457\u001b[0m  0.0170\n",
      "      6        0.6504       0.6392        0.6675  0.0270\n",
      "      7        0.6778       0.6392        0.6803  0.0170\n",
      "      8        0.6775       0.6392        \u001b[35m0.6245\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6259\u001b[0m       0.6392        \u001b[35m0.5889\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6006\u001b[0m       \u001b[32m0.6495\u001b[0m        0.5967  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6771\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6641\u001b[0m  0.0150\n",
      "      2        0.6944       0.6392        0.7829  0.0140\n",
      "      3        0.7744       0.6392        0.6719  0.0130\n",
      "      4        \u001b[36m0.6648\u001b[0m       0.6392        \u001b[35m0.6449\u001b[0m  0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        \u001b[36m0.6466\u001b[0m       0.6392        0.6475  0.0170\n",
      "      6        0.6531       0.6392        0.6708  0.0150\n",
      "      7        0.6802       0.6392        0.6696  0.0160\n",
      "      8        0.6652       0.6392        \u001b[35m0.6140\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6141\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5755\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5855\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5590\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6690\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6604\u001b[0m  0.0120\n",
      "      2        0.6773       0.6392        0.7435  0.0150\n",
      "      3        0.7498       0.6392        0.6859  0.0148\n",
      "      4        0.6752       0.6392        \u001b[35m0.6398\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6407\u001b[0m       0.6392        \u001b[35m0.6361\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6406\u001b[0m       0.6392        0.6464  0.0170\n",
      "      7        0.6555       0.6392        \u001b[35m0.6189\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6147\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5568\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5632\u001b[0m       0.6804        \u001b[35m0.5378\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5600\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4849\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6738\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6589\u001b[0m  0.0130\n",
      "      2        0.6752       0.6392        0.7495  0.0190\n",
      "      3        0.7570       0.6392        0.6974  0.0140\n",
      "      4        0.6820       0.6392        \u001b[35m0.6456\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6453\u001b[0m       0.6392        \u001b[35m0.6434\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6451\u001b[0m       0.6392        0.6571  0.0160\n",
      "      7        0.6625       0.6392        0.6725  0.0145\n",
      "      8        0.6663       0.6392        \u001b[35m0.6313\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.6176\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5845\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5790\u001b[0m       0.6598        0.5854  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6928\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6657\u001b[0m  0.0120\n",
      "      2        0.6978       0.6392        0.7767  0.0130\n",
      "      3        0.7568       0.6392        \u001b[35m0.6523\u001b[0m  0.0120\n",
      "      4        \u001b[36m0.6410\u001b[0m       0.6392        \u001b[35m0.6306\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6202\u001b[0m       0.6392        0.6451  0.0250\n",
      "      6        0.6510       0.6392        0.6598  0.0160\n",
      "      7        0.6207       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5830\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.5494\u001b[0m       \u001b[32m0.6907\u001b[0m        0.6037  0.0167\n",
      "      9        0.5696       0.6907        0.5973  0.0160\n",
      "     10        \u001b[36m0.5349\u001b[0m       \u001b[32m0.7010\u001b[0m        0.6370  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6788\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6952\u001b[0m  0.0160\n",
      "      2        0.7154       0.6392        0.7297  0.0170\n",
      "      3        0.7079       0.6392        \u001b[35m0.6522\u001b[0m  0.0180\n",
      "      4        \u001b[36m0.6510\u001b[0m       0.6392        \u001b[35m0.6470\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6487\u001b[0m       0.6392        0.6607  0.0170\n",
      "      6        0.6600       0.6392        \u001b[35m0.6306\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.6332\u001b[0m       0.6392        \u001b[35m0.6093\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.6187\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5935\u001b[0m  0.0230\n",
      "      9        \u001b[36m0.6077\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5586\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5810\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5308\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6743\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6988\u001b[0m  0.0170\n",
      "      2        0.7219       0.6392        0.7283  0.0200\n",
      "      3        0.7047       0.6392        \u001b[35m0.6507\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.6460\u001b[0m       0.6392        \u001b[35m0.6485\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6448\u001b[0m       0.6392        0.6640  0.0200\n",
      "      6        0.6513       0.6392        \u001b[35m0.6303\u001b[0m  0.0210\n",
      "      7        \u001b[36m0.6184\u001b[0m       0.6392        \u001b[35m0.6129\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.6024\u001b[0m       0.6392        \u001b[35m0.5955\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5813\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5643\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5567\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5441\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6888\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6824\u001b[0m  0.0180\n",
      "      2        0.7140       0.6392        0.7436  0.0200\n",
      "      3        0.7245       0.6392        \u001b[35m0.6489\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.6511\u001b[0m       0.6392        \u001b[35m0.6391\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6445\u001b[0m       0.6392        0.6546  0.0210\n",
      "      6        0.6616       0.6392        \u001b[35m0.6318\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.6360\u001b[0m       0.6392        \u001b[35m0.6031\u001b[0m  0.0310\n",
      "      8        \u001b[36m0.6142\u001b[0m       0.6392        \u001b[35m0.5926\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6065\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5523\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.5735\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5268\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6700\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6922\u001b[0m  0.0150\n",
      "      2        0.7158       0.6392        0.7220  0.0170\n",
      "      3        0.7038       0.6392        \u001b[35m0.6494\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6493\u001b[0m       0.6392        \u001b[35m0.6474\u001b[0m  0.0210\n",
      "      5        0.6512       0.6392        0.6629  0.0200\n",
      "      6        0.6614       0.6392        \u001b[35m0.6316\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.6335\u001b[0m       0.6392        \u001b[35m0.6160\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.6232\u001b[0m       0.6392        \u001b[35m0.6016\u001b[0m  0.0210\n",
      "      9        \u001b[36m0.6083\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5675\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.5850\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5410\u001b[0m  0.0199\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6756\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6760\u001b[0m  0.0190\n",
      "      2        0.6963       0.6392        0.7265  0.0210\n",
      "      3        0.7139       0.6392        \u001b[35m0.6469\u001b[0m  0.0200\n",
      "      4        \u001b[36m0.6494\u001b[0m       0.6392        \u001b[35m0.6336\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6406\u001b[0m       0.6392        0.6435  0.0180\n",
      "      6        0.6506       0.6392        \u001b[35m0.6127\u001b[0m  0.0250\n",
      "      7        \u001b[36m0.6214\u001b[0m       0.6392        \u001b[35m0.5849\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6008\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5660\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.5860\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5259\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.5567\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5039\u001b[0m  0.0290\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6754\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6775\u001b[0m  0.0240\n",
      "      2        0.7060       0.6392        0.7233  0.0178\n",
      "      3        0.7132       0.6392        \u001b[35m0.6535\u001b[0m  0.0210\n",
      "      4        \u001b[36m0.6527\u001b[0m       0.6392        \u001b[35m0.6399\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6428\u001b[0m       0.6392        0.6470  0.0180\n",
      "      6        0.6494       0.6392        \u001b[35m0.6242\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.6243\u001b[0m       0.6392        \u001b[35m0.5952\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.6027\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5799\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.5881\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5416\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.5638\u001b[0m       0.7010        \u001b[35m0.5259\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6766\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6634\u001b[0m  0.0470\n",
      "      2        0.6854       0.6392        0.7280  0.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        0.7235       0.6392        \u001b[35m0.6558\u001b[0m  0.0300\n",
      "      4        \u001b[36m0.6552\u001b[0m       0.6392        \u001b[35m0.6364\u001b[0m  0.0240\n",
      "      5        \u001b[36m0.6399\u001b[0m       0.6392        0.6421  0.0330\n",
      "      6        0.6469       0.6392        \u001b[35m0.6199\u001b[0m  0.0330\n",
      "      7        \u001b[36m0.6203\u001b[0m       0.6392        \u001b[35m0.5890\u001b[0m  0.0250\n",
      "      8        \u001b[36m0.5947\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5707\u001b[0m  0.0299\n",
      "      9        \u001b[36m0.5733\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5290\u001b[0m  0.0270\n",
      "     10        \u001b[36m0.5384\u001b[0m       0.7320        \u001b[35m0.5085\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6875\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6882\u001b[0m  0.0260\n",
      "      2        0.7223       0.6392        0.7217  0.0250\n",
      "      3        0.7036       0.6392        \u001b[35m0.6499\u001b[0m  0.0260\n",
      "      4        \u001b[36m0.6488\u001b[0m       0.6392        \u001b[35m0.6448\u001b[0m  0.0380\n",
      "      5        0.6496       0.6392        0.6569  0.0250\n",
      "      6        0.6583       0.6392        \u001b[35m0.6324\u001b[0m  0.0240\n",
      "      7        \u001b[36m0.6304\u001b[0m       0.6392        \u001b[35m0.6108\u001b[0m  0.0300\n",
      "      8        \u001b[36m0.6132\u001b[0m       0.6392        \u001b[35m0.5993\u001b[0m  0.0250\n",
      "      9        \u001b[36m0.5973\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5626\u001b[0m  0.0240\n",
      "     10        \u001b[36m0.5656\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5419\u001b[0m  0.0260\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6840\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6791\u001b[0m  0.0190\n",
      "      2        0.7086       0.6392        0.7330  0.0270\n",
      "      3        0.7120       0.6392        \u001b[35m0.6503\u001b[0m  0.0290\n",
      "      4        \u001b[36m0.6481\u001b[0m       0.6392        \u001b[35m0.6424\u001b[0m  0.0290\n",
      "      5        \u001b[36m0.6457\u001b[0m       0.6392        0.6590  0.0290\n",
      "      6        0.6573       0.6392        \u001b[35m0.6338\u001b[0m  0.0227\n",
      "      7        \u001b[36m0.6284\u001b[0m       0.6392        \u001b[35m0.6085\u001b[0m  0.0280\n",
      "      8        \u001b[36m0.6106\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.6023\u001b[0m  0.0375\n",
      "      9        \u001b[36m0.5990\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5620\u001b[0m  0.0240\n",
      "     10        \u001b[36m0.5701\u001b[0m       0.6907        \u001b[35m0.5479\u001b[0m  0.0320\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6843\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6854\u001b[0m  0.0190\n",
      "      2        0.7185       0.6392        0.7068  0.0300\n",
      "      3        0.6863       0.6392        \u001b[35m0.6343\u001b[0m  0.0280\n",
      "      4        \u001b[36m0.6265\u001b[0m       0.6392        \u001b[35m0.6301\u001b[0m  0.0260\n",
      "      5        0.6293       0.6392        \u001b[35m0.6225\u001b[0m  0.0240\n",
      "      6        \u001b[36m0.6033\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5874\u001b[0m  0.0280\n",
      "      7        \u001b[36m0.5678\u001b[0m       0.6701        \u001b[35m0.5831\u001b[0m  0.0300\n",
      "      8        \u001b[36m0.5547\u001b[0m       0.6804        \u001b[35m0.5636\u001b[0m  0.0300\n",
      "      9        \u001b[36m0.5287\u001b[0m       0.6804        \u001b[35m0.5569\u001b[0m  0.0300\n",
      "     10        \u001b[36m0.5146\u001b[0m       0.7010        \u001b[35m0.5350\u001b[0m  0.0307\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6847\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6727\u001b[0m  0.0250\n",
      "      2        0.6940       0.6392        0.7735  0.0310\n",
      "      3        0.7465       0.6392        \u001b[35m0.6617\u001b[0m  0.0340\n",
      "      4        \u001b[36m0.6559\u001b[0m       0.6392        \u001b[35m0.6424\u001b[0m  0.0411\n",
      "      5        \u001b[36m0.6398\u001b[0m       0.6392        0.6527  0.0300\n",
      "      6        0.6570       0.6392        0.6538  0.0210\n",
      "      7        0.6465       0.6392        \u001b[35m0.6021\u001b[0m  0.0300\n",
      "      8        \u001b[36m0.6027\u001b[0m       0.6289        \u001b[35m0.5831\u001b[0m  0.0460\n",
      "      9        \u001b[36m0.5939\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5404\u001b[0m  0.0320\n",
      "     10        \u001b[36m0.5568\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5040\u001b[0m  0.0470\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6862\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6758\u001b[0m  0.0230\n",
      "      2        0.7046       0.6392        0.7731  0.0260\n",
      "      3        0.7404       0.6392        \u001b[35m0.6547\u001b[0m  0.0477\n",
      "      4        \u001b[36m0.6482\u001b[0m       0.6392        \u001b[35m0.6421\u001b[0m  0.0360\n",
      "      5        \u001b[36m0.6350\u001b[0m       0.6392        0.6663  0.0330\n",
      "      6        0.6574       0.6392        0.6477  0.0330\n",
      "      7        \u001b[36m0.6271\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.6061\u001b[0m  0.0340\n",
      "      8        \u001b[36m0.5923\u001b[0m       \u001b[32m0.6598\u001b[0m        0.6105  0.0290\n",
      "      9        \u001b[36m0.5883\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5539\u001b[0m  0.0270\n",
      "     10        \u001b[36m0.5450\u001b[0m       0.7216        \u001b[35m0.5458\u001b[0m  0.0240\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6918\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6882\u001b[0m  0.0210\n",
      "      2        0.7219       0.6392        0.7585  0.0320\n",
      "      3        0.7300       0.6392        \u001b[35m0.6515\u001b[0m  0.0280\n",
      "      4        \u001b[36m0.6527\u001b[0m       0.6392        \u001b[35m0.6453\u001b[0m  0.0317\n",
      "      5        \u001b[36m0.6475\u001b[0m       0.6392        0.6663  0.0240\n",
      "      6        0.6726       0.6392        0.6650  0.0365\n",
      "      7        0.6624       0.6392        \u001b[35m0.6234\u001b[0m  0.0310\n",
      "      8        \u001b[36m0.6300\u001b[0m       0.6392        \u001b[35m0.6065\u001b[0m  0.0220\n",
      "      9        \u001b[36m0.6209\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5810\u001b[0m  0.0280\n",
      "     10        \u001b[36m0.5988\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5381\u001b[0m  0.0410\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6739\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6798\u001b[0m  0.0320\n",
      "      2        0.7036       0.6392        0.7449  0.0290\n",
      "      3        0.7232       0.6392        \u001b[35m0.6430\u001b[0m  0.0320\n",
      "      4        \u001b[36m0.6435\u001b[0m       0.6392        \u001b[35m0.6258\u001b[0m  0.1690\n",
      "      5        \u001b[36m0.6293\u001b[0m       0.6392        0.6415  0.0690\n",
      "      6        0.6451       0.6392        \u001b[35m0.6018\u001b[0m  0.2539\n",
      "      7        \u001b[36m0.6054\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5551\u001b[0m  0.1843\n",
      "      8        \u001b[36m0.5752\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5383\u001b[0m  0.1131\n",
      "      9        \u001b[36m0.5591\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.4842\u001b[0m  0.0610\n",
      "     10        \u001b[36m0.5289\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4675\u001b[0m  0.0860\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6871\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6789\u001b[0m  0.0940\n",
      "      2        0.7056       0.6392        0.7653  0.0837\n",
      "      3        0.7395       0.6392        \u001b[35m0.6495\u001b[0m  0.0726\n",
      "      4        \u001b[36m0.6502\u001b[0m       0.6392        \u001b[35m0.6351\u001b[0m  0.1320\n",
      "      5        \u001b[36m0.6361\u001b[0m       0.6392        0.6537  0.0976\n",
      "      6        0.6592       0.6392        0.6399  0.0776\n",
      "      7        \u001b[36m0.6352\u001b[0m       0.6392        \u001b[35m0.5899\u001b[0m  0.0980\n",
      "      8        \u001b[36m0.5940\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5803\u001b[0m  0.0808\n",
      "      9        \u001b[36m0.5870\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.5161\u001b[0m  0.0640\n",
      "     10        \u001b[36m0.5437\u001b[0m       0.6907        0.5187  0.0760\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6790\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6779\u001b[0m  0.0500\n",
      "      2        0.7150       0.6392        0.7452  0.0590\n",
      "      3        0.7291       0.6392        \u001b[35m0.6501\u001b[0m  0.0640\n",
      "      4        \u001b[36m0.6512\u001b[0m       0.6392        \u001b[35m0.6400\u001b[0m  0.0410\n",
      "      5        \u001b[36m0.6449\u001b[0m       0.6392        0.6578  0.0440\n",
      "      6        0.6654       0.6392        \u001b[35m0.6393\u001b[0m  0.0380\n",
      "      7        \u001b[36m0.6375\u001b[0m       0.6392        \u001b[35m0.5923\u001b[0m  0.0610\n",
      "      8        \u001b[36m0.6017\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5778\u001b[0m  0.0470\n",
      "      9        \u001b[36m0.5930\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.5148\u001b[0m  0.0441\n",
      "     10        \u001b[36m0.5495\u001b[0m       0.7216        \u001b[35m0.4977\u001b[0m  0.0590\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6793\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6805\u001b[0m  0.0420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.7235       0.6392        0.7389  0.0490\n",
      "      3        0.7197       0.6392        \u001b[35m0.6430\u001b[0m  0.0310\n",
      "      4        \u001b[36m0.6442\u001b[0m       0.6392        \u001b[35m0.6352\u001b[0m  0.0300\n",
      "      5        \u001b[36m0.6417\u001b[0m       0.6392        0.6634  0.0200\n",
      "      6        0.6628       0.6392        \u001b[35m0.6108\u001b[0m  0.0230\n",
      "      7        \u001b[36m0.6122\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5793\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.5910\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5411\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5532\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5028\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.5264\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.4653\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6763\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7004\u001b[0m  0.0170\n",
      "      2        0.7360       0.6392        0.7177  0.0187\n",
      "      3        0.6869       0.6392        \u001b[35m0.6295\u001b[0m  0.0210\n",
      "      4        \u001b[36m0.6257\u001b[0m       0.6392        \u001b[35m0.6261\u001b[0m  0.0230\n",
      "      5        0.6329       0.6392        0.6337  0.0190\n",
      "      6        \u001b[36m0.6141\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5570\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.5581\u001b[0m       0.6804        \u001b[35m0.5562\u001b[0m  0.0220\n",
      "      8        \u001b[36m0.5472\u001b[0m       \u001b[32m0.7938\u001b[0m        \u001b[35m0.4901\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.5196\u001b[0m       0.7732        \u001b[35m0.4764\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.4962\u001b[0m       0.7732        \u001b[35m0.4747\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6749\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6749\u001b[0m  0.0180\n",
      "      2        0.7121       0.6392        0.7297  0.0210\n",
      "      3        0.7115       0.6392        \u001b[35m0.6352\u001b[0m  0.0190\n",
      "      4        \u001b[36m0.6364\u001b[0m       0.6392        \u001b[35m0.6217\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6311\u001b[0m       0.6392        0.6443  0.0180\n",
      "      6        0.6445       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5815\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.5869\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5511\u001b[0m  0.0210\n",
      "      8        \u001b[36m0.5729\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5063\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5334\u001b[0m       0.7320        \u001b[35m0.4829\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.5216\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4583\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6688\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0197\n",
      "      2        0.7018       0.6392        0.7217  0.0180\n",
      "      3        0.6987       0.6392        \u001b[35m0.6325\u001b[0m  0.0180\n",
      "      4        \u001b[36m0.6246\u001b[0m       0.6392        \u001b[35m0.6192\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6165\u001b[0m       0.6392        0.6306  0.0208\n",
      "      6        \u001b[36m0.6052\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5695\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.5458\u001b[0m       0.7010        \u001b[35m0.5683\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.5356\u001b[0m       0.7010        \u001b[35m0.5446\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5108\u001b[0m       \u001b[32m0.7320\u001b[0m        0.5492  0.0200\n",
      "     10        \u001b[36m0.5023\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5188\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6844\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6988\u001b[0m  0.0180\n",
      "      2        0.7419       0.6392        0.7619  0.0170\n",
      "      3        0.7247       0.6392        \u001b[35m0.6447\u001b[0m  0.0340\n",
      "      4        \u001b[36m0.6449\u001b[0m       0.6392        \u001b[35m0.6438\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6446\u001b[0m       0.6392        0.6752  0.0210\n",
      "      6        0.6787       0.6392        \u001b[35m0.6414\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.6365\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5978\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.5959\u001b[0m       0.6495        \u001b[35m0.5899\u001b[0m  0.0200\n",
      "      9        0.6070       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5491\u001b[0m  0.0220\n",
      "     10        \u001b[36m0.5479\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.4786\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6732\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6887\u001b[0m  0.0170\n",
      "      2        0.7210       0.6392        0.7639  0.0220\n",
      "      3        0.7253       0.6392        \u001b[35m0.6389\u001b[0m  0.0180\n",
      "      4        \u001b[36m0.6373\u001b[0m       0.6392        \u001b[35m0.6292\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6272\u001b[0m       0.6392        0.6856  0.0200\n",
      "      6        0.6746       0.6392        \u001b[35m0.5996\u001b[0m  0.0204\n",
      "      7        \u001b[36m0.5931\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5612\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.5648\u001b[0m       0.7113        0.5682  0.0199\n",
      "      9        \u001b[36m0.5641\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.5077\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.5313\u001b[0m       0.7732        \u001b[35m0.4776\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6749\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6882\u001b[0m  0.0200\n",
      "      2        0.7228       0.6392        0.7592  0.0190\n",
      "      3        0.7308       0.6392        \u001b[35m0.6431\u001b[0m  0.0200\n",
      "      4        \u001b[36m0.6456\u001b[0m       0.6392        \u001b[35m0.6393\u001b[0m  0.0210\n",
      "      5        \u001b[36m0.6410\u001b[0m       0.6392        0.6636  0.0170\n",
      "      6        0.6728       0.6392        0.6425  0.0328\n",
      "      7        \u001b[36m0.6371\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5697\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.5846\u001b[0m       0.6907        0.5718  0.0170\n",
      "      9        0.5972       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5061\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.5502\u001b[0m       0.7320        0.5301  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6617\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6632\u001b[0m  0.0190\n",
      "      2        0.6812       0.6392        0.7545  0.0200\n",
      "      3        0.7432       0.6392        \u001b[35m0.6586\u001b[0m  0.0180\n",
      "      4        \u001b[36m0.6557\u001b[0m       0.6392        \u001b[35m0.6402\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.6394\u001b[0m       0.6392        0.6497  0.0180\n",
      "      6        0.6572       0.6392        0.6727  0.0170\n",
      "      7        0.6651       0.6392        \u001b[35m0.6031\u001b[0m  0.0210\n",
      "      8        \u001b[36m0.6052\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5625\u001b[0m  0.0230\n",
      "      9        \u001b[36m0.5854\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5249\u001b[0m  0.0230\n",
      "     10        \u001b[36m0.5542\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.4840\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6801\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6856\u001b[0m  0.0210\n",
      "      2        0.7259       0.6392        0.7706  0.0200\n",
      "      3        0.7402       0.6392        \u001b[35m0.6441\u001b[0m  0.0190\n",
      "      4        \u001b[36m0.6488\u001b[0m       0.6392        \u001b[35m0.6436\u001b[0m  0.0160\n",
      "      5        \u001b[36m0.6458\u001b[0m       0.6392        0.6625  0.0300\n",
      "      6        0.6742       0.6392        0.6714  0.0180\n",
      "      7        0.6686       0.6392        \u001b[35m0.5963\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.6096\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5560\u001b[0m  0.0201\n",
      "      9        \u001b[36m0.5891\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5292\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5748\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4740\u001b[0m  0.0205\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6711\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6855\u001b[0m  0.0170\n",
      "      2        0.7322       0.6392        0.7456  0.0170\n",
      "      3        0.7225       0.6392        \u001b[35m0.6404\u001b[0m  0.0200\n",
      "      4        \u001b[36m0.6432\u001b[0m       0.6392        \u001b[35m0.6339\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.6428\u001b[0m       0.6392        0.6782  0.0170\n",
      "      6        0.6863       0.6392        \u001b[35m0.6217\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.6207\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5694\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.5878\u001b[0m       0.6701        0.5933  0.0300\n",
      "      9        0.5994       0.7216        \u001b[35m0.5169\u001b[0m  0.0290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m0.5626\u001b[0m       0.7113        0.5535  0.0470\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6827\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6672\u001b[0m  0.0310\n",
      "      2        0.6991       0.6392        0.7752  0.0330\n",
      "      3        0.7593       0.6392        \u001b[35m0.6561\u001b[0m  0.0279\n",
      "      4        \u001b[36m0.6543\u001b[0m       0.6392        \u001b[35m0.6443\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.6454\u001b[0m       0.6392        0.6529  0.0249\n",
      "      6        0.6575       0.6392        \u001b[35m0.6434\u001b[0m  0.0300\n",
      "      7        \u001b[36m0.6342\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5822\u001b[0m  0.0240\n",
      "      8        \u001b[36m0.5857\u001b[0m       0.6701        \u001b[35m0.5766\u001b[0m  0.0230\n",
      "      9        \u001b[36m0.5799\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.5011\u001b[0m  0.0230\n",
      "     10        \u001b[36m0.5299\u001b[0m       0.7423        \u001b[35m0.4822\u001b[0m  0.0270\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6739\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6895\u001b[0m  0.0220\n",
      "      2        0.7383       0.6392        0.7326  0.0258\n",
      "      3        0.6993       0.6392        \u001b[35m0.6294\u001b[0m  0.0297\n",
      "      4        \u001b[36m0.6276\u001b[0m       0.6392        \u001b[35m0.6221\u001b[0m  0.0270\n",
      "      5        0.6312       0.6392        0.6732  0.0290\n",
      "      6        0.6589       0.6392        \u001b[35m0.5741\u001b[0m  0.0250\n",
      "      7        \u001b[36m0.5618\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5345\u001b[0m  0.0240\n",
      "      8        \u001b[36m0.5529\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.4869\u001b[0m  0.0290\n",
      "      9        \u001b[36m0.4955\u001b[0m       0.7526        0.4930  0.0240\n",
      "     10        0.5102       \u001b[32m0.7629\u001b[0m        0.5050  0.0230\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6683\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7009\u001b[0m  0.0220\n",
      "      2        0.7502       0.6392        0.7248  0.0250\n",
      "      3        0.6973       0.6392        \u001b[35m0.6358\u001b[0m  0.0290\n",
      "      4        \u001b[36m0.6353\u001b[0m       0.6392        \u001b[35m0.6341\u001b[0m  0.0230\n",
      "      5        0.6418       0.6392        0.6800  0.0260\n",
      "      6        0.6779       0.6392        \u001b[35m0.6193\u001b[0m  0.0250\n",
      "      7        \u001b[36m0.6050\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5556\u001b[0m  0.0290\n",
      "      8        \u001b[36m0.5659\u001b[0m       0.6804        0.5730  0.0220\n",
      "      9        \u001b[36m0.5598\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4780\u001b[0m  0.0290\n",
      "     10        \u001b[36m0.5389\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4624\u001b[0m  0.0260\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6729\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0250\n",
      "      2        0.7155       0.6392        0.7502  0.0290\n",
      "      3        0.7155       0.6392        \u001b[35m0.6267\u001b[0m  0.0210\n",
      "      4        \u001b[36m0.6209\u001b[0m       0.6392        \u001b[35m0.6094\u001b[0m  0.0310\n",
      "      5        \u001b[36m0.6071\u001b[0m       0.6392        0.6609  0.0260\n",
      "      6        0.6300       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5591\u001b[0m  0.0250\n",
      "      7        \u001b[36m0.5358\u001b[0m       0.6907        \u001b[35m0.5581\u001b[0m  0.0290\n",
      "      8        0.5424       0.6907        0.5590  0.0270\n",
      "      9        \u001b[36m0.5171\u001b[0m       \u001b[32m0.7216\u001b[0m        0.5715  0.0290\n",
      "     10        \u001b[36m0.5089\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5355\u001b[0m  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6767\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6904\u001b[0m  0.0240\n",
      "      2        0.7161       0.6392        0.7277  0.0211\n",
      "      3        0.7069       0.6392        \u001b[35m0.6541\u001b[0m  0.0180\n",
      "      4        \u001b[36m0.6539\u001b[0m       0.6392        0.6542  0.0241\n",
      "      5        0.6578       0.6392        0.6720  0.0200\n",
      "      6        0.6733       0.6392        \u001b[35m0.6519\u001b[0m  0.0330\n",
      "      7        0.6550       0.6392        \u001b[35m0.6346\u001b[0m  0.0210\n",
      "      8        \u001b[36m0.6433\u001b[0m       0.6392        \u001b[35m0.6133\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.6247\u001b[0m       0.6392        \u001b[35m0.5768\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.6003\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5351\u001b[0m  0.0197\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6612\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6785\u001b[0m  0.0180\n",
      "      2        0.6942       0.6392        0.7157  0.0191\n",
      "      3        0.6911       0.6392        \u001b[35m0.6400\u001b[0m  0.0240\n",
      "      4        \u001b[36m0.6327\u001b[0m       0.6392        0.6431  0.0190\n",
      "      5        0.6376       0.6392        0.6430  0.0230\n",
      "      6        \u001b[36m0.6213\u001b[0m       0.6289        \u001b[35m0.6007\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.5885\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5880\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.5695\u001b[0m       0.6907        0.5900  0.0260\n",
      "      9        \u001b[36m0.5667\u001b[0m       \u001b[32m0.7010\u001b[0m        0.6123  0.0230\n",
      "     10        0.5774       0.7010        0.6364  0.0240\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6788\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6636\u001b[0m  0.0170\n",
      "      2        0.6809       0.6392        0.7465  0.0180\n",
      "      3        0.7321       0.6392        0.6655  0.0230\n",
      "      4        \u001b[36m0.6626\u001b[0m       0.6392        \u001b[35m0.6490\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6500\u001b[0m       0.6392        0.6595  0.0240\n",
      "      6        0.6628       0.6392        \u001b[35m0.6424\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.6412\u001b[0m       0.6392        \u001b[35m0.6021\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.6114\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5847\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5967\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5355\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.5695\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.5061\u001b[0m  0.0322\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6733\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6582\u001b[0m  0.0390\n",
      "      2        \u001b[36m0.6692\u001b[0m       0.6392        0.7305  0.0190\n",
      "      3        0.7250       0.6392        0.6773  0.0170\n",
      "      4        0.6696       0.6392        \u001b[35m0.6504\u001b[0m  0.0210\n",
      "      5        \u001b[36m0.6484\u001b[0m       0.6392        0.6511  0.0210\n",
      "      6        0.6513       0.6392        \u001b[35m0.6488\u001b[0m  0.0220\n",
      "      7        \u001b[36m0.6438\u001b[0m       0.6392        \u001b[35m0.6159\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.6130\u001b[0m       0.6392        \u001b[35m0.5960\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5957\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5511\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.5646\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5271\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6801\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6624\u001b[0m  0.0200\n",
      "      2        0.6839       0.6392        0.7449  0.0180\n",
      "      3        0.7357       0.6392        0.6689  0.0230\n",
      "      4        \u001b[36m0.6680\u001b[0m       0.6392        \u001b[35m0.6512\u001b[0m  0.0324\n",
      "      5        \u001b[36m0.6541\u001b[0m       0.6392        0.6582  0.0200\n",
      "      6        0.6635       0.6392        0.6663  0.0190\n",
      "      7        0.6679       0.6392        \u001b[35m0.6384\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.6421\u001b[0m       0.6392        \u001b[35m0.6184\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.6270\u001b[0m       0.6392        \u001b[35m0.5906\u001b[0m  0.0360\n",
      "     10        \u001b[36m0.6029\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5541\u001b[0m  0.0230\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6830\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6707\u001b[0m  0.0210\n",
      "      2        0.6994       0.6392        0.7429  0.0240\n",
      "      3        0.7295       0.6392        \u001b[35m0.6695\u001b[0m  0.0190\n",
      "      4        \u001b[36m0.6668\u001b[0m       0.6392        \u001b[35m0.6575\u001b[0m  0.0250\n",
      "      5        \u001b[36m0.6594\u001b[0m       0.6392        0.6659  0.0247\n",
      "      6        0.6684       0.6392        0.6727  0.0199\n",
      "      7        0.6708       0.6392        \u001b[35m0.6565\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6521\u001b[0m       0.6392        \u001b[35m0.6391\u001b[0m  0.0230\n",
      "      9        \u001b[36m0.6378\u001b[0m       0.6392        \u001b[35m0.6309\u001b[0m  0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m0.6268\u001b[0m       0.6392        \u001b[35m0.5969\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7057\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6806\u001b[0m  0.0200\n",
      "      2        0.7255       0.6392        0.7422  0.0200\n",
      "      3        0.7255       0.6392        \u001b[35m0.6609\u001b[0m  0.0190\n",
      "      4        \u001b[36m0.6618\u001b[0m       0.6392        \u001b[35m0.6583\u001b[0m  0.0190\n",
      "      5        0.6626       0.6392        0.6730  0.0230\n",
      "      6        0.6782       0.6392        0.6802  0.0190\n",
      "      7        0.6811       0.6392        0.6681  0.0270\n",
      "      8        0.6680       0.6392        \u001b[35m0.6568\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.6582\u001b[0m       0.6392        \u001b[35m0.6540\u001b[0m  0.0230\n",
      "     10        \u001b[36m0.6545\u001b[0m       0.6392        \u001b[35m0.6395\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6988\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6590\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6790\u001b[0m       0.6392        0.7487  0.0200\n",
      "      3        0.7469       0.6392        0.6998  0.0220\n",
      "      4        0.6893       0.6392        0.6592  0.0190\n",
      "      5        \u001b[36m0.6595\u001b[0m       0.6392        \u001b[35m0.6558\u001b[0m  0.0220\n",
      "      6        0.6596       0.6392        0.6661  0.0210\n",
      "      7        0.6710       0.6392        0.6680  0.0200\n",
      "      8        0.6689       0.6392        \u001b[35m0.6500\u001b[0m  0.0250\n",
      "      9        \u001b[36m0.6512\u001b[0m       0.6392        \u001b[35m0.6347\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6394\u001b[0m       0.6392        \u001b[35m0.6218\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6707\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6869\u001b[0m  0.0160\n",
      "      2        0.7140       0.6392        0.7152  0.0200\n",
      "      3        0.6957       0.6392        \u001b[35m0.6506\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.6487\u001b[0m       0.6392        \u001b[35m0.6492\u001b[0m  0.0198\n",
      "      5        0.6528       0.6392        0.6631  0.0398\n",
      "      6        0.6592       0.6392        \u001b[35m0.6359\u001b[0m  0.0520\n",
      "      7        \u001b[36m0.6310\u001b[0m       0.6392        \u001b[35m0.6138\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6123\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5871\u001b[0m  0.0220\n",
      "      9        \u001b[36m0.5846\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5590\u001b[0m  0.0220\n",
      "     10        \u001b[36m0.5695\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5193\u001b[0m  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6976\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6738\u001b[0m  0.0150\n",
      "      2        0.7103       0.6392        0.7359  0.0237\n",
      "      3        0.7159       0.6392        \u001b[35m0.6529\u001b[0m  0.0206\n",
      "      4        \u001b[36m0.6486\u001b[0m       0.6392        \u001b[35m0.6464\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6467\u001b[0m       0.6392        0.6610  0.0240\n",
      "      6        0.6539       0.6392        \u001b[35m0.6320\u001b[0m  0.0230\n",
      "      7        \u001b[36m0.6144\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.6043\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.5847\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5813\u001b[0m  0.0210\n",
      "      9        \u001b[36m0.5478\u001b[0m       0.6701        \u001b[35m0.5693\u001b[0m  0.0210\n",
      "     10        \u001b[36m0.5317\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5509\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6764\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6636\u001b[0m  0.0170\n",
      "      2        0.6844       0.6392        0.7687  0.0240\n",
      "      3        0.7495       0.6392        0.6691  0.0210\n",
      "      4        \u001b[36m0.6626\u001b[0m       0.6392        \u001b[35m0.6444\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6435\u001b[0m       0.6392        0.6497  0.0218\n",
      "      6        0.6536       0.6392        0.6632  0.0240\n",
      "      7        0.6544       0.6392        \u001b[35m0.6015\u001b[0m  0.0270\n",
      "      8        \u001b[36m0.6008\u001b[0m       0.6289        \u001b[35m0.5840\u001b[0m  0.0290\n",
      "      9        \u001b[36m0.5914\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5214\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.5425\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.4833\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6971\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7262\u001b[0m  0.0170\n",
      "      2        0.7624       0.6392        0.7328  0.0190\n",
      "      3        0.7083       0.6392        \u001b[35m0.6580\u001b[0m  0.0200\n",
      "      4        \u001b[36m0.6576\u001b[0m       0.6392        0.6674  0.0160\n",
      "      5        0.6711       0.6392        0.6914  0.0200\n",
      "      6        0.6867       0.6392        0.6667  0.0210\n",
      "      7        0.6608       0.6392        \u001b[35m0.6453\u001b[0m  0.0198\n",
      "      8        \u001b[36m0.6440\u001b[0m       0.6392        0.6545  0.0220\n",
      "      9        0.6443       0.6392        \u001b[35m0.6160\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.6044\u001b[0m       0.6392        \u001b[35m0.6041\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7052\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6858\u001b[0m  0.0320\n",
      "      2        0.7279       0.6392        0.7946  0.0190\n",
      "      3        0.7581       0.6392        \u001b[35m0.6608\u001b[0m  0.0230\n",
      "      4        \u001b[36m0.6599\u001b[0m       0.6392        \u001b[35m0.6525\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6541\u001b[0m       0.6392        0.6689  0.0180\n",
      "      6        0.6748       0.6392        0.6847  0.0230\n",
      "      7        0.6823       0.6392        \u001b[35m0.6479\u001b[0m  0.0206\n",
      "      8        \u001b[36m0.6502\u001b[0m       0.6392        \u001b[35m0.6210\u001b[0m  0.0210\n",
      "      9        \u001b[36m0.6321\u001b[0m       0.6392        \u001b[35m0.6090\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.6222\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5393\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6802\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7093\u001b[0m  0.0180\n",
      "      2        0.7395       0.6392        0.7203  0.0240\n",
      "      3        0.7000       0.6392        \u001b[35m0.6531\u001b[0m  0.0230\n",
      "      4        \u001b[36m0.6523\u001b[0m       0.6392        0.6551  0.0230\n",
      "      5        0.6556       0.6392        0.6614  0.0200\n",
      "      6        0.6586       0.6392        \u001b[35m0.6376\u001b[0m  0.0220\n",
      "      7        \u001b[36m0.6325\u001b[0m       0.6392        \u001b[35m0.6052\u001b[0m  0.0189\n",
      "      8        \u001b[36m0.6065\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5843\u001b[0m  0.0240\n",
      "      9        \u001b[36m0.5841\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5270\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.5497\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.4664\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6766\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6684\u001b[0m  0.0180\n",
      "      2        0.6964       0.6392        0.7684  0.0330\n",
      "      3        0.7543       0.6392        0.6687  0.0230\n",
      "      4        \u001b[36m0.6684\u001b[0m       0.6392        \u001b[35m0.6508\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6532\u001b[0m       0.6392        0.6588  0.0300\n",
      "      6        0.6649       0.6392        0.6759  0.0290\n",
      "      7        0.6789       0.6392        \u001b[35m0.6478\u001b[0m  0.0310\n",
      "      8        \u001b[36m0.6504\u001b[0m       0.6392        \u001b[35m0.6107\u001b[0m  0.0280\n",
      "      9        \u001b[36m0.6228\u001b[0m       0.6392        \u001b[35m0.5929\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.6098\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5340\u001b[0m  0.0260\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6673\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6694\u001b[0m  0.0190\n",
      "      2        0.6966       0.6392        0.7403  0.0200\n",
      "      3        0.7303       0.6392        \u001b[35m0.6620\u001b[0m  0.0420\n",
      "      4        \u001b[36m0.6616\u001b[0m       0.6392        \u001b[35m0.6518\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6556\u001b[0m       0.6392        0.6631  0.0200\n",
      "      6        0.6720       0.6392        0.6693  0.0200\n",
      "      7        0.6704       0.6392        \u001b[35m0.6309\u001b[0m  0.0260\n",
      "      8        \u001b[36m0.6372\u001b[0m       0.6392        \u001b[35m0.6115\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.6264\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5591\u001b[0m  0.0480\n",
      "     10        \u001b[36m0.5842\u001b[0m       0.7010        \u001b[35m0.5313\u001b[0m  0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6800\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0170\n",
      "      2        0.7220       0.6392        0.7424  0.0350\n",
      "      3        0.7247       0.6392        \u001b[35m0.6542\u001b[0m  0.0320\n",
      "      4        \u001b[36m0.6559\u001b[0m       0.6392        \u001b[35m0.6480\u001b[0m  0.0328\n",
      "      5        \u001b[36m0.6533\u001b[0m       0.6392        0.6623  0.0310\n",
      "      6        0.6692       0.6392        \u001b[35m0.6459\u001b[0m  0.0230\n",
      "      7        \u001b[36m0.6433\u001b[0m       0.6392        \u001b[35m0.5913\u001b[0m  0.0220\n",
      "      8        \u001b[36m0.5990\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5632\u001b[0m  0.0300\n",
      "      9        \u001b[36m0.5786\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4937\u001b[0m  0.0310\n",
      "     10        \u001b[36m0.5414\u001b[0m       0.7423        \u001b[35m0.4929\u001b[0m  0.0320\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6929\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6867\u001b[0m  0.0190\n",
      "      2        0.7309       0.6392        0.7674  0.0230\n",
      "      3        0.7400       0.6392        \u001b[35m0.6665\u001b[0m  0.0300\n",
      "      4        \u001b[36m0.6636\u001b[0m       0.6392        \u001b[35m0.6580\u001b[0m  0.0280\n",
      "      5        \u001b[36m0.6613\u001b[0m       0.6392        0.6728  0.0210\n",
      "      6        0.6787       0.6392        0.6845  0.0250\n",
      "      7        0.6830       0.6392        0.6667  0.0210\n",
      "      8        0.6633       0.6392        \u001b[35m0.6508\u001b[0m  0.0244\n",
      "      9        \u001b[36m0.6510\u001b[0m       0.6392        \u001b[35m0.6487\u001b[0m  0.0420\n",
      "     10        \u001b[36m0.6493\u001b[0m       0.6392        \u001b[35m0.6298\u001b[0m  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6713\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6609\u001b[0m  0.0230\n",
      "      2        0.6823       0.6392        0.7438  0.0220\n",
      "      3        0.7413       0.6392        0.6831  0.0290\n",
      "      4        0.6738       0.6392        \u001b[35m0.6471\u001b[0m  0.0300\n",
      "      5        \u001b[36m0.6478\u001b[0m       0.6392        0.6477  0.0320\n",
      "      6        0.6539       0.6392        0.6588  0.0205\n",
      "      7        0.6568       0.6392        \u001b[35m0.6145\u001b[0m  0.0240\n",
      "      8        \u001b[36m0.6136\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5886\u001b[0m  0.0350\n",
      "      9        \u001b[36m0.5996\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5392\u001b[0m  0.0306\n",
      "     10        \u001b[36m0.5555\u001b[0m       0.7010        \u001b[35m0.5227\u001b[0m  0.0350\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6779\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6577\u001b[0m  0.0306\n",
      "      2        \u001b[36m0.6760\u001b[0m       0.6392        0.7507  0.0260\n",
      "      3        0.7490       0.6392        0.6944  0.0217\n",
      "      4        0.6840       0.6392        0.6598  0.0230\n",
      "      5        \u001b[36m0.6567\u001b[0m       0.6392        \u001b[35m0.6527\u001b[0m  0.0190\n",
      "      6        \u001b[36m0.6526\u001b[0m       0.6392        0.6621  0.0230\n",
      "      7        \u001b[36m0.6519\u001b[0m       0.6392        \u001b[35m0.6211\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.5992\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5939\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5677\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5587\u001b[0m  0.0207\n",
      "     10        \u001b[36m0.5247\u001b[0m       0.7113        \u001b[35m0.5542\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6649\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6781\u001b[0m  0.0180\n",
      "      2        0.7119       0.6392        0.7530  0.0280\n",
      "      3        0.7277       0.6392        \u001b[35m0.6464\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.6490\u001b[0m       0.6392        0.6492  0.0210\n",
      "      5        0.6546       0.6392        0.6841  0.0240\n",
      "      6        0.6875       0.6392        0.6477  0.0397\n",
      "      7        \u001b[36m0.6437\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5951\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.6048\u001b[0m       \u001b[32m0.6701\u001b[0m        0.5988  0.0190\n",
      "      9        0.6209       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5257\u001b[0m  0.0250\n",
      "     10        \u001b[36m0.5755\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4699\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6877\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6847\u001b[0m  0.0200\n",
      "      2        0.7267       0.6392        0.7963  0.0190\n",
      "      3        0.7563       0.6392        \u001b[35m0.6689\u001b[0m  0.0187\n",
      "      4        \u001b[36m0.6658\u001b[0m       0.6392        \u001b[35m0.6601\u001b[0m  0.0240\n",
      "      5        \u001b[36m0.6604\u001b[0m       0.6392        0.6705  0.0282\n",
      "      6        0.6700       0.6392        0.6686  0.0190\n",
      "      7        0.6634       0.6392        \u001b[35m0.6447\u001b[0m  0.0250\n",
      "      8        \u001b[36m0.6390\u001b[0m       0.6392        \u001b[35m0.6330\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.6262\u001b[0m       0.6392        \u001b[35m0.6308\u001b[0m  0.0270\n",
      "     10        \u001b[36m0.6091\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5925\u001b[0m  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6622\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6785\u001b[0m  0.0190\n",
      "      2        0.6980       0.6392        0.7460  0.0226\n",
      "      3        0.7259       0.6392        \u001b[35m0.6596\u001b[0m  0.0200\n",
      "      4        \u001b[36m0.6582\u001b[0m       0.6392        \u001b[35m0.6517\u001b[0m  0.0217\n",
      "      5        \u001b[36m0.6530\u001b[0m       0.6392        0.6678  0.0410\n",
      "      6        0.6709       0.6392        0.6613  0.0250\n",
      "      7        0.6561       \u001b[32m0.6804\u001b[0m        \u001b[35m0.6013\u001b[0m  0.0260\n",
      "      8        \u001b[36m0.6192\u001b[0m       0.6701        0.6219  0.0380\n",
      "      9        0.6383       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5902\u001b[0m  0.0330\n",
      "     10        \u001b[36m0.6148\u001b[0m       0.6701        0.7679  0.0230\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6839\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6756\u001b[0m  0.0486\n",
      "      2        0.7100       0.6392        0.7970  0.0270\n",
      "      3        0.7736       0.6392        0.6988  0.0330\n",
      "      4        0.6890       0.6392        \u001b[35m0.6565\u001b[0m  0.0266\n",
      "      5        \u001b[36m0.6542\u001b[0m       0.6392        \u001b[35m0.6472\u001b[0m  0.0290\n",
      "      6        \u001b[36m0.6470\u001b[0m       0.6392        0.6679  0.0220\n",
      "      7        0.6733       0.6392        0.6656  0.0220\n",
      "      8        0.6547       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5927\u001b[0m  0.0280\n",
      "      9        \u001b[36m0.5984\u001b[0m       0.6495        0.6051  0.0220\n",
      "     10        0.6107       \u001b[32m0.7938\u001b[0m        \u001b[35m0.5013\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6739\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6743\u001b[0m  0.0200\n",
      "      2        0.7061       0.6392        0.7769  0.0190\n",
      "      3        0.7576       0.6392        \u001b[35m0.6711\u001b[0m  0.0210\n",
      "      4        \u001b[36m0.6702\u001b[0m       0.6392        \u001b[35m0.6580\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6605\u001b[0m       0.6392        0.6645  0.0270\n",
      "      6        0.6703       0.6392        0.6737  0.0200\n",
      "      7        0.6747       0.6392        \u001b[35m0.6418\u001b[0m  0.0287\n",
      "      8        \u001b[36m0.6456\u001b[0m       0.6392        \u001b[35m0.6187\u001b[0m  0.0250\n",
      "      9        \u001b[36m0.6328\u001b[0m       0.6392        \u001b[35m0.5963\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.6174\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5391\u001b[0m  0.0320\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6958\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6739\u001b[0m  0.0180\n",
      "      2        0.7203       0.6392        0.8100  0.0240\n",
      "      3        0.7915       0.6392        0.6911  0.0180\n",
      "      4        \u001b[36m0.6854\u001b[0m       0.6392        \u001b[35m0.6596\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6617\u001b[0m       0.6392        \u001b[35m0.6586\u001b[0m  0.0210\n",
      "      6        0.6633       0.6392        0.6728  0.0230\n",
      "      7        0.6786       0.6392        0.6824  0.0200\n",
      "      8        0.6838       0.6392        0.6639  0.0240\n",
      "      9        0.6623       0.6392        \u001b[35m0.6385\u001b[0m  0.0178\n",
      "     10        \u001b[36m0.6398\u001b[0m       0.6392        \u001b[35m0.6294\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6939\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6709\u001b[0m  0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.7157       0.6392        0.8166  0.0140\n",
      "      3        0.7990       0.6392        0.6893  0.0200\n",
      "      4        \u001b[36m0.6819\u001b[0m       0.6392        \u001b[35m0.6582\u001b[0m  0.0240\n",
      "      5        \u001b[36m0.6585\u001b[0m       0.6392        \u001b[35m0.6553\u001b[0m  0.0180\n",
      "      6        0.6593       0.6392        0.6658  0.0200\n",
      "      7        0.6637       0.6392        \u001b[35m0.6315\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6279\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5922\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.5962\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5531\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.5607\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4831\u001b[0m  0.0227\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6789\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6810\u001b[0m  0.0150\n",
      "      2        0.7345       0.6392        0.7491  0.0220\n",
      "      3        0.7238       0.6392        \u001b[35m0.6519\u001b[0m  0.0210\n",
      "      4        \u001b[36m0.6517\u001b[0m       0.6392        \u001b[35m0.6518\u001b[0m  0.0200\n",
      "      5        0.6541       0.6392        0.6647  0.0220\n",
      "      6        0.6636       0.6392        \u001b[35m0.6395\u001b[0m  0.0230\n",
      "      7        \u001b[36m0.6269\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5898\u001b[0m  0.0250\n",
      "      8        \u001b[36m0.5874\u001b[0m       0.6495        \u001b[35m0.5597\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5528\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5047\u001b[0m  0.0250\n",
      "     10        0.5604       0.7113        0.5169  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6925\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0190\n",
      "      2        0.7371       0.6392        0.7818  0.0190\n",
      "      3        0.7464       0.6392        \u001b[35m0.6570\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.6546\u001b[0m       0.6392        \u001b[35m0.6448\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6490\u001b[0m       0.6392        0.6652  0.0352\n",
      "      6        0.6724       0.6392        0.6604  0.0145\n",
      "      7        0.6524       \u001b[32m0.6495\u001b[0m        \u001b[35m0.6022\u001b[0m  0.0220\n",
      "      8        \u001b[36m0.6064\u001b[0m       0.6495        \u001b[35m0.6011\u001b[0m  0.0291\n",
      "      9        0.6065       \u001b[32m0.7732\u001b[0m        \u001b[35m0.5136\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.5508\u001b[0m       0.7423        \u001b[35m0.5001\u001b[0m  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6736\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6769\u001b[0m  0.0170\n",
      "      2        0.7146       0.6392        0.7577  0.0250\n",
      "      3        0.7292       0.6392        \u001b[35m0.6635\u001b[0m  0.0210\n",
      "      4        \u001b[36m0.6595\u001b[0m       0.6392        \u001b[35m0.6427\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.6420\u001b[0m       0.6392        \u001b[35m0.6406\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6400\u001b[0m       0.6392        \u001b[35m0.6168\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.5941\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5453\u001b[0m  0.0157\n",
      "      8        \u001b[36m0.5344\u001b[0m       \u001b[32m0.7216\u001b[0m        0.5497  0.0160\n",
      "      9        \u001b[36m0.5318\u001b[0m       \u001b[32m0.7423\u001b[0m        0.5866  0.0190\n",
      "     10        0.5765       \u001b[32m0.7835\u001b[0m        \u001b[35m0.5338\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6765\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7151\u001b[0m  0.0230\n",
      "      2        0.7367       0.6392        \u001b[35m0.7039\u001b[0m  0.0220\n",
      "      3        0.6878       0.6392        \u001b[35m0.6516\u001b[0m  0.0250\n",
      "      4        \u001b[36m0.6514\u001b[0m       0.6392        0.6591  0.0200\n",
      "      5        0.6622       0.6392        0.6684  0.0160\n",
      "      6        0.6657       0.6392        \u001b[35m0.6358\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.6372\u001b[0m       0.6392        \u001b[35m0.6143\u001b[0m  0.0210\n",
      "      8        \u001b[36m0.6209\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5687\u001b[0m  0.0220\n",
      "      9        \u001b[36m0.5880\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5328\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5732\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5112\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6738\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7026\u001b[0m  0.0140\n",
      "      2        0.7257       0.6392        0.7114  0.0180\n",
      "      3        0.6940       0.6392        \u001b[35m0.6567\u001b[0m  0.0110\n",
      "      4        \u001b[36m0.6551\u001b[0m       0.6392        0.6669  0.0140\n",
      "      5        0.6665       0.6392        0.6848  0.0170\n",
      "      6        0.6756       0.6392        0.6617  0.0170\n",
      "      7        \u001b[36m0.6528\u001b[0m       0.6392        \u001b[35m0.6537\u001b[0m  0.0120\n",
      "      8        \u001b[36m0.6426\u001b[0m       0.6392        \u001b[35m0.6415\u001b[0m  0.0120\n",
      "      9        \u001b[36m0.6247\u001b[0m       0.6392        \u001b[35m0.6195\u001b[0m  0.0350\n",
      "     10        \u001b[36m0.6029\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5889\u001b[0m  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6726\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6877\u001b[0m  0.0190\n",
      "      2        0.7078       0.6392        0.7227  0.0240\n",
      "      3        0.7045       0.6392        \u001b[35m0.6561\u001b[0m  0.0170\n",
      "      4        \u001b[36m0.6566\u001b[0m       0.6392        0.6580  0.0180\n",
      "      5        0.6624       0.6392        0.6739  0.0170\n",
      "      6        0.6743       0.6392        \u001b[35m0.6478\u001b[0m  0.0130\n",
      "      7        \u001b[36m0.6498\u001b[0m       0.6392        \u001b[35m0.6231\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6330\u001b[0m       0.6392        \u001b[35m0.5973\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.6124\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5581\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.5890\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5291\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6702\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7443\u001b[0m  0.0140\n",
      "      2        0.7546       0.6392        \u001b[35m0.6684\u001b[0m  0.0160\n",
      "      3        \u001b[36m0.6643\u001b[0m       0.6392        \u001b[35m0.6469\u001b[0m  0.0170\n",
      "      4        \u001b[36m0.6498\u001b[0m       0.6392        0.6639  0.0140\n",
      "      5        0.6664       0.6392        0.6495  0.0230\n",
      "      6        \u001b[36m0.6473\u001b[0m       0.6392        \u001b[35m0.6167\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.6214\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5954\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.6031\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5639\u001b[0m  0.0140\n",
      "      9        \u001b[36m0.5829\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5495\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5703\u001b[0m       0.6907        0.6257  0.0175\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6855\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6855\u001b[0m  0.0170\n",
      "      2        0.7194       0.6392        0.7197  0.0130\n",
      "      3        0.7043       0.6392        \u001b[35m0.6490\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6510\u001b[0m       0.6392        0.6506  0.0130\n",
      "      5        0.6549       0.6392        0.6686  0.0160\n",
      "      6        0.6698       0.6392        \u001b[35m0.6421\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6418\u001b[0m       0.6392        \u001b[35m0.6133\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6191\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5923\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6004\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5506\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5720\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5213\u001b[0m  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6769\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6957\u001b[0m  0.0138\n",
      "      2        0.7323       0.6392        0.7042  0.0130\n",
      "      3        0.6931       0.6392        \u001b[35m0.6509\u001b[0m  0.0150\n",
      "      4        \u001b[36m0.6525\u001b[0m       0.6392        0.6547  0.0159\n",
      "      5        0.6617       0.6392        0.6651  0.0170\n",
      "      6        0.6651       0.6392        \u001b[35m0.6336\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6354\u001b[0m       0.6392        \u001b[35m0.6136\u001b[0m  0.0230\n",
      "      8        \u001b[36m0.6191\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5732\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5888\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5434\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.5696\u001b[0m       0.7113        \u001b[35m0.5251\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6841\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6978\u001b[0m  0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.7377       0.6392        0.7012  0.0170\n",
      "      3        0.6888       0.6392        \u001b[35m0.6515\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6538\u001b[0m       0.6392        0.6624  0.0160\n",
      "      5        0.6690       0.6392        0.6673  0.0180\n",
      "      6        0.6627       0.6392        \u001b[35m0.6299\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6303\u001b[0m       0.6392        \u001b[35m0.6220\u001b[0m  0.0130\n",
      "      8        \u001b[36m0.6149\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5624\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.5752\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5245\u001b[0m  0.0130\n",
      "     10        \u001b[36m0.5462\u001b[0m       0.7423        0.5281  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6672\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6805\u001b[0m  0.0130\n",
      "      2        0.7065       0.6392        0.7033  0.0160\n",
      "      3        0.6893       0.6392        \u001b[35m0.6461\u001b[0m  0.0150\n",
      "      4        \u001b[36m0.6444\u001b[0m       0.6392        0.6474  0.0160\n",
      "      5        0.6498       0.6392        \u001b[35m0.6417\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6298\u001b[0m       0.6392        \u001b[35m0.5931\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.5879\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5631\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.5503\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5228\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.5346\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.4856\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5333\u001b[0m       \u001b[32m0.8041\u001b[0m        \u001b[35m0.4629\u001b[0m  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6711\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7057\u001b[0m  0.0140\n",
      "      2        0.7310       0.6392        \u001b[35m0.6836\u001b[0m  0.0170\n",
      "      3        \u001b[36m0.6683\u001b[0m       0.6392        \u001b[35m0.6386\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6395\u001b[0m       0.6392        0.6511  0.0160\n",
      "      5        0.6521       0.6392        \u001b[35m0.6294\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.6231\u001b[0m       0.6392        \u001b[35m0.5952\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.5985\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5608\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.5685\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5368\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.5547\u001b[0m       0.6907        \u001b[35m0.5302\u001b[0m  0.0130\n",
      "     10        \u001b[36m0.5454\u001b[0m       \u001b[32m0.7216\u001b[0m        0.5628  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6734\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7298\u001b[0m  0.0150\n",
      "      2        0.7518       0.6392        \u001b[35m0.6769\u001b[0m  0.0170\n",
      "      3        \u001b[36m0.6635\u001b[0m       0.6392        \u001b[35m0.6424\u001b[0m  0.0150\n",
      "      4        \u001b[36m0.6414\u001b[0m       0.6392        0.6575  0.0170\n",
      "      5        0.6549       0.6392        \u001b[35m0.6368\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6221\u001b[0m       0.6392        \u001b[35m0.6031\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.5885\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5722\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.5462\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5548\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.5284\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5348\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5216\u001b[0m       0.7216        \u001b[35m0.5127\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6811\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7341\u001b[0m  0.0170\n",
      "      2        0.7623       0.6392        \u001b[35m0.7007\u001b[0m  0.0150\n",
      "      3        0.6845       0.6392        \u001b[35m0.6531\u001b[0m  0.0120\n",
      "      4        \u001b[36m0.6536\u001b[0m       0.6392        0.6675  0.0150\n",
      "      5        0.6738       0.6392        0.6814  0.0150\n",
      "      6        0.6793       0.6392        \u001b[35m0.6388\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6417\u001b[0m       0.6392        \u001b[35m0.6132\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6290\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5768\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.6027\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5369\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5880\u001b[0m       0.7423        \u001b[35m0.5005\u001b[0m  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6720\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7027\u001b[0m  0.0140\n",
      "      2        0.7235       0.6392        0.7151  0.0180\n",
      "      3        0.6909       0.6392        \u001b[35m0.6472\u001b[0m  0.0120\n",
      "      4        \u001b[36m0.6423\u001b[0m       0.6392        0.6556  0.0160\n",
      "      5        0.6523       0.6392        0.6605  0.0120\n",
      "      6        \u001b[36m0.6345\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.6002\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.5868\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5966\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.5784\u001b[0m       0.6804        0.6588  0.0150\n",
      "      9        0.6158       0.6495        0.8904  0.0149\n",
      "     10        0.7204       0.6392        0.6152  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6667\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6848\u001b[0m  0.0130\n",
      "      2        0.7060       0.6392        0.7270  0.0140\n",
      "      3        0.7077       0.6392        \u001b[35m0.6593\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6583\u001b[0m       0.6392        0.6596  0.0160\n",
      "      5        0.6592       0.6392        0.6729  0.0160\n",
      "      6        0.6680       0.6392        \u001b[35m0.6470\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6395\u001b[0m       0.6392        \u001b[35m0.6100\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6132\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5893\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5970\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5798\u001b[0m  0.0140\n",
      "     10        \u001b[36m0.5898\u001b[0m       0.6804        0.7032  0.0137\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6768\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6941\u001b[0m  0.0170\n",
      "      2        0.7231       0.6392        0.7301  0.0160\n",
      "      3        0.7073       0.6392        \u001b[35m0.6542\u001b[0m  0.0130\n",
      "      4        \u001b[36m0.6532\u001b[0m       0.6392        0.6588  0.0170\n",
      "      5        0.6608       0.6392        0.6656  0.0130\n",
      "      6        0.6574       0.6392        \u001b[35m0.6153\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6157\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.6011\u001b[0m  0.0157\n",
      "      8        \u001b[36m0.6059\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5337\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.5698\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.4970\u001b[0m  0.0140\n",
      "     10        \u001b[36m0.5419\u001b[0m       0.7010        0.5709  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6641\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7090\u001b[0m  0.0130\n",
      "      2        0.7378       0.6392        \u001b[35m0.7076\u001b[0m  0.0170\n",
      "      3        0.6935       0.6392        \u001b[35m0.6498\u001b[0m  0.0130\n",
      "      4        \u001b[36m0.6526\u001b[0m       0.6392        0.6567  0.0138\n",
      "      5        0.6609       0.6392        0.6599  0.0170\n",
      "      6        0.6590       0.6392        \u001b[35m0.6113\u001b[0m  0.0120\n",
      "      7        \u001b[36m0.6191\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5979\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6130\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5340\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.5752\u001b[0m       0.7113        0.5544  0.0150\n",
      "     10        0.5967       0.6598        0.8484  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6717\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6883\u001b[0m  0.0110\n",
      "      2        0.7253       0.6392        0.7173  0.0140\n",
      "      3        0.7001       0.6392        \u001b[35m0.6481\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6506\u001b[0m       0.6392        \u001b[35m0.6469\u001b[0m  0.0120\n",
      "      5        0.6551       0.6392        0.6578  0.0160\n",
      "      6        0.6509       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5846\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.5968\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5757\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.5913\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.4966\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5545\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4619\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5242\u001b[0m       0.7320        0.4855  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6761\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7017\u001b[0m  0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.7402       0.6392        0.7104  0.0170\n",
      "      3        0.6914       0.6392        \u001b[35m0.6454\u001b[0m  0.0260\n",
      "      4        \u001b[36m0.6460\u001b[0m       0.6392        0.6550  0.0210\n",
      "      5        0.6610       0.6392        0.6623  0.0140\n",
      "      6        0.6494       0.6392        \u001b[35m0.5947\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.5948\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5863\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.5815\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5177\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5506\u001b[0m       0.7010        0.5181  0.0150\n",
      "     10        \u001b[36m0.5382\u001b[0m       0.7010        0.7334  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6624\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6778\u001b[0m  0.0130\n",
      "      2        0.7104       0.6392        0.7131  0.0170\n",
      "      3        0.6922       0.6392        \u001b[35m0.6405\u001b[0m  0.0140\n",
      "      4        \u001b[36m0.6372\u001b[0m       0.6392        0.6448  0.0150\n",
      "      5        0.6493       0.6392        0.6491  0.0170\n",
      "      6        \u001b[36m0.6279\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5833\u001b[0m  0.0193\n",
      "      7        \u001b[36m0.5833\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5689\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.5573\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5471\u001b[0m  0.0140\n",
      "      9        0.5611       \u001b[32m0.7320\u001b[0m        \u001b[35m0.4956\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5516\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4885\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6701\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7213\u001b[0m  0.0150\n",
      "      2        0.7499       0.6392        \u001b[35m0.6843\u001b[0m  0.0150\n",
      "      3        \u001b[36m0.6690\u001b[0m       0.6392        \u001b[35m0.6414\u001b[0m  0.0150\n",
      "      4        \u001b[36m0.6442\u001b[0m       0.6392        0.6608  0.0160\n",
      "      5        0.6668       0.6392        0.6432  0.0150\n",
      "      6        \u001b[36m0.6314\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5787\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.5909\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5465\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.5572\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5309\u001b[0m  0.0140\n",
      "      9        0.5633       0.7010        0.6195  0.0138\n",
      "     10        0.5832       0.6804        0.6845  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6866\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7260\u001b[0m  0.0150\n",
      "      2        0.7677       0.6392        \u001b[35m0.6994\u001b[0m  0.0170\n",
      "      3        \u001b[36m0.6787\u001b[0m       0.6392        \u001b[35m0.6438\u001b[0m  0.0170\n",
      "      4        \u001b[36m0.6427\u001b[0m       0.6392        \u001b[35m0.6398\u001b[0m  0.0170\n",
      "      5        \u001b[36m0.6364\u001b[0m       0.6392        \u001b[35m0.6229\u001b[0m  0.0160\n",
      "      6        \u001b[36m0.6006\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5593\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.5378\u001b[0m       0.7010        \u001b[35m0.5554\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.5219\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5503\u001b[0m  0.0140\n",
      "      9        0.5239       \u001b[32m0.7835\u001b[0m        \u001b[35m0.5037\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5133\u001b[0m       \u001b[32m0.7938\u001b[0m        \u001b[35m0.4865\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6696\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7133\u001b[0m  0.0150\n",
      "      2        0.7462       0.6392        0.7153  0.0170\n",
      "      3        0.6956       0.6392        \u001b[35m0.6549\u001b[0m  0.0130\n",
      "      4        \u001b[36m0.6561\u001b[0m       0.6392        0.6690  0.0140\n",
      "      5        0.6721       0.6392        0.6819  0.0180\n",
      "      6        0.6786       0.6392        \u001b[35m0.6438\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6432\u001b[0m       0.6392        \u001b[35m0.6119\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.6232\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5814\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.6105\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5315\u001b[0m  0.0130\n",
      "     10        \u001b[36m0.5916\u001b[0m       0.7216        0.5815  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6654\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6891\u001b[0m  0.0160\n",
      "      2        0.7159       0.6392        0.7393  0.0170\n",
      "      3        0.7137       0.6392        \u001b[35m0.6555\u001b[0m  0.0150\n",
      "      4        \u001b[36m0.6526\u001b[0m       0.6392        0.6560  0.0200\n",
      "      5        0.6550       0.6392        0.6755  0.0150\n",
      "      6        0.6606       0.6392        \u001b[35m0.6326\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6185\u001b[0m       0.6392        0.6518  0.0160\n",
      "      8        0.6207       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5723\u001b[0m  0.0157\n",
      "      9        \u001b[36m0.5649\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5720\u001b[0m  0.0150\n",
      "     10        0.5771       0.6392        1.2361  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6829\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8201\u001b[0m  0.0140\n",
      "      2        0.8325       0.6392        \u001b[35m0.6502\u001b[0m  0.0150\n",
      "      3        \u001b[36m0.6505\u001b[0m       0.6392        \u001b[35m0.6483\u001b[0m  0.0140\n",
      "      4        0.6517       0.6392        0.6880  0.0180\n",
      "      5        0.6864       0.6392        \u001b[35m0.6400\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6295\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5724\u001b[0m  0.0110\n",
      "      7        \u001b[36m0.5959\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.5178\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.5704\u001b[0m       0.6907        0.6772  0.0140\n",
      "      9        0.6855       0.6392        1.3851  0.0160\n",
      "     10        1.0735       0.7320        0.5466  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6675\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6988\u001b[0m  0.0140\n",
      "      2        0.7302       0.6392        0.7212  0.0160\n",
      "      3        0.6964       0.6392        \u001b[35m0.6465\u001b[0m  0.0128\n",
      "      4        \u001b[36m0.6448\u001b[0m       0.6392        0.6677  0.0150\n",
      "      5        0.6704       0.6392        0.6713  0.0150\n",
      "      6        0.6548       0.6392        \u001b[35m0.5989\u001b[0m  0.0260\n",
      "      7        \u001b[36m0.5975\u001b[0m       \u001b[32m0.6495\u001b[0m        0.6049  0.0180\n",
      "      8        \u001b[36m0.5964\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.4948\u001b[0m  0.0140\n",
      "      9        \u001b[36m0.5566\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4797\u001b[0m  0.0130\n",
      "     10        0.5907       \u001b[32m0.7938\u001b[0m        0.4860  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6756\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7158\u001b[0m  0.0150\n",
      "      2        0.7532       0.6392        0.7161  0.0160\n",
      "      3        0.7000       0.6392        \u001b[35m0.6599\u001b[0m  0.0140\n",
      "      4        \u001b[36m0.6626\u001b[0m       0.6392        0.6756  0.0150\n",
      "      5        0.6801       0.6392        0.6847  0.0170\n",
      "      6        0.6850       0.6392        0.6644  0.0160\n",
      "      7        0.6644       0.6392        \u001b[35m0.6421\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6468\u001b[0m       0.6392        \u001b[35m0.6333\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.6435\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5716\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.6006\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5418\u001b[0m  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6794\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7315\u001b[0m  0.0130\n",
      "      2        0.7799       0.6392        \u001b[35m0.6940\u001b[0m  0.0140\n",
      "      3        \u001b[36m0.6765\u001b[0m       0.6392        \u001b[35m0.6465\u001b[0m  0.0250\n",
      "      4        \u001b[36m0.6494\u001b[0m       0.6392        0.6599  0.0160\n",
      "      5        0.6648       0.6392        \u001b[35m0.6403\u001b[0m  0.0150\n",
      "      6        \u001b[36m0.6353\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5766\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6035\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5659\u001b[0m  0.0140\n",
      "      8        \u001b[36m0.5917\u001b[0m       0.7113        0.6207  0.0150\n",
      "      9        0.6053       0.6701        0.9400  0.0140\n",
      "     10        0.8166       0.6392        0.9093  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6769\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.6973\u001b[0m  0.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.7507       0.6392        0.7260  0.0150\n",
      "      3        0.7022       0.6392        \u001b[35m0.6483\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6486\u001b[0m       0.6392        0.6548  0.0140\n",
      "      5        0.6619       0.6392        0.6768  0.0180\n",
      "      6        0.6655       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5879\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.5878\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5799\u001b[0m  0.0140\n",
      "      8        0.5892       \u001b[32m0.7629\u001b[0m        \u001b[35m0.4739\u001b[0m  0.0177\n",
      "      9        \u001b[36m0.5405\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4597\u001b[0m  0.0150\n",
      "     10        \u001b[36m0.5231\u001b[0m       0.7113        0.6533  0.0150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6892\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7552\u001b[0m  0.0110\n",
      "      2        0.8086       0.6392        \u001b[35m0.6824\u001b[0m  0.0140\n",
      "      3        \u001b[36m0.6685\u001b[0m       0.6392        \u001b[35m0.6531\u001b[0m  0.0150\n",
      "      4        \u001b[36m0.6569\u001b[0m       0.6392        0.6736  0.0160\n",
      "      5        0.6779       0.6392        0.6578  0.0150\n",
      "      6        \u001b[36m0.6455\u001b[0m       0.6392        \u001b[35m0.6010\u001b[0m  0.0130\n",
      "      7        \u001b[36m0.5969\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5877\u001b[0m  0.0120\n",
      "      8        \u001b[36m0.5697\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.4791\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.5401\u001b[0m       0.7113        0.5310  0.0150\n",
      "     10        0.6533       0.5567        0.8850  0.0130\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6757\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7983\u001b[0m  0.0120\n",
      "      2        0.8163       0.6392        \u001b[35m0.6494\u001b[0m  0.0140\n",
      "      3        \u001b[36m0.6490\u001b[0m       0.6392        0.6521  0.0150\n",
      "      4        0.6645       0.6392        0.7133  0.0120\n",
      "      5        0.7130       0.6392        0.6672  0.0120\n",
      "      6        0.6524       0.6392        \u001b[35m0.6074\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6056\u001b[0m       0.6392        0.6338  0.0150\n",
      "      8        0.6073       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5103\u001b[0m  0.0130\n",
      "      9        \u001b[36m0.5661\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4835\u001b[0m  0.0130\n",
      "     10        0.5697       0.7423        0.5258  0.0160\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6850\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7559\u001b[0m  0.0140\n",
      "      2        0.8002       0.6392        \u001b[35m0.6693\u001b[0m  0.0160\n",
      "      3        \u001b[36m0.6611\u001b[0m       0.6392        \u001b[35m0.6547\u001b[0m  0.0150\n",
      "      4        \u001b[36m0.6602\u001b[0m       0.6392        0.6811  0.0237\n",
      "      5        0.6853       0.6392        0.6575  0.0180\n",
      "      6        \u001b[36m0.6448\u001b[0m       0.6392        \u001b[35m0.5995\u001b[0m  0.0260\n",
      "      7        \u001b[36m0.5938\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5901\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.5652\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5351\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.5469\u001b[0m       \u001b[32m0.7010\u001b[0m        0.6326  0.0170\n",
      "     10        0.5873       0.6804        0.6181  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6706\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8450\u001b[0m  0.0240\n",
      "      2        0.8035       0.6392        \u001b[35m0.6428\u001b[0m  0.0280\n",
      "      3        \u001b[36m0.6407\u001b[0m       0.6392        0.6497  0.0315\n",
      "      4        0.6549       0.6392        \u001b[35m0.6427\u001b[0m  0.0270\n",
      "      5        \u001b[36m0.6326\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5763\u001b[0m  0.0260\n",
      "      6        \u001b[36m0.5883\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5279\u001b[0m  0.0230\n",
      "      7        \u001b[36m0.5540\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5277\u001b[0m  0.0270\n",
      "      8        0.5761       0.6598        0.7283  0.0230\n",
      "      9        0.6927       0.6392        0.6145  0.0230\n",
      "     10        0.7315       0.6392        0.6023  0.0240\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6677\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7913\u001b[0m  0.0230\n",
      "      2        0.7752       0.6392        \u001b[35m0.6475\u001b[0m  0.0250\n",
      "      3        \u001b[36m0.6429\u001b[0m       0.6392        0.6512  0.0240\n",
      "      4        0.6522       0.6392        0.6727  0.0230\n",
      "      5        0.6482       0.6392        \u001b[35m0.6129\u001b[0m  0.0230\n",
      "      6        \u001b[36m0.6016\u001b[0m       0.6392        \u001b[35m0.6080\u001b[0m  0.0250\n",
      "      7        \u001b[36m0.5869\u001b[0m       \u001b[32m0.6701\u001b[0m        0.6230  0.0340\n",
      "      8        0.5988       0.6701        0.6863  0.0220\n",
      "      9        0.6199       0.6598        0.6308  0.0230\n",
      "     10        0.6262       \u001b[32m0.7732\u001b[0m        \u001b[35m0.5473\u001b[0m  0.0240\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6677\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7997\u001b[0m  0.0200\n",
      "      2        0.7803       0.6392        \u001b[35m0.6449\u001b[0m  0.0260\n",
      "      3        \u001b[36m0.6459\u001b[0m       0.6392        0.6449  0.0350\n",
      "      4        0.6539       0.6392        0.6593  0.0200\n",
      "      5        0.6531       0.6392        \u001b[35m0.5971\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.6080\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5846\u001b[0m  0.0260\n",
      "      7        \u001b[36m0.6051\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5823\u001b[0m  0.0200\n",
      "      8        0.6097       0.6701        0.6387  0.0180\n",
      "      9        0.6276       0.6701        0.5968  0.0220\n",
      "     10        0.6091       \u001b[32m0.8144\u001b[0m        \u001b[35m0.4932\u001b[0m  0.0171\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6677\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8438\u001b[0m  0.0200\n",
      "      2        0.8047       0.6392        \u001b[35m0.6460\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6456\u001b[0m       0.6392        0.6540  0.0210\n",
      "      4        0.6591       0.6392        0.6784  0.0220\n",
      "      5        0.6706       0.6392        \u001b[35m0.6275\u001b[0m  0.0240\n",
      "      6        \u001b[36m0.6243\u001b[0m       0.6392        \u001b[35m0.6137\u001b[0m  0.0230\n",
      "      7        \u001b[36m0.6166\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5577\u001b[0m  0.0200\n",
      "      8        \u001b[36m0.5790\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5410\u001b[0m  0.0230\n",
      "      9        \u001b[36m0.5657\u001b[0m       0.7010        0.6196  0.0210\n",
      "     10        0.5964       0.6598        0.7480  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6643\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7958\u001b[0m  0.0180\n",
      "      2        0.7812       0.6392        \u001b[35m0.6472\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6495\u001b[0m       0.6392        \u001b[35m0.6462\u001b[0m  0.0260\n",
      "      4        0.6564       0.6392        0.6599  0.0220\n",
      "      5        0.6559       0.6392        \u001b[35m0.5939\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.6067\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5794\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.6053\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5643\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.5989\u001b[0m       0.7010        0.5657  0.0160\n",
      "      9        \u001b[36m0.5851\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5367\u001b[0m  0.0200\n",
      "     10        \u001b[36m0.5622\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4648\u001b[0m  0.0167\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6668\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7565\u001b[0m  0.0170\n",
      "      2        0.7704       0.6392        \u001b[35m0.6463\u001b[0m  0.0190\n",
      "      3        \u001b[36m0.6489\u001b[0m       0.6392        \u001b[35m0.6435\u001b[0m  0.0170\n",
      "      4        0.6562       0.6392        0.6580  0.0190\n",
      "      5        0.6561       0.6392        \u001b[35m0.6045\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6158\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5813\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.6012\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5442\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.5799\u001b[0m       0.7216        \u001b[35m0.5361\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.5637\u001b[0m       0.7010        0.6042  0.0180\n",
      "     10        0.5862       0.7010        0.6152  0.0330\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6697\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7755\u001b[0m  0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.7777       0.6392        \u001b[35m0.6436\u001b[0m  0.0180\n",
      "      3        \u001b[36m0.6439\u001b[0m       0.6392        0.6505  0.0200\n",
      "      4        0.6608       0.6392        0.6521  0.0200\n",
      "      5        \u001b[36m0.6407\u001b[0m       0.6392        \u001b[35m0.5911\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.6020\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5520\u001b[0m  0.0254\n",
      "      7        \u001b[36m0.5704\u001b[0m       \u001b[32m0.7216\u001b[0m        0.5529  0.0190\n",
      "      8        0.5723       0.6907        0.6832  0.0230\n",
      "      9        0.6066       0.6701        0.6528  0.0220\n",
      "     10        0.6030       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4854\u001b[0m  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6886\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7987\u001b[0m  0.0180\n",
      "      2        0.7923       0.6392        \u001b[35m0.6517\u001b[0m  0.0230\n",
      "      3        \u001b[36m0.6508\u001b[0m       0.6392        0.6535  0.0180\n",
      "      4        0.6609       0.6392        0.6767  0.0200\n",
      "      5        0.6732       0.6392        \u001b[35m0.6381\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.6309\u001b[0m       0.6392        \u001b[35m0.6167\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.6163\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5767\u001b[0m  0.0210\n",
      "      8        \u001b[36m0.5722\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5575\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5603\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5252\u001b[0m  0.0160\n",
      "     10        \u001b[36m0.5526\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4737\u001b[0m  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6871\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7760\u001b[0m  0.0160\n",
      "      2        0.7839       0.6392        \u001b[35m0.6503\u001b[0m  0.0190\n",
      "      3        \u001b[36m0.6485\u001b[0m       0.6392        \u001b[35m0.6451\u001b[0m  0.0160\n",
      "      4        0.6522       0.6392        0.6641  0.0170\n",
      "      5        0.6585       0.6392        \u001b[35m0.6035\u001b[0m  0.0200\n",
      "      6        \u001b[36m0.6023\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5903\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.5916\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5222\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.5554\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.4772\u001b[0m  0.0177\n",
      "      9        \u001b[36m0.5352\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4604\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.5184\u001b[0m       0.7526        0.4662  0.0180\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6713\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7764\u001b[0m  0.0170\n",
      "      2        0.7653       0.6392        \u001b[35m0.6328\u001b[0m  0.0180\n",
      "      3        \u001b[36m0.6253\u001b[0m       0.6392        0.6408  0.0190\n",
      "      4        0.6409       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5886\u001b[0m  0.0210\n",
      "      5        \u001b[36m0.5680\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5759\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.5501\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5413\u001b[0m  0.0210\n",
      "      7        \u001b[36m0.5315\u001b[0m       0.7216        \u001b[35m0.5274\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.5150\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5168\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.5067\u001b[0m       0.7423        \u001b[35m0.4869\u001b[0m  0.0190\n",
      "     10        \u001b[36m0.4822\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.4864\u001b[0m  0.0196\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6678\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8151\u001b[0m  0.0160\n",
      "      2        0.7905       0.6392        \u001b[35m0.6548\u001b[0m  0.0187\n",
      "      3        \u001b[36m0.6514\u001b[0m       0.6392        0.6650  0.0210\n",
      "      4        0.6675       0.6392        0.6926  0.0176\n",
      "      5        0.6787       0.6392        \u001b[35m0.6388\u001b[0m  0.0200\n",
      "      6        \u001b[36m0.6311\u001b[0m       0.6392        \u001b[35m0.6298\u001b[0m  0.0350\n",
      "      7        \u001b[36m0.6240\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5837\u001b[0m  0.0275\n",
      "      8        \u001b[36m0.5849\u001b[0m       0.6701        \u001b[35m0.5769\u001b[0m  0.0300\n",
      "      9        0.6008       0.6495        0.8502  0.0290\n",
      "     10        0.7908       0.6392        0.6904  0.0380\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6758\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8578\u001b[0m  0.0283\n",
      "      2        0.8217       0.6392        \u001b[35m0.6507\u001b[0m  0.0330\n",
      "      3        \u001b[36m0.6491\u001b[0m       0.6392        0.6617  0.0400\n",
      "      4        0.6656       0.6392        0.6913  0.0320\n",
      "      5        0.6817       0.6392        \u001b[35m0.6442\u001b[0m  0.0280\n",
      "      6        \u001b[36m0.6329\u001b[0m       0.6392        \u001b[35m0.6387\u001b[0m  0.0220\n",
      "      7        \u001b[36m0.6259\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5886\u001b[0m  0.0250\n",
      "      8        \u001b[36m0.5754\u001b[0m       \u001b[32m0.6804\u001b[0m        0.5994  0.0240\n",
      "      9        0.5872       0.6495        0.8928  0.0220\n",
      "     10        0.7511       0.6392        0.7836  0.0240\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6651\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8179\u001b[0m  0.0210\n",
      "      2        0.8015       0.6392        \u001b[35m0.6477\u001b[0m  0.0240\n",
      "      3        \u001b[36m0.6492\u001b[0m       0.6392        0.6572  0.0250\n",
      "      4        0.6649       0.6392        0.6948  0.0230\n",
      "      5        0.6866       0.6392        \u001b[35m0.6281\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.6286\u001b[0m       0.6392        \u001b[35m0.6182\u001b[0m  0.0240\n",
      "      7        0.6308       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5479\u001b[0m  0.0250\n",
      "      8        \u001b[36m0.5815\u001b[0m       0.6907        0.5532  0.0310\n",
      "      9        0.5909       0.6598        0.7916  0.0210\n",
      "     10        0.7336       0.6392        0.7357  0.0240\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6742\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8689\u001b[0m  0.0230\n",
      "      2        0.8283       0.6392        \u001b[35m0.6454\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6458\u001b[0m       0.6392        0.6593  0.0230\n",
      "      4        0.6709       0.6392        0.6971  0.0230\n",
      "      5        0.6841       0.6392        \u001b[35m0.6159\u001b[0m  0.0230\n",
      "      6        \u001b[36m0.6178\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.6046\u001b[0m  0.0230\n",
      "      7        0.6197       \u001b[32m0.7732\u001b[0m        \u001b[35m0.5218\u001b[0m  0.0240\n",
      "      8        \u001b[36m0.5721\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4813\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5279\u001b[0m       0.7423        0.5379  0.0270\n",
      "     10        0.5494       0.6804        0.7870  0.0250\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6740\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8446\u001b[0m  0.0220\n",
      "      2        0.8178       0.6392        \u001b[35m0.6481\u001b[0m  0.0220\n",
      "      3        \u001b[36m0.6518\u001b[0m       0.6392        0.6608  0.0230\n",
      "      4        0.6687       0.6392        0.6887  0.0230\n",
      "      5        0.6881       0.6392        \u001b[35m0.6396\u001b[0m  0.0290\n",
      "      6        \u001b[36m0.6416\u001b[0m       0.6392        \u001b[35m0.6142\u001b[0m  0.0210\n",
      "      7        \u001b[36m0.6330\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5566\u001b[0m  0.0220\n",
      "      8        \u001b[36m0.5977\u001b[0m       0.7216        0.5600  0.0200\n",
      "      9        0.6119       0.6598        0.7237  0.0190\n",
      "     10        0.6985       0.6392        0.7024  0.0170\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6639\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8209\u001b[0m  0.0210\n",
      "      2        0.8053       0.6392        \u001b[35m0.6442\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6452\u001b[0m       0.6392        0.6593  0.0190\n",
      "      4        0.6727       0.6392        0.6790  0.0200\n",
      "      5        0.6661       0.6392        \u001b[35m0.5995\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.6094\u001b[0m       \u001b[32m0.6598\u001b[0m        0.6009  0.0220\n",
      "      7        0.6112       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5447\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.5845\u001b[0m       0.7216        \u001b[35m0.5106\u001b[0m  0.0320\n",
      "      9        \u001b[36m0.5481\u001b[0m       0.7113        0.5915  0.0290\n",
      "     10        0.5725       0.6804        0.6951  0.0300\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6630\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8015\u001b[0m  0.0250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.8022       0.6392        \u001b[35m0.6426\u001b[0m  0.0270\n",
      "      3        \u001b[36m0.6450\u001b[0m       0.6392        0.6470  0.0280\n",
      "      4        0.6607       0.6392        0.6682  0.0260\n",
      "      5        0.6564       \u001b[32m0.6701\u001b[0m        \u001b[35m0.5793\u001b[0m  0.0220\n",
      "      6        \u001b[36m0.5935\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5619\u001b[0m  0.0250\n",
      "      7        \u001b[36m0.5796\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5384\u001b[0m  0.0230\n",
      "      8        \u001b[36m0.5653\u001b[0m       0.7113        0.7040  0.0208\n",
      "      9        0.6408       0.6598        0.8115  0.0240\n",
      "     10        0.6635       \u001b[32m0.8144\u001b[0m        \u001b[35m0.5256\u001b[0m  0.0260\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6722\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8139\u001b[0m  0.0210\n",
      "      2        0.7988       0.6392        \u001b[35m0.6380\u001b[0m  0.0230\n",
      "      3        \u001b[36m0.6376\u001b[0m       0.6392        0.6434  0.0370\n",
      "      4        0.6549       0.6392        0.6651  0.0133\n",
      "      5        0.6411       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5662\u001b[0m  0.0347\n",
      "      6        \u001b[36m0.5642\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5601\u001b[0m  0.0247\n",
      "      7        \u001b[36m0.5427\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.5103\u001b[0m  0.0210\n",
      "      8        0.5586       \u001b[32m0.8041\u001b[0m        \u001b[35m0.4630\u001b[0m  0.0210\n",
      "      9        0.5807       0.5979        0.6768  0.0240\n",
      "     10        0.6294       0.7113        0.5346  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6719\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7426\u001b[0m  0.0210\n",
      "      2        0.7663       0.6392        \u001b[35m0.6388\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6388\u001b[0m       0.6392        \u001b[35m0.6262\u001b[0m  0.0250\n",
      "      4        0.6440       0.6392        0.6347  0.0260\n",
      "      5        \u001b[36m0.6206\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5342\u001b[0m  0.0240\n",
      "      6        \u001b[36m0.5664\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4738\u001b[0m  0.0230\n",
      "      7        \u001b[36m0.5233\u001b[0m       0.7526        \u001b[35m0.4648\u001b[0m  0.0220\n",
      "      8        \u001b[36m0.5182\u001b[0m       0.7320        0.5672  0.0230\n",
      "      9        0.5407       0.6907        0.6680  0.0230\n",
      "     10        0.5834       0.7113        0.5169  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6737\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7799\u001b[0m  0.0240\n",
      "      2        0.7754       0.6392        \u001b[35m0.6404\u001b[0m  0.0230\n",
      "      3        \u001b[36m0.6349\u001b[0m       0.6392        0.6497  0.0230\n",
      "      4        0.6558       0.6392        0.6450  0.0240\n",
      "      5        \u001b[36m0.6067\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5722\u001b[0m  0.0250\n",
      "      6        \u001b[36m0.5593\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.5697\u001b[0m  0.0220\n",
      "      7        \u001b[36m0.5396\u001b[0m       0.7113        \u001b[35m0.5638\u001b[0m  0.0220\n",
      "      8        \u001b[36m0.5254\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.5175\u001b[0m  0.0240\n",
      "      9        \u001b[36m0.5046\u001b[0m       0.7216        \u001b[35m0.4957\u001b[0m  0.0230\n",
      "     10        \u001b[36m0.4870\u001b[0m       0.7320        \u001b[35m0.4899\u001b[0m  0.0250\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6690\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8308\u001b[0m  0.0220\n",
      "      2        0.8153       0.6392        \u001b[35m0.6490\u001b[0m  0.0230\n",
      "      3        \u001b[36m0.6497\u001b[0m       0.6392        0.6629  0.0240\n",
      "      4        0.6683       0.6392        0.6813  0.0240\n",
      "      5        0.6692       0.6392        \u001b[35m0.5987\u001b[0m  0.0230\n",
      "      6        \u001b[36m0.6059\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5976\u001b[0m  0.0230\n",
      "      7        0.6156       \u001b[32m0.7629\u001b[0m        \u001b[35m0.5099\u001b[0m  0.0230\n",
      "      8        \u001b[36m0.5590\u001b[0m       0.7629        \u001b[35m0.4431\u001b[0m  0.0240\n",
      "      9        \u001b[36m0.5191\u001b[0m       \u001b[32m0.7835\u001b[0m        0.4929  0.0230\n",
      "     10        0.5941       0.6598        0.8223  0.0250\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6761\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8251\u001b[0m  0.0240\n",
      "      2        0.8097       0.6392        \u001b[35m0.6511\u001b[0m  0.0240\n",
      "      3        \u001b[36m0.6483\u001b[0m       0.6392        0.6661  0.0280\n",
      "      4        0.6672       0.6392        0.6860  0.0270\n",
      "      5        0.6624       0.6289        \u001b[35m0.6194\u001b[0m  0.0220\n",
      "      6        \u001b[36m0.6020\u001b[0m       0.6289        0.6654  0.0410\n",
      "      7        0.6222       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5717\u001b[0m  0.0190\n",
      "      8        \u001b[36m0.5512\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5037\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5073\u001b[0m       0.7526        0.6296  0.0220\n",
      "     10        0.6077       0.6701        0.9364  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6642\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7555\u001b[0m  0.0180\n",
      "      2        0.7672       0.6392        \u001b[35m0.6525\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6486\u001b[0m       0.6392        \u001b[35m0.6488\u001b[0m  0.0210\n",
      "      4        0.6530       0.6392        0.6609  0.0210\n",
      "      5        \u001b[36m0.6377\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.5577\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.5800\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.5095\u001b[0m  0.0210\n",
      "      7        \u001b[36m0.5508\u001b[0m       0.7010        0.5671  0.0220\n",
      "      8        0.5872       0.6598        1.1577  0.0190\n",
      "      9        0.9868       0.6392        0.7968  0.0180\n",
      "     10        0.9103       0.6392        0.8741  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6728\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8492\u001b[0m  0.0220\n",
      "      2        0.8239       0.6392        \u001b[35m0.6438\u001b[0m  0.0260\n",
      "      3        \u001b[36m0.6438\u001b[0m       0.6392        0.6670  0.0240\n",
      "      4        0.6762       0.6392        0.6720  0.0190\n",
      "      5        0.6516       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5773\u001b[0m  0.0250\n",
      "      6        \u001b[36m0.6014\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5449\u001b[0m  0.0200\n",
      "      7        \u001b[36m0.5830\u001b[0m       0.7113        0.5739  0.0340\n",
      "      8        0.6023       0.6701        0.7767  0.0219\n",
      "      9        0.7094       0.6392        0.8830  0.0222\n",
      "     10        0.9864       0.6392        0.8623  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6690\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7795\u001b[0m  0.0200\n",
      "      2        0.7899       0.6392        \u001b[35m0.6607\u001b[0m  0.0240\n",
      "      3        \u001b[36m0.6621\u001b[0m       0.6392        0.6612  0.0240\n",
      "      4        0.6649       0.6392        0.6752  0.0220\n",
      "      5        0.6740       0.6392        \u001b[35m0.6304\u001b[0m  0.0220\n",
      "      6        \u001b[36m0.6340\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m0.5936\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.6140\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.5243\u001b[0m  0.0220\n",
      "      8        \u001b[36m0.5614\u001b[0m       0.7010        0.5919  0.0230\n",
      "      9        0.6118       0.6495        1.1711  0.0220\n",
      "     10        0.9220       0.6392        0.7221  0.0190\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6721\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8764\u001b[0m  0.0190\n",
      "      2        0.8493       0.6392        \u001b[35m0.6508\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6518\u001b[0m       0.6392        0.6666  0.0230\n",
      "      4        0.6784       0.6392        0.7109  0.0350\n",
      "      5        0.7099       0.6392        0.6561  0.0240\n",
      "      6        \u001b[36m0.6509\u001b[0m       0.6392        \u001b[35m0.6140\u001b[0m  0.0270\n",
      "      7        \u001b[36m0.6404\u001b[0m       0.6392        0.6303  0.0210\n",
      "      8        0.6408       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5320\u001b[0m  0.0190\n",
      "      9        \u001b[36m0.6013\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.4773\u001b[0m  0.0209\n",
      "     10        \u001b[36m0.5373\u001b[0m       0.7320        0.5138  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6663\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.8018\u001b[0m  0.0210\n",
      "      2        0.8139       0.6392        \u001b[35m0.6468\u001b[0m  0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m0.6485\u001b[0m       0.6392        0.6666  0.0220\n",
      "      4        0.6775       0.6392        0.6851  0.0220\n",
      "      5        0.6728       0.6392        \u001b[35m0.6062\u001b[0m  0.0240\n",
      "      6        \u001b[36m0.6061\u001b[0m       0.6392        \u001b[35m0.6012\u001b[0m  0.0190\n",
      "      7        0.6091       \u001b[32m0.7423\u001b[0m        \u001b[35m0.4855\u001b[0m  0.0220\n",
      "      8        \u001b[36m0.5627\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.4655\u001b[0m  0.0190\n",
      "      9        0.5675       \u001b[32m0.8351\u001b[0m        \u001b[35m0.4559\u001b[0m  0.0230\n",
      "     10        \u001b[36m0.5374\u001b[0m       0.7423        0.4774  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6691\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7946\u001b[0m  0.0160\n",
      "      2        0.7975       0.6392        \u001b[35m0.6411\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6411\u001b[0m       0.6392        0.6563  0.0190\n",
      "      4        0.6693       0.6392        0.6844  0.0200\n",
      "      5        0.6625       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5943\u001b[0m  0.0800\n",
      "      6        \u001b[36m0.5855\u001b[0m       0.6598        0.6034  0.0410\n",
      "      7        \u001b[36m0.5792\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m0.5173\u001b[0m  0.0250\n",
      "      8        \u001b[36m0.5709\u001b[0m       \u001b[32m0.7320\u001b[0m        0.5653  0.0253\n",
      "      9        0.6704       0.5773        0.8538  0.0250\n",
      "     10        0.6933       0.6598        0.7124  0.0210\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6770\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7902\u001b[0m  0.0220\n",
      "      2        0.8047       0.6392        \u001b[35m0.6448\u001b[0m  0.0290\n",
      "      3        \u001b[36m0.6475\u001b[0m       0.6392        0.6519  0.0220\n",
      "      4        0.6618       0.6392        0.6695  0.0280\n",
      "      5        0.6583       \u001b[32m0.6598\u001b[0m        \u001b[35m0.5729\u001b[0m  0.0330\n",
      "      6        \u001b[36m0.5721\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.5646\u001b[0m  0.0280\n",
      "      7        0.5754       \u001b[32m0.8041\u001b[0m        \u001b[35m0.4739\u001b[0m  0.0330\n",
      "      8        \u001b[36m0.5631\u001b[0m       \u001b[32m0.8144\u001b[0m        \u001b[35m0.4676\u001b[0m  0.0257\n",
      "      9        \u001b[36m0.5431\u001b[0m       0.7216        0.4933  0.0320\n",
      "     10        \u001b[36m0.5368\u001b[0m       0.7526        0.5022  0.0380\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6673\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m0.7675\u001b[0m  0.0290\n",
      "      2        0.7780       0.6392        \u001b[35m0.6426\u001b[0m  0.0270\n",
      "      3        \u001b[36m0.6398\u001b[0m       0.6392        0.6507  0.0220\n",
      "      4        0.6547       0.6392        \u001b[35m0.6406\u001b[0m  0.0230\n",
      "      5        \u001b[36m0.6099\u001b[0m       \u001b[32m0.6804\u001b[0m        \u001b[35m0.5748\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.5680\u001b[0m       \u001b[32m0.7113\u001b[0m        0.5978  0.0200\n",
      "      7        \u001b[36m0.5531\u001b[0m       0.7113        0.5885  0.0240\n",
      "      8        \u001b[36m0.5350\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m0.5096\u001b[0m  0.0240\n",
      "      9        \u001b[36m0.5050\u001b[0m       0.7629        \u001b[35m0.4698\u001b[0m  0.0390\n",
      "     10        \u001b[36m0.4932\u001b[0m       0.7216        0.4772  0.0220\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6776\u001b[0m       \u001b[32m0.6389\u001b[0m        \u001b[35m0.6606\u001b[0m  0.0152\n",
      "      2        \u001b[36m0.6660\u001b[0m       0.6389        \u001b[35m0.6524\u001b[0m  0.0161\n",
      "      3        \u001b[36m0.6526\u001b[0m       0.6389        \u001b[35m0.6398\u001b[0m  0.0200\n",
      "      4        \u001b[36m0.6380\u001b[0m       0.6389        \u001b[35m0.6192\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6190\u001b[0m       0.6389        \u001b[35m0.6011\u001b[0m  0.0190\n",
      "      6        \u001b[36m0.6009\u001b[0m       \u001b[32m0.7315\u001b[0m        \u001b[35m0.5735\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.5691\u001b[0m       0.7222        \u001b[35m0.5399\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.5414\u001b[0m       \u001b[32m0.7593\u001b[0m        \u001b[35m0.5067\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.5097\u001b[0m       \u001b[32m0.7685\u001b[0m        \u001b[35m0.4858\u001b[0m  0.0260\n",
      "     10        \u001b[36m0.4971\u001b[0m       0.7500        \u001b[35m0.4718\u001b[0m  0.0227\n"
     ]
    }
   ],
   "source": [
    "# Optimising the hyperparameters via grid search\n",
    "\n",
    "params = {\n",
    "    'lr': [0.05,0.1,0.2],\n",
    "    'optimizer__momentum': [0.85,0.9,0.95],\n",
    "    'module__hidden_size': [50,100,200],\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=True, cv=10,verbose=0)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gs.fit(x_trainTensor, y_trainTensor)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a5a2a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 61.42744064331055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9f16d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7446890286512928 {'lr': 0.1, 'module__hidden_size': 200, 'optimizer__momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# See the best score and the parameters\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbecdc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7579143389199255"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the score of the best model on the train set\n",
    "gs.score(x_trainTensor,y_trainTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4dec6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLP_optimised.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the optimised model as a file\n",
    "dump(gs, 'MLP_optimised.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d89c8fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.85</td>\n",
       "      <td>50</td>\n",
       "      <td>0.638749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.638749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.638749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.85</td>\n",
       "      <td>100</td>\n",
       "      <td>0.638749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.640636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>100</td>\n",
       "      <td>0.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.85</td>\n",
       "      <td>200</td>\n",
       "      <td>0.640636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.655486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>200</td>\n",
       "      <td>0.688924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>50</td>\n",
       "      <td>0.642523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.636897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.651852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>100</td>\n",
       "      <td>0.646331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.698323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>100</td>\n",
       "      <td>0.696541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>200</td>\n",
       "      <td>0.731761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.744689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>200</td>\n",
       "      <td>0.744654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>50</td>\n",
       "      <td>0.704018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.705765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.724458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>100</td>\n",
       "      <td>0.724389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.694654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.95</td>\n",
       "      <td>100</td>\n",
       "      <td>0.681447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>200</td>\n",
       "      <td>0.726345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.665024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.95</td>\n",
       "      <td>200</td>\n",
       "      <td>0.678057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr momentum hidden_size     score\n",
       "0   0.05     0.85          50  0.638749\n",
       "1   0.05      0.9          50  0.638749\n",
       "2   0.05     0.95          50  0.638749\n",
       "3   0.05     0.85         100  0.638749\n",
       "4   0.05      0.9         100  0.640636\n",
       "5   0.05     0.95         100  0.644444\n",
       "6   0.05     0.85         200  0.640636\n",
       "7   0.05      0.9         200  0.655486\n",
       "8   0.05     0.95         200  0.688924\n",
       "9    0.1     0.85          50  0.642523\n",
       "10   0.1      0.9          50  0.636897\n",
       "11   0.1     0.95          50  0.651852\n",
       "12   0.1     0.85         100  0.646331\n",
       "13   0.1      0.9         100  0.698323\n",
       "14   0.1     0.95         100  0.696541\n",
       "15   0.1     0.85         200  0.731761\n",
       "16   0.1      0.9         200  0.744689\n",
       "17   0.1     0.95         200  0.744654\n",
       "18   0.2     0.85          50  0.704018\n",
       "19   0.2      0.9          50  0.705765\n",
       "20   0.2     0.95          50  0.724458\n",
       "21   0.2     0.85         100  0.724389\n",
       "22   0.2      0.9         100  0.694654\n",
       "23   0.2     0.95         100  0.681447\n",
       "24   0.2     0.85         200  0.726345\n",
       "25   0.2      0.9         200  0.665024\n",
       "26   0.2     0.95         200  0.678057"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(gs.cv_results_)\n",
    "results = results[['param_lr','param_optimizer__momentum','param_module__hidden_size','mean_test_score']]\n",
    "results.columns = ['lr','momentum','hidden_size','score']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e6f667",
   "metadata": {},
   "source": [
    "# Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "121f4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "mlp = load('MLP_optimised.joblib')\n",
    "x_test = pd.read_csv('x_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "# Convert dataframes to series and then to tensor\n",
    "y_test = y_test.squeeze()\n",
    "x_testTensor = torch.tensor(x_test.to_numpy()).float()\n",
    "y_testTensor = torch.tensor(y_test.to_numpy()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae9de32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402597402597403"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the score of the best model on the test set\n",
    "mlp.score(x_testTensor,y_testTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "478aeefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahem\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot normalized confusion matrix\n",
    "disp = plot_confusion_matrix(mlp, x_testTensor, y_testTensor, cmap=plt.cm.Blues, normalize='all')\n",
    "disp.ax_.set_title('MLP confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b5cd7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.78034682 0.62068966] \n",
      "recall [0.85987261 0.48648649] \n",
      "F1 [0.81818182 0.54545455] \n",
      "support [157  74]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# See precision, recall and F1 score\n",
    "precision,recall,f,support = precision_recall_fscore_support(y_testTensor, mlp.predict(x_testTensor))\n",
    "print('precision',precision,'\\nrecall',recall,'\\nF1',f,'\\nsupport',support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b36b680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahem\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise ROC curve\n",
    "metrics.plot_roc_curve(mlp, x_testTensor, y_testTensor, name='MLP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab986e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
